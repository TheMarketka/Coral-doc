%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\chapter{Expressions}

\minitoc

\newpage

\grammar\begin{lstlisting}
Expr        
    ::= Simple_Expr
      | Application_Expr
      | Object_Creation_Expr
      | Type_Application_Expr
      | '(' Expr ')'
      | 'begin' Expr 'end'
      | Infix_Expr
      | Conditional_Expr
      | Match_Expr
      | Quasiquote_Expr
      | Quote_Expr
      | Metaclass_Access
      | Message_Data_Expr
      | Workflow_Expr
      | Rescue_Expr
      | Catch_Expr
      | Type_Ref_Expr
      | Loop_Expr
      | Signal_Expr
      | Raise_Expr
      | Throw_Expr
      | Return_Expr
      | Rebind_Expr
      | Update_Expr
      | Yield_Expr
      | Annotated_Expr
      | Cast_Expr
      | Use_Expr
      | Delayed_Expr
      | Ref_Expr
      | Jump_Expr
      | Function_Expr
      | Binding_Expr
      | Tuple_Exprs
      | Method_Expr
      | Structure_Ref_Expr
      | Member_Constraint_Invocation_Expr
      | Expr semi Expr
      | Scope_Stat
\end{lstlisting}

Expressions are composed of various keywords, operators and operands. Expression forms are discussed subsequently. 







\section{Expression Typing}
\label{sec:expression-typing}

The typing of expressions is often relative to some {\em expected type} (which might be undefined). When we write ``expression $e$ is expected to conform to type $T$\,'', we mean:
\begin{enumerate}
  \item The expected type of $e$ is $T$.
  \item The type of expression $e$ must conform to $T$. 
\end{enumerate}

Usually, the type of the expression is defined by the last element of an execution branch, as discussed subsequently with each expression kind. 

What we call ``statement'', in context of Aml is in fact yet another kind of an expression, and those expressions themselves always have a type (usually \code{Unit}) and a value. 





\section{Data Expressions}





\subsection{Simple Constant Expressions}
\label{sec:literal-expr}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= Constant
Constant
    ::= Literal
\end{lstlisting}

Typing of literals is as described in (\sref{sec:literals}); their evaluation is immediate. 

Aml guarantees that methods of numeric literals (the class \code{Number}) always terminate, are idempotent, and do not have any observable side effects. 






\subsection{The Nil and Undefined Values}

\grammar\begin{lstlisting}
Constant 
    ::= ...
      | 'nil'
      | 'undefined'
\end{lstlisting}

The \code{nil} value is of type \code{Option[$T$]}, the \code{None} variant, and is thus compatible with every type that is nullable (\sref{sec:nullable-types}).

The \code{undefined} value is of type \code{Nothing}, a subtype of \code{Nothing}, and is therefore compatible with every type whatsoever. 

The \code{nil} represents a ``no value'', and is itself represented by an object (with a possible immediate representation). 

A reference to any member of the \code{nil} object causes \code{Member_Not_Found} to be raised, unless the member in fact exists. The \code{nil} object is also frozen by default. 

The \code{undefined} represents ``nothing, not even no value''.

See (\sref{sec:emptiness}) for more details on ``nothing'' values. 





\subsection{Tuple Expressions}
\label{sec:tuples}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Tuple_Exprs
Tuple_Exprs 
    ::= Exprs {',' [nl] Named_Exprs}
      | Named_Exprs
      | Tuple_Head_Expr '(' [nl] Exprs {',' [nl] Named_Exprs} [nl] ')'
      | Tuple_Head_Expr '(' [nl] Named_Exprs [nl] ')'
      | Tuple_Head_Expr '{' [nl] Tuple_Fields_Init [nl] '}'
Tuple_Head_Expr
    ::= ['mutable' | 'immutable'] 'tuple' [nl]
Named_Exprs 
    ::= Named_Expr {',' [nl] Named_Expr}
Named_Expr
    ::= '~' id ':' Expr
Constant 
    ::= ...
      | '()'
Tuple_Fields_Init 
    ::= Tuple_Positional_Fields_Init [semi Tuple_Labelled_Fields_Init]
      | Tuple_Labelled_Fields_Init
Tuple_Positional_Fields_Init
    ::= Tuple_Field_Init {semi Tuple_Field_Init}
Tuple_Labelled_Fields_Init
    ::= Tuple_Labelled_Field_Init {semi Tuple_Labelled_Field_Init}
Tuple_Positional_Field_Init 
    ::= Expr
Tuple_Labelled_Field_Init
    ::= id '=>' Expr
\end{lstlisting}

A tuple expression ~\lstinline!($e_1 \commadots e_n$)!~ is an alias for the class instance creation ~\lstinline!Tuple($e_1 \commadots e_n$)!, where $n \geq 1$. The empty tuple ~\lstinline!()!~ is the unique value of type \code{Unit}. A tuple with only one value is usually only the value itself, without being wrapped in a tuple.  

A tuple expression may alternatively appear in the form ~\lstinline!tuple {$e_1$; $\ldots$; $e_n$}!. In that form, it may also be prepended with either \code{mutable} or \code{immutable} keyword. Implicitly, all forms are prepended with \code{immutable}. 

Sub-expressions that are not labelled with any id are positional. 

Sub-expressions in a tuple expression that are prepended with a tilde and an id (in form of ~\lstinline!~$x_i$: $e_i$!) are labelled $x_i$ -- this adds annotation ~\lstinline!@[labelled :$x_i$]!~ to the type of the sub-expression, and such an element is then not accessible by its order. If the annotation is explicitly added, the behaviour is the same. Labelled sub-expressions, either in the syntax sugar or explicit form, can only appear at the end of the sequence of sub-expressions, thus no unnamed sub-expressions can appear after a named sub-expression. 
% TBD: specify the full path to that annotation

Labelled sub-expressions must appear after all positional (non-labelled) sub-expressions. Otherwise, they are implicitly reordered after all positional sub-expressions, and a warning is issued. The positions of non-labelled sub-expressions is then recalculated to match the new order.

Tuple expressions have the runtime type of ~\lstinline!Aml/Language.Tuple[$T_1 \commadots T_n$]!, where each $T_i$ is the known type of each $e_i$, including the annotations that give label to sub-expressions. Tuple expressions prepended by \code{mutable} are of the type ~\lstinline!Aml/Language.Mutable_Tuple[$T_1 \commadots T_n$]!.

Tuple expressions with an extended grammar rules are also used within function applications (\sref{sec:function-applications}), and the rules considering element labelling and positions are the same as for the simple data tuple expressions. 

\paragraph{Mixing labelled and non-labelled elements}
As a rule of thumb, only the following combinations of labelled and non-labelled elements should be used:
\begin{itemize}
  \item All non-labelled elements. Usually should not exceed 3 elements.
  \item All labelled elements.  
  \item One non-labelled element followed by labelled elements, as an argument (\sref{sec:function-applications}). 
  \item Many non-labelled elements followed by up to 3 labelled elements, also as an argument. 
\end{itemize}
The compiler should by default issue a warning when different combinations are encountered. 





\subsection{Tuple Clone Expressions}
\label{sec:tuple-clone}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Tuple_Exprs
Tuple_Exprs 
    ::= ...
      | Tuple_Head_Expr '{' [nl] Expr 'with' Tuple_Fields_Clone [nl] '}'
Tuple_Fields_Clone 
    ::= Tuple_Field_Clone {semi Tuple_Field_Clone}
Tuple_Field_Clone
    ::= (id | decimal_numeral) ['=>' Expr]
\end{lstlisting}

An expression of the form 
\begin{lstlisting}
tuple { $e$ with $i_1$ => $e_1$; $\ldots$; $i_n$ => $e_n$ }
\end{lstlisting}
is a tuple clone expression. 





\subsection{List Expressions}
\label{sec:list-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | List_Expr
Words
    ::= Word {{? Unicode whitespace ?}+ Word}
Word
    ::= {id_char}+
List_Expr
    ::= '%' List_Flags '[' [Expr {semi Expr}] ']'
      | '%w' List_Flags '[' [Words] ']'
List_Flags
    ::= [['i' |  (* immutable *)
          'm']   (* mutable *)
         ['l']]  (* double linked *)]
\end{lstlisting}

An expression of the form ~\lstinline!%[$e_1$; $\ldots$; $e_n$]! is a list expression. 

\begin{itemize}
  \item Expression of the form ~\lstinline!%[$e_1$; $\ldots$; $e_n$]!
    has type of \code{Linked_List[$T$]}. 
  \item Expression of the form ~\lstinline!%i[$e_1$; $\ldots$; $e_n$]!
    has also type of \code{Linked_List[$T$]}. 
  \item Expression of the form ~\lstinline!%m[$e_1$; $\ldots$; $e_n$]!
    has type of \code{Mutable_Linked_List[$T$]}. 
  \item Expression of the form ~\lstinline!%l[$e_1$; $\ldots$; $e_n$]!
    has type of \code{Double_Linked_List[$T$]}. 
  \item Expression of the form ~\lstinline!%il[$e_1$; $\ldots$; $e_n$]!
    has also type of \code{Double_Linked_List[$T$]}. 
  \item Expression of the form ~\lstinline!%ml[$e_1$; $\ldots$; $e_n$]!
    has type of \code{Mutable_Double_Linked_List[$T$]}. 
  \item Expression of the form ~\lstinline!%w[word word2 wordx]!
    has type of \code{Linked_List[String]}, and respectively for the other flags, where $T$ is \code{String} (\code{Aml/Language.String}). 
\end{itemize}

The ``\code{i}'' and ``\code{m}'' flags can be inferred from the expected type, based on \code{immutable} and \code{mutable} modifier (\sref{sec:mutable-immutable-storage}) respectively (or the related type annotations). This is also true for array expressions (\sref{sec:array-expressions}), dictionary expressions (\sref{sec:dict-expressions}), multimap expressions (\sref{sec:multimap-expressions}) and bag expressions (\sref{sec:bag-expressions}). It is an error if there is a mutability flag in the expression that is incompatible to the mutability required by the expected type. 





\subsection{Array Expressions}
\label{sec:array-expressions}

\grammar\begin{lstlisting}
Simple_Expr
    ::= ...
      | Array_Expr
Array_Expr
    ::= '%' Array_Flags '[|' [Expr {semi Expr}] '|]'
      | '%w' Array_Flags '[|' Words '|]'
Array_Flags 
    ::= [['i' |  (* immutable *)
          'm']]  (* mutable *)
\end{lstlisting}

An expression of the form ~\lstinline!%[|$e_1$; $\ldots$; $e_n$|]! is an array expression. 

\begin{itemize}
  \item Expression of the form ~\lstinline!%[|$e_1$; $\ldots$; $e_n$|]!
    has type of \code{Mutable_Array[$T$]}. 
  \item Expression of the form ~\lstinline!%i[|$e_1$; $\ldots$; $e_n$|]!
    has type of \code{Array[$T$]}. 
  \item Expression of the form ~\lstinline!%m[|$e_1$; $\ldots$; $e_n$|]!
    has type of \code{Mutable_Array[$T$]}.
  \item Expression of the form ~\lstinline!%w[|word word2 wordx|]!
    has type of \code{Mutable_Array[String]}, and respectively for the other flags, where $T$ is \code{String} (\code{Aml/Language.String}). 
\end{itemize}






\subsection{Dictionary Expressions}
\label{sec:dict-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | Dictionary_Expr
Dictionary_Expr 
    ::= '%' Dict_Flags '{' [Dict_Mapping1 {semi Dict_Mapping1}] '}'
      | '%' Dict_Flags '{' [Dict_Mapping2 {semi Dict_Mapping2}] '}'
Dict_Mapping1
    ::= Expr '=>' Expr
Dict_Mapping2 
    ::= ['~'] id ':' Expr
Dict_Flags
    ::= [['i' |  (* immutable *)
          'm']   (* mutable *)
         ['l']]  (* linked *)
\end{lstlisting}

An expression of the form ~\lstinline!%{$e_1$; $\ldots$; $e_n$}! is a dictionary expression. 

\begin{itemize}
  \item Expression of the form ~\lstinline!%{$e_1$; $\ldots$; $e_n$}!
    has type of \code{Hash_Dictionary[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%i{$e_1$; $\ldots$; $e_n$}!
    has also type of \code{Hash_Dictionary[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%m{$e_1$; $\ldots$; $e_n$}!
    has type of \code{Mutable_Hash_Dictionary[$K$, $T$]}.
  \item Expression of the form ~\lstinline!%l{$e_1$; $\ldots$; $e_n$}!
    has type of \code{Linked_Hash_Dictionary[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%il{$e_1$; $\ldots$; $e_n$}!
    has type of \code{Linked_Hash_Dictionary[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%ml{$e_1$; $\ldots$; $e_n$}!
    has also type of \code{Linked_Hash_Dictionary[$K$, $T$]}.
  \item Expression of the form ~\lstinline!%ml{$e_1$; $\ldots$; $e_n$}!
    has type of \code{Mutable_Linked_Hash_Dictionary[$K$, $T$]}.
  \item Dictionary expression that uses the \code{Dict_Mapping1} syntax category to define its elements has $K$ of \code{Symbol} (\code{Aml/Language.Symbol}). 
\end{itemize}





\subsection{Multimap Expressions}
\label{sec:multimap-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | Multimap_Expr
Multimap_Expr 
    ::= '%' Dict_Flags '{{' [Dict_Mapping1 {semi Dict_Mapping1}] '}}'
      | '%' Dict_Flags '{{' [Dict_Mapping2 {semi Dict_Mapping2}] '}}'
\end{lstlisting}

An expression of the form ~\lstinline!%{{$e_1$; $\ldots$; $e_n$}}! is a multimap expression. 

\begin{itemize}
  \item Expression of the form ~\lstinline!%{{$e_1$; $\ldots$; $e_n$}}!
    has type of \code{Hash_Multimap[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%i{{$e_1$; $\ldots$; $e_n$}}!
    has also type of \code{Hash_Multimap[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%m{{$e_1$; $\ldots$; $e_n$}}!
    has type of \code{Mutable_Hash_Multimap[$K$, $T$]}.
  \item Expression of the form ~\lstinline!%l{{$e_1$; $\ldots$; $e_n$}}!
    has type of \code{Linked_Hash_Multimap[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%il{{$e_1$; $\ldots$; $e_n$}}!
    has also type of \code{Linked_Hash_Multimap[$K$, $T$]}. 
  \item Expression of the form ~\lstinline!%ml{{$e_1$; $\ldots$; $e_n$}}!
    has type of \code{Mutable_Linked_Hash_Multimap[$K$, $T$]}.
  \item Multimap expression that uses the \code{Dict_Mapping1} syntax category to define its elements has $K$ of \code{Symbol} (\code{Aml/Language.Symbol}). 
\end{itemize}






\subsection{Bag Expressions}
\label{sec:bag-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | Bag_Expr
Bag_Expr
    ::= '%' Bag_Flags '(' [Expr {semi Expr}] ')'
Bag_Flags
    ::= [['i' |  (* immutable *)
          'm']   (* mutable *)
         ['l']   (* linked *)
         ['s']]  (* set instead of bag (tally-less bag) *)
\end{lstlisting}

An expression of the form ~\lstinline!%($e_1$; $\ldots$; $e_n$)! is a bag expression. 

\begin{itemize}
  \item Expression of the form ~\lstinline!%($e_1$; $\ldots$; $e_n$)!
    has type of \code{Hash_Bag[$T$]}. 
  \item Expression of the form ~\lstinline!%i($e_1$; $\ldots$; $e_n$)!
    has also type of \code{Hash_Bag[$T$]}. 
  \item Expression of the form ~\lstinline!%m($e_1$; $\ldots$; $e_n$)!
    has type of \code{Mutable_Hash_Bag[$T$]}.
  \item Expression of the form ~\lstinline!%l($e_1$; $\ldots$; $e_n$)!
    has type of \code{Linked_Hash_Bag[$T$]}. 
  \item Expression of the form ~\lstinline!%il($e_1$; $\ldots$; $e_n$)!
    has type of \code{Linked_Hash_Bag[$T$]}. 
  \item Expression of the form ~\lstinline!%ml($e_1$; $\ldots$; $e_n$)!
    has type of \code{Mutable_Linked_Hash_Bag[$T$]}.
  \item Expression of the form ~\lstinline!%s($e_1$; $\ldots$; $e_n$)!
    has type of \code{Hash_Set[$T$]}. 
  \item Expression of the form ~\lstinline[deletekeywords={is}]!%is($e_1$; $\ldots$; $e_n$)!
    has also type of \code{Hash_Set[$T$]}. 
  \item Expression of the form ~\lstinline!%ms($e_1$; $\ldots$; $e_n$)!
    has type of \code{Mutable_Hash_Set[$T$]}.
  \item Expression of the form ~\lstinline!%ls($e_1$; $\ldots$; $e_n$)!
    has type of \code{Linked_Hash_Set[$T$]}. 
  \item Expression of the form ~\lstinline!%ils($e_1$; $\ldots$; $e_n$)!
    has type of \code{Linked_Hash_Set[$T$]}. 
  \item Expression of the form ~\lstinline!%mls($e_1$; $\ldots$; $e_n$)!
    has type of \code{Mutable_Linked_Hash_Set[$T$]}.
\end{itemize}





\subsection{Polymorphic Variant Expressions}
\label{sec:polymorphic-variant-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | Tag_Name Expr
\end{lstlisting}

The expression ~\lstinline!`$\id$ $e$! evaluates to the polymorphic variant value whose tag is $\id$, and whose argument is the value of evaluated expression $e$. 





\subsection{Record Expressions}
\label{sec:record-expressions}

\grammar\begin{lstlisting}
Simple_Expr
    ::= ...
      | Record_Expr
Record_Expr 
    ::= 'record' [nl] '{' [nl] Record_Fields_Init [nl] '}'
Record_Fields_Init
    ::= Record_Field_Init {semi Record_Field_Init}
Record_Field_Init
    ::= Stable_Id [':' Type_Expr] '=' Expr
\end{lstlisting}

An expression of the form
\begin{lstlisting}
record { $i_1$ = $e_1$; $\ldots$; $i_n$ = $e_n$ }
\end{lstlisting}
is a record expression. 






\subsection{Record Clone Expressions}
\label{sec:record-clone-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | Record_Clone_Expr
Record_Clone_Expr
    ::= 'record' [nl] 
        '{' [nl] Expr 'with' Record_Fields_Clone [nl] '}'
Record_Fields_Clone 
    ::= Record_Field_Clone {semi Record_Field_Clone}
Record_Field_Clone 
    ::= Stable_Id [':' Type_Expr] ['=' Expr]
\end{lstlisting}

An expression of the form
\begin{lstlisting}
record { $e$ with $i_1$ = $e_1$; $\ldots$; $i_n$ = $e_n$ }
\end{lstlisting}
is a record clone expression. 





\subsection{Object Clone Expressions}
\label{sec:object-clone-expressions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | Object_Clone_Expr
Object_Clone_Expr 
    ::= '{<' Object_Ivars_Init '>}'
Object_Ivars_Init 
    ::= Object_Ivar_Init {semi Object_Ivar_Init}
Object_Ivar_Init
    ::= id ['=' Expr]
\end{lstlisting}

An expression of the form
\begin{lstlisting}
{< $i_1$ = $e_1$; $\ldots$; $i_n$ = $e_n$ >}
\end{lstlisting}
is an object clone expression. 





\subsection{Delayed Expressions}
\label{sec:delayed-expressions}

\grammar\begin{lstlisting}
Expr 
    ::= ...
      | Delayed_Expr
Delayed_Expr 
    ::= 'lazy' [nl] Expr
\end{lstlisting}

Delayed expressions of the form ~\lstinline!lazy $e$!~ are a syntax sugar for:
\begin{lstlisting}[deletekeywords={new}]
Aml/Language.Lazy.new(fun () -> $e$)
\end{lstlisting}

The \code{Aml/Language.Lazy} instance is not automatically unboxed, unlike lazy value or variable definitions. It is an error to define a lazy value or variable with a delayed expression, as that would be only redundant. The delayed expression is evaluated by sending the instance a ``\code{value}'' message\footnote{This is the behaviour of call-by-need parameters.}, or by using the prefix operator ``\lstinline@!@''. The delayed expression is force re-evaluated by sending the instance a ``\code{value!}'' message, overwriting any previous value\footnote{This is the behaviour of call-by-name parameters.}, or by using the prefix operator ``\lstinline@!!@'', with the same side-effect. 






\subsection{Ref Expressions}
\label{sec:ref-expressions}

\grammar\begin{lstlisting}
Ref_Expr ::= 'ref' [nl] Expr
\end{lstlisting}

Ref expressions of the form ~\lstinline!ref $e$!~ are a syntax sugar for:
\begin{lstlisting}[deletekeywords={new}]
Aml/Language.Reference_Cell.new ($e$)
\end{lstlisting}

The \code{Aml/Language.Reference_Cell} instance is not automatically unboxed. The contained value can be retrieved from a reference cell using the prefix operator ``\lstinline@!@''\footnote{This operator is not used in the meaning of \code{not}, because accidentally overlooking it does not invert the value that it's applied to.}, or by sending the instance a ``\code{value}'' message. The contained value can be overwritten by using the infix operator ``\lstinline!<-!'', or by sending the instance a ``\code{set_value}'' message. 

Reference cells are lightweight instances that can be used to simulate output parameters at low costs, in both CPU cycles and the language design.

\example An example of how to manipulate reference cells. 
\begin{lstlisting}
(* initialize a reference cell *)
let a = ref 42
let b = Aml/Language.Reference_Cell.new (42)
let c = new Aml/Language.Reference_Cell (42)

(* retrieve contained value from reference cell *)
let d = !a
let e = a.value

(* change the value the reference cell contains *)
a <- 64
a.value := 128
\end{lstlisting}





\subsection{Arguments Expressions}
\label{sec:arguments-expressions}

\grammar\begin{lstlisting}
Args_Expr 
    ::= 'arguments' [nl] '{' Arguments [Block_Argument] '}' 
      | 'arguments' [nl] '{' Block_Argument '}'
\end{lstlisting}

Arguments expressions of the form ~\lstinline!arguments $a_1 \ldots a_n$!~ generate a special value, which is equivalent to what is passed as arguments in function applications. A value $x$ generated with this expression can be used in a function application using ``\,\lstinline!**$x$!\,''. The type of such expression is a tuple with each element representing one argument, where the argument itself may again be a tuple (or any other value). 





\subsection{Message Data Expression}
\label{sec:message-data-expression}

\grammar\begin{lstlisting}
Message_Data_Expr
    ::= 'message' '{' Expr '}' 'with' Args_Expr
      | 'message' symbol_literal 'with' Args_Expr
      | Args_Expr
\end{lstlisting}

A value $x$ generated with this expression can be used to send an object a message using e.g. ``\,\lstinline!obj.'send $x$!\,''. In the first form, the expression is typed with expected type of \code{Symbol}. 





\subsection{Workflows}
\label{sec:workflows}

\grammar\begin{lstlisting}[deletekeywords={is,with,or,is,and}]
Workflow_Expr          ::= Expr '{' Workflow_or_Range_Expr '}'
Workflow_or_Range_Expr ::= Workflow | Short_Workflow | Range_Expr

Workflow ::= 'let!' Let_Binding semi Workflow
           | ['implicit'] Val_Dcl In_Sep Workflow ['end']
           | ['implicit'] Var_Dcl In_Sep Workflow ['end']
           | ['implicit'] Val_Def In_Sep Workflow ['end']
           | ['implicit'] Var_Def In_Sep Workflow ['end']
           | ['implicit'] Op_Dcl In_Sep Workflow ['end']
           | ['implicit'] Op_Def In_Sep Workflow ['end']
           | ['implicit'] Multi_Op_Dcl In_Sep Workflow ['end']
           | ['implicit'] Multi_Op_Def In_Sep Workflow ['end']
           | {Local_Modifier} Tmpl_Def In_Sep Workflow ['end']
           | Struct_Def In_Sep Workflow ['end']
           
             (* because Do_Binding can't be the last element of a workflow: *)
           | 'do' Expr In_Sep Workflow ['done'] 
           | 'do!' Expr In_Sep Workflow ['done']
           
           | 'use!' [Storage_Modifier] Let_Binding In_Sep Workflow ['end']
           | 'use' [Storage_Modifier] Let_Binding In_Sep Workflow ['end']
           | 'yield!' Expr
           | Yield_Expr
           | 'return!' Expr
           | Return_Expr
           
           | 'if' Wf_Condition ('then' | semi) Workflow
             {[semi] 'elsif' Wf_Condition ('then' | semi) Workflow} 
             [[semi] Else Workflow] 'end' ['if']
           | 'unless' Wf_Condition ('then' | semi) Workflow
             {[semi] 'elsif' Wf_Condition ('then' | semi) Workflow} 
             [[semi] Else Workflow] 'end' ['unless']
             
           | ? Match_Expr where Expr is extended with Workflow ?
           | ? Switch_Expr where Expr is extended with Workflow ?
           | ? Catch_Expr or Rescue_Expr, where initial Expr, 
               Handle_Block, Catch_Block and Rescue_Block are extended with Workflow ?
           
           | 'for' Val_Dcls 'in' ['reverse'] Expr
             ['step' Expr] Wf_For_Loop
           | ('while' | 'until') Condition Wf_For_Loop
           | 'for' id '=' Expr ('to' | 'downto') Expr Wf_For_Loop
           | Workflow ('while' | 'until') Condition
           
           | Workflow semi Workflow
           | Annot_Workflow
           | Expr

Annot_Workflow ::= {Annotation}+ Workflow           
Short_Workflow ::= 'for' Generator_Expr
                 | [Label_Dcl] 'for' Val_Dcls 'in' Expr 
                   ['step' Expr] Wf_For_Loop

Wf_For_Loop    ::= 'loop' Wf_Loop_Block 'end' ['loop']
                 | 'do' Wf_Loop_Block 'done'
Wf_Loop_Block  ::= Workflow + Loop_Ctrl_Expr
Wf_Condition   ::= Workflow - Conditional_Expr
\end{lstlisting}

% TODO: finish Workflow, continue with loop, while, for
% TODO: finish the definitions




\subsection{Collection Comprehensions}
\label{sec:collection-comprehensions}

\grammar\begin{lstlisting}
List_Literal       ::= '%' [CF] '['  Collection_Gen  ']'
Array_Literal      ::= '%' [CF] '[|' Collection_Gen '|]'
Dictionary_Literal ::= '%' [CF] '{'  Collection_Gen  '}'
Bag_Literal        ::= '%' [CF] '('  Collection_Gen  ')'
Collection_Gen     ::= (Workflow_Expr | Expr) ['in' Range_Expr]
                     | Short_Workflow
                     | Range_Expr
\end{lstlisting}

Collection comprehensions extend the syntax of collection ``literals''\footnote{Pure literals are terminal symbols in the language, but collection literals are wrappers around virtually any expression.}, so that collections may be defined not by their explicit values, but by a function that generates them -- and that function is a generator. Only tuple literals don't have collection comprehension, due to their special nature within the language. 

Note that the generator expression for dictionary literal comprehension has to generate values of type ~\lstinline!($K$, $E$)!, where $K$ is the type of the keys and $E$ is the type of mapped values, or, if the actual dictionary type defines its own entry type, values that are members of the entry type. 

If the \code{Workflow_Expr} inside the collection literal uses \code{Seq_Literal} or similar on-demand computations, the collection literal value is also a cache for its results. 

If the expression that generates values would create an infinite collection, the \code{in Range_Expr} specification can be used to constrain the generated values to the given range. 

% TBD: define traits/annotations like "literal-convertible", "collection-literal" and "collection-literal-builder", so that generators may produce different values and those will be inserted into the collection from the literal without the extra allocation for system-defined literal type; convert either from the system-defined literal type, or use update() for dictionaries and add() for lists, arrays, bags/sets. Also add a trait/annotation that will define that this is not needed for when the type is a system-provided type. 





\subsection{Sequence Comprehensions}
\label{sec:sequence-comprehensions}

\grammar\begin{lstlisting}
Collection_Literal ::= Seq_Literal
Eagerness          ::= ['eager' | 'lazy']
Seq                ::= Eagerness 'seq'
Seq_Literal        ::= Seq '{' Collection_Gen '}'
Collection_Literal ::= Seq_Literal
\end{lstlisting}

Apart from collection comprehensions (\sref{sec:collection-comprehensions}), Aml offers also sequence comprehensions. The crucial difference is in evaluation: collection comprehension trigger eager evaluation, unless indeed the used source collection does not employ lazy evaluation of some kind by itself. Sequence comprehension, on the other hand, is super-lazy. 

A sequence generated by the form ~\lstinline!seq { $e$ }!~ works like a forgetting enumerator -- it computes values using the expression $e$ only when they are required. This is most useful for very large sequences, and/or when the computation is expensive in some way. 

The expression $e$ may be of a few different kinds:
\begin{itemize}
  \item A \code{Range_Expr}, in which case the sequence is based on a given range, optionally including a \code{delta}, which then defines the increment between each value (and which can indeed be \code{1} or more, not limited to fractions of \code{1}). Such a sequence is {\em linear}, and its size is determinable without computing all the values. At most one bound can be infinity, in which case the size of the sequence is infinite. 
  \item A \code{Method_Expr}, in which case a function that accepts a key (or an index, if you wish) and computes the corresponding value. Such a sequence is {\em indexed}, but its size is undefined. 
  \item A workflow using \code{yield} and \code{yield!} to feed the sequence with a next value. Such a sequence is again {\em linear}, and its size is defined when all values are computed. 
\end{itemize}

In every case, a range may be optionally given to constrain the generated sequence. 

The Aml Standard Runtime Library offers more functions to manipulate and create sequences. 

A sequence comprehension expression ~\lstinline!seq { $e$ }!~ is equivalent to ~\lstinline!lazy seq { $e$ }!, whereas ~\lstinline!eager seq { $e$ }!~ is implicitly cached, but eagerly evaluated -- and thus can't use \code{Method_Expr}, because there is no known range of keys or indexes.






\subsection{Generator Expressions}
\label{sec:generator-expressions}

\grammar\begin{lstlisting}
Loop_Expr
    ::= ...
      'for' (Generator_Expr | Generator_Iter)
Generator_Iter 
    ::= '(' Enumerators ')' {nl} (Expr | For_Loop)
Yield 
    ::= 'yield' | 'yield!'
Generator_Expr 
    ::= '{' Enumerators '}' {nl} Yield Expr
Enumerators
    ::= Generator {semi Enumerator}
Enumerator
    ::= Generator [semi Atomic_Pattern '=' Expr]
      | Guard
Generator 
    ::= [Label_Dcl] Atomic_Pattern 'in' Expr [Guard]
Guard 
    ::= Cond_Modifier1
\end{lstlisting}

A {\em generator iteration} ~\lstinline!for ($\enums$) $e$!~ executes expression $e$ for each binding generated by the enumerators $\enums$ and as an expression, it is typed as \code{Unit}. A {\em generator expression} ~\lstinline!for {$\enums$} yield $e$!~ evaluates expression $e$ for each binding generated by the enumerators $\enums$ and collects the results.

An enumerator sequence always starts with a generator; this can be followed by further generators, value definitions or guards. A {\em generator} ~\lstinline!$p$ in $e$!~ produces bindings from an expression $e$, which are matched in some way against pattern $p$ (\sref{sec:pattern-matching}). A {\em value definition} ~\lstinline!$p$ = $e$!~ binds the value name $p$ (or several names in a pattern $p$) to the result of evaluating the expression $e$. A {\em guard} ~\lstinline!if $e$!~ (or ~\lstinline!unless $e$!) contains a boolean expression $e$, which restricts enumerated bindings. The precise meaning of generators and guards is defined by translation to invocations of four methods: \code{map}, \code{with_filter}, \code{flat_map} and \code{each}. These methods can be implemented in different ways for different carrier types.

The translation scheme is defined as follows. In a first step, every generator ~\lstinline!$p$ in $e$!, where $p$ is not irrefutable (\sref{sec:irrefutable-patterns}) for the type of $e$, is replaced by 
\begin{lstlisting}
$p$ in $e$.with_filter { when $p$ then yes otherwise no }
\end{lstlisting}

Then, the following rules are applied repeatedly, until all comprehensions are eliminated. 
\begin{itemize}

\item A comprehensioin 
\begin{lstlisting}
for {$p$ in $e$} yield $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.map { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension
\begin{lstlisting}
for {<<$l$>> $p$ in $e$} yield $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.map({ when $p$ then $e'$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehensioin 
\begin{lstlisting}
for {$p$ in $e$} yield! $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.flat_map { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension
\begin{lstlisting}
for {<<$l$>> $p$ in $e$} yield! $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.flat_map({ when $p$ then $e'$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 


\item A comprehension 
\begin{lstlisting}
for ($p$ in $e$) $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.each { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for (<<$l$>> $p$ in $e$) $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.each({ when $p$ then $e'$ }, label: $l$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehension 
\begin{lstlisting}
for {$p$ in $e$; $p'$ in $e'\ \ldots$} yield $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}
$e$.flat_map { when $p$ then for {$p'$ in $e'\ \ldots$ } yield $e''$ }
\end{lstlisting}
If there was \code{yield!} instead of \code{yield}, then \code{yield!} is also in the translated code. 

\item A comprehension 
\begin{lstlisting}
for {<<$l$>> $p$ in $e$; $p'$ in $e'\ \ldots$} yield $e''$
\end{lstlisting}
where $l$ is a label name, and where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.flat_map(
  { when $p$ then for {$p'$ in $e'\ \ldots$ } yield $e''$ },
  label: $l$
)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. If there was \code{yield!} instead of \code{yield}, then \code{yield!} is also in the translated code. 

\item A comprehension 
\begin{lstlisting}
for ($p$ in $e$; $p'$ in $e'\ \ldots$) $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}
$e$.each { when $p$ then for ($p'$ in $e'\ \ldots$) $e''$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for (<<$l$>> $p$ in $e$; $p'$ in $e'\ \ldots$) $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.each(
  { when $p$ then for ($p'$ in $e'\ \ldots$) $e''$ },
  label: $l$
)
\end{lstlisting}

\item A generator ~\lstinline!$p$ in $e$!~ followed by a guard ~\lstinline!if $g$!~ is translated to a single generator
\begin{lstlisting}
$p$ in $e$.with_filter(fun ($x_1 \commadots x_n$) -> { $g$ })
\end{lstlisting}
where $x_1 \commadots x_n$ are the free variables of the pattern $p$. 

\item A generator ~\lstinline!$p$ in $e$!~ followed by a guard ~\lstinline!unless $g$!~ is translated to a single generator
\begin{lstlisting}
$p$ in $e$.with_filter(fun ($x_1 \commadots x_n$) -> { not $g$ })
\end{lstlisting}
where $x_1 \commadots x_n$ are the free variables of the pattern $p$. 

\item A generator ~\lstinline!$p$ in $e$!~ followed by a definition ~\lstinline!$p'$ = $e'$!~ is translated to the following generator of pairs of values, where $x$ and $x'$ are fresh names:
\begin{lstlisting}
($p$, $p'$) in for {$p$ as $x$ in $e$} yield { let $p'$ as $x'$ = $e'$ in ($x$, $x'$) }
\end{lstlisting}

\end{itemize}

Generators in generator expression can optionally have a label $l$ assigned, so that expressions like ~\lstinline!break $l$!~ could work.\footnote{It is up to the concrete method how it handles the invocation, which uses \code{throw}-\code{catch} expressions -- however, ignoring it may result in an uncaught \code{Throwable} killing the thread.} Like with other loop expressions, if an \code{exhausted} or a \code{broken} loop control expression is given in the generator iteration expression $e$, it is passed to the outermost \code{each} method as a named argument, possibly along the \code{label} argument. 

\example The following code produces all pairs of numbers between $1$ and $n - 1$, whose sums are prime numbers. 
\begin{lstlisting}
for { i in 1 .. n
      j in 1 .. i
      if is_prime? i + j
} yield (i, j)
\end{lstlisting}
The comprehension is translated to:
\begin{lstlisting}
(1 .. n).flat_map {
  when i then (1 .. i)
    .with_filter { j -> { is_prime? i + j } }
    .map { when j then (i, j) }
}
\end{lstlisting}

\example Generator expressions can be used to express vector and matrix algorithms concisely.
\begin{lstlisting}
method transpose['a] (xss: List[List['a]]): List[List['a]] =
  for {i in 0 .. xss(0).length} yield {
    for (xs in xss) yield xs(i)
  }
\end{lstlisting} 
The comprehension is translated to: 
\begin{lstlisting}
method transpose['a](xss: List[List['a]]): List[List['a]] = 
  (0 .. xss(0).length)
    .map { 
      when i 
        xss.map { when xs then xs(i) }
    }
\end{lstlisting}






\subsection{Anonymous Functions}
\label{sec:anonymous-functions}

\grammar\begin{lstlisting}
Function_Expr
    ::= {Value_Param_Clause '->'}+ Expr
      | 'fun' {Params_Clause}+ [Guard] [':' Type] '->' Expr
      | 'function' When_Clauses 'end' ['function']
\end{lstlisting}

The anonymous function ~\lstinline!($x_1$: $T_1 \commadots x_n$: $T_n$) -> { $b$ }!~ maps parameters $x_i$ of types $T_i$ to a result value given by evaluation of block $b$. The scope of each formal parameter $x_i$ is $e$. Formal parameters must have pairwise distinct names.\footnote{In future versions of Aml, a syntax where curly brackets are not required to be surrounding an anonymous function's body may be allowed.}

If the expected type of an anonymous function is of the form ~\lstinline!Function[$S_1 \commadots S_n$, $R$]!, the expected type of $b$ is $R$ and the type $T_i$ of any of the parameters $x_i$ can be omitted, in which case $T_i = S_i$ is assumed. If there is no expected type of the anonymous function, then for each parameter $x_i$ which has no explicit type $T_i$, $T_i$ is assumed to be \code{Object}, and the type of the result value is also assumed to be \code{Object}. 

Note that anonymous functions explicitly specify all of their parameters, unlike anonymous pattern matching functions (\sref{sec:pattern-matching-anon-fun}), where the parameters are inferred from the expected type. 

The anonymous function is evaluated as the following expression:
\begin{lstlisting}
(Function[$S_1 \commadots S_n$, $T$] with {
  def apply ($x_1$: $T_1 \commadots x_n$: $T_n$): $T$ = { $b$ }
}).new
\end{lstlisting}

In the case of a single untyped formal parameter, ~\lstinline!($x$) -> { $b$ }!~ can be abbreviated to ~\lstinline!$x$ -> { $b$ }!. If an anonymous function ~\lstinline!($x$: $T$) -> { $b$ }!~ with a single typed parameter appears as the result of expression of a block, it can be abbreviated to ~\lstinline!$x$: $T$ -> { $b$ }!.

A formal parameter may also be a wildcard represented by an underscore ``\lstinline!_!''. In that case, a fresh name for the parameter is chosen arbitrarily. 

A parameter of an anonymous function may optionally be preceded by an \code{implicit} modifier. In that case the parameter is labeled \code{implicit} (\sref{sec:implicit-params-views}); however the parameter section itself does not count as an implicit parameter section in the sense of (\sref{sec:implicit-parameters}). Such a parameter ~\lstinline!implicit $x_i$!~ is then added transparently to the block $b$ as ~\lstinline!implicit val $y_i$ = $x_i$!, where $y_i$ is a fresh name. Also, therefore arguments to anonymous functions always have to be given explicitly. 

\example Examples of anonymous functions:
\begin{lstlisting}[mathescape=false]
(* identity function *)
x -> x

(* curried function composition *)
f -> g -> x -> f(g(x))

(* or a bit shorter *)
fun f g x -> f(g x)

(* a summation function *)
fun (x: Integer) (y: Integer) -> x + y

(* a function which takes an empty parameter list,
   increments a non-local variable (via closure)
   and returns the new value *)
() -> { count += 1; count }

(* a function that ignores its argument and returns 5 *)
_ -> 5 
\end{lstlisting}





\subsubsection{Placeholder Syntax for Anonymous Functions}
\label{sec:placeholder-functions}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | impl_par
\end{lstlisting}

An expression (\code{Expr}) may contain embedded percent symbols ``\lstinline!%!'' followed by a number at places where identifiers are legal. Such an expression represents an anonymous function, where each numbered percent symbol denotes the corresponding positional parameter, and the zero-numbered symbol denotes the anonymous function itself.\footnote{This is different from Scala where the parameters are referenced with an underscore and not numbered -- they are successive.}

Define an {\em anonymous section} to be an expression of the form ~\lstinline!%$n$ as $T$!, where $T$ is a type, or else of the form ~\lstinline!%$n$!, provided that the percent symbol does not appear as the expression part of a typed expression. 

An expression $e$ of syntactic category \code{Expr} {\em binds} an anonymous section $u$, if the following conditions hold:
\begin{enumerate}
  \item $e$ properly contains $u$
  \item there is no other expression of syntactic category \code{Expr} which is properly contained in $e$ and which itself properly contains $u$
\end{enumerate}

If an expression $e$ binds anonymous sections $u_1 \commadots u_n$, in order specified by the numbering (and with blanks in between filled by a fresh $u_i$), it is equivalent to the anonymous ~\lstinline!($u'_1$) -> $\ldots$ -> ($u'_n$) -> $e'$!, where each $u'_i$ results from $u_i$ by replacing the percent symbol with a fresh identifier and $e'$ results from $e$ by replacing each $u_i$ with $u'_i$. If $u_i$ was a part of a typed expression, the corresponding parameter is typed the same and the $u'_i$ in $e$ does not need to be typed anymore. 

\example The anonymous functions in the left column use placeholder syntax. Each of these is equivalent to the anonymous function to its right. 
\begin{lstlisting}
%1                          x -> x
%1 + 1                      x -> x + 1
%1 * %2                     x -> y -> x * y
(%1 as Integer) * 2         (x: Integer) -> x * 2
if %1 then x else y end     (z: Boolean) -> if z then x else y end
%1.map f                    x -> x.map f
%1.map (%1 + 1)             x -> x.map (y -> y + 1)
\end{lstlisting} 






\section{Application Expressions}







\subsection{Designator Expressions}
\label{sec:designators}

\grammar\begin{lstlisting}
Simple_Expr
    ::= ...
      | Path
      | Expr '.' Selection
      | [Expr '.'] Dynamic_Var_Selection
Selection 
    ::= Simple_Selection
      | Tuple_Selection
      | Optional_Selection
      | Forced_Selection
Simple_Selection 
    ::= id
Tuple_Selection
    ::= decimal_numeral
Optional_Selection 
    ::= '?' (Simple_Selection | Tuple_Selection)
Forced_Selection
    ::= '!' (Simple_Selection | Tuple_Selection)
Dynamic_Var_Selection
    ::= ('@' | '@@') '{' Expr '}'
\end{lstlisting}

A designator refers to a named term. It can be a {\em simple name} or a {\em selection}.

A simple name $x$ refers to a value as specified in (\sref{sec:identifiers-names-scopes}). If $x$ is bound by a definition or a declaration in an enclosing class or object $C$, it is taken to be equivalent (at the resolution time) to the selection ~\lstinline!$C$.self.$x$!, where $C$ is taken to refer to the class or object containing $x$, even if the type name $C$ is shadowed at the occurrence of $x$. 

If $r$ is a stable identifier (\sref{sec:type-paths}) of type $T$, the selection ~\lstinline!$r$.$x$!~ refers to a member $m$ of $r$ that is identified in $T$ by the name $x$. 

For other expressions $e$, ~\lstinline!$e$.$x$!~ is typed as if it was ~\lstinline!{ val $y$ = $e$ in $y$.$x$ }!, for some fresh name $y$. 

The selection ~\lstinline!$e$.?$x$!~ is typed as if it was 
\begin{lstlisting}
{ if let? $y$ = $e$  (* optional binding *)
  then $y$.$x$ 
  else nil 
  end }
\end{lstlisting}
for some fresh name $y$; also called {\em safe navigation} or {\em safe selection}. Works with weak references as well. 

The expected type of a designator's prefix is undefined. The type of a designator is the type $T$ of the entity it refers to. 

The selection ~\lstinline!$e$.$x$!~ is evaluated by first evaluating the qualifier expression $e$, which yields an object $r$. The selection's result is then the member $m$ of $r$ that is either defined by $m$ or defined by a definition overriding $m$. 

A selection ~\lstinline!$e$.$x$!, where $x$ is formed by decimal digits, is useful for selecting members whose name is a decimal number. Tuple types have such members, and other types may define such members by enclosing their names in doubled backquotes, e.g. ~\lstinline!method ``1`` () = 1!. The expression $e$ must not be a number literal. 

A selection ~\lstinline!$e$.$x$!, where $x$ is of the form ~\lstinline!@$a$!, is an instance value or variable selection; and where $x$ is of the form ~\lstinline!@@$a$!, the selection is a class instance value or variable selection, a shorthand for the selection ~\lstinline[deletekeywords={class}]!$e$.'class.@$x$!.\footnote{The ``\,\lstinline[deletekeywords={class}]!.'class!\,'' syntax construct is attribute selection (\sref{sec:attribute-selection}).}

A designator of the form ~\lstinline!@$x$!~ is an instance value or variable selection, a shorthand for ~\lstinline!self.@$x$!. A designator of the form ~\lstinline!@@$x$!~ is a class instance value or variable selection, a shorthand for ~\lstinline[deletekeywords={class}]!self.'class.@$x$!. 

\example Instance value or variable selections. 
\begin{lstlisting}[deletekeywords={class}]
obj.@ivar

obj.@@cvar 
(* same as: *)
obj.'class.@cvar

@ivar
(* same as: *)
self.@ivar

@@cvar
(* same as: *)
self.'class.@cvar

(* dynamic ivar selection *)
obj.@{expr}

(* dynamic cvar selection *)
obj.@@{expr}
\end{lstlisting}

The distinctive form in which instance and class instance value or variable selections appears practically means that objects have separate namespaces\footnote{Therefore names of instance values or variables never clash with names of other members of the instance.} for their instance variables (state) and all other members (methods, nested classes etc.). 





\subsection{Self, This, Super \& Outer}
\label{sec:self-this-super}

\grammar\begin{lstlisting}
Simple_Expr 
    ::= ...
      | [id '.'] 'self' ['.' Selection]
      | [id '.'] 'this' '.' Selection
      | [id '.'] 'super' [Class_Qualifier] ['.' Selection]
      | 'outer' Class_Qualifier '.' 'self' ['.' Selection]
      | 'outer' Class_Qualifier '.' 'this' '.' Selection
\end{lstlisting}

The expression \code{self} stands always for the current instance in the context (and in function resolution searches in the actual class of the instance) in the innermost template containing the reference (thus excluding blocks and anonymous functions). 

The expression \code{this} is the same as \code{self}, except that function resolution searches from the class that this expression appears in, possibly skipping overrides in subtypes of the actual class of \code{self}, and continues as usual up the inheritance chain. The \code{this} expression is interchangeable with \code{self} in the following paragraphs, although use of \code{self} is preferred. 

The expression ~\lstinline!$C$.self!~ refers to the current instance in the context of the enclosing (or even directly enclosing) type $C$. It is an error if $C$ is not an enclosing type. The type of the expression is the same as ~\lstinline!$C$.self.type!. 

A reference ~\lstinline!super.$m$!~ refers to a method or type $m$ in the least proper supertype of the innermost template containing the reference. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

A reference ~\lstinline!$C$.super.$m$!~ refers to a method or type $m$ in the least proper supertype of the innermost class or object definition named $C$, which encloses the reference. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

The \code{super} prefix may be followed by a qualifier ~\lstinline![$T$]!, as in ~\lstinline!$C$.super[$T$].$m$!. In this case, the reference is to the type or method $m$ in the parent class or trait of $C$, whose simple name is $T$. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

The expression ~\lstinline!outer[$T$]!~ refers to the current instance in the context of enclosing (or even directly enclosing) type $T$. It is an error if $T$ is not an enclosing type. The type of the expression is the same as ~\lstinline!outer[$T$].type!. 

Class qualifier may be a simple name referring to name of an enclosing type or supertype (depending on the preceding keyword: \code{outer} or \code{super}), or---if there is no type of such name or the qualifier is not a simple name---a stable id referring to the enclosing type or supertype. The latter case is useful in cases when there are multiple enclosing types or supertypes of the same simple name. Class qualifiers are evaluated at compile time, but, when the slow path of stable id is taken, it may refer to a lazily imported type name. It is obviously an error if the slow path is taken, no name is found during compilation and there are no lazy imports in the scope, or no name is found using the lazy import. 





\subsection{Use Expressions}
\label{sec:use-expressions}

\grammar\begin{lstlisting}
Use_Expr 
    ::= Use_Expr_As 
      | Use_Aspect
      | Use_Refinement
      | Use_Droppable
      | Use_Clause [Do_Block | In_Sep Expr ['end']]
Use_Expr_As 
    ::= 'use' Expr ('as' | 'as!' | 'as?')
        [['var' | 'val'] id ':'] Type [Do_Block | In_Sep Expr ['end']]
Use_Aspect
    ::= 'use' 'aspect' Stable_Id [Do_Block | In_Sep Expr ['end']]
Use_Refinement 
    ::= 'use' 'refinement' Stable_Id [Do_Block | In_Sep Expr ['end']]
Use_Droppable 
    ::= 'use' [Storage_Modifier] Let_Binding In_Sep Expr ['end']
\end{lstlisting}

Use expressions of the form ~\lstinline!use $e$ as $T$!~ are similar to typed expressions (\sref{sec:typed-expressions}). Their intention is to rebind an expression to a specific type (changing its expected type), and then either have this type to be effective in the same scope from that point onward, or, if a \code{Block_Expr} is syntactically given, only in the scope of that block expression. If a block is given, then the return value of the block is the value of this expression, otherwise, the value retrieved by evaluation of \code{Simple_Expr} is the value of this expression. Conversions described in typed expressions (\sref{sec:typed-expressions}) apply in these expressions as well, including the differences between \code{as} and ~\lstinline@as!@. 

Use expressions of the forms ~\lstinline!use $e$ as val $v$: $T$!~ and ~\lstinline!use $e$ as var $v$: $T$!~ rebind the evaluated expression $e$ to a value or variable named $v$, typed with type $T$. The \code{val} and \code{var} parts are optional -- and \code{val} is implied. 

Use expressions of the form ~\lstinline!use aspect $T$!~ enable the specified aspect, either in the scope defined by the given block, or if no block is given, then from that point onward, up to the scope end. If the expression is used as a template statement, then the aspect is enabled for the whole template anywhere, unless it has the block part. 

Use expressions of the form ~\lstinline!use refinement $T$!~ enable the specified refinement, either in the scope defined by the given block, or if no block is given, then from that point onward, up to the scope end. If the expression is used as a template statement, then the refinement is enabled for the whole template anywhere, unless it has the block part.

Use expressions of the form ~\lstinline!use $v$ = $a$ in $e$!~ are droppable expressions -- on every value $v_i$ bound in variable sub-patterns of $v$\footnote{Or, if $v$ is a variable pattern, than the value bound from such pattern.} has \code{$v_i$.drop()} sent to them right after evaluation of the expression $e$ ends (or \code{drop($v_i$)}, in case the type of $v_i$ does not implement \code{Droppable} and such function exists in the scope). The exact behaviour of that application is obviously defined by the implementation of such method.\footnote{Usually, such value should be considered unusable.}







\subsection{Function Applications}
\label{sec:function-applications}

\grammar\begin{lstlisting}[deletekeywords={no}]
Expr
    ::= ...
      | Application_Expr
Application_Expr 
    ::= Regular_Precedence_Application_Expr 
      | High_Precedence_Application_Expr
      | Op_Application_Expr
Regular_Precedence_Application_Expr
    ::= Expr Arguments [Block_Expr2 | Method_Expr]
      | 'super' [Arguments] [Block_Expr2 | Method_Expr]
High_Precedence_Application_Expr
    ::= Expr [Block_Argument]
      | Expr '.' '(' [Arguments] ')' [Block_Argument]
      | 'super' [Block_Argument]
Arguments
    ::= {Argument}+
Argument
    ::= Positional_Argument
      | Labelled_Argument
Positional_Argument 
    ::= ['?' | '*' | '**'] Expr
      | Tuple_Argument
      | '(' Tuple_Argument ')'
      | Slice_Expr (* only when enclosed in parentheses or within Tuple_Argument *)
Labelled_Argument
    ::= ('~' | '~?') id ':' Expr
      |  '~'         id ':' Slice_Expr
      |  '~'         id ':' Tuple_Argument
      |  '~'         id ':' '(' Tuple_Argument ')'
      | ('~' | '~?') id
Tuple_Argument 
    ::= Positional_Tuple_Arguments [',' Named_Tuple_Arguments]
      | Named_Tuple_Arguments
Positional_Tuple_Arguments 
    ::= Positional_Tuple_Argument {',' Positional_Tuple_Argument}
Positional_Tuple_Argument 
    ::= ['?' | '...'] Expr
      | Slice_Expr (* only when enclosed in parentheses or within Tuple_Argument *)
Named_Tuple_Arguments
    ::= Named_Tuple_Argument {',' Named_Tuple_Argument}
Named_Tuple_Argument
    ::= Labelled_Argument
      | '~...' Expr
Block_Argument
    ::= Block_Expr
      | Method_Expr
\end{lstlisting}

A function application ~\lstinline!$f$($e_1 \ldots e_m$) $b$!~ applies the function $f$ to the argument expressions $e_1 \ldots e_m$ and passes the block expression $b$ (\sref{sec:blocks}) into it. If $f$ is of a value type, the application is taken to be equivalent to ~\lstinline!$f$.apply($e_1 \ldots e_m$)!, i.e. the application of an \code{apply} method defined by $f$. 

\paragraph{Note}
Target type expression (\sref{sec:target-type-expressions}) that start only with a dot ``\,\code{.}\,'' can't appear among arguments, unless the arguments are enclosed in parentheses, or the argument is preceded by a comma inside a tuple argument; due to resulting ambiguity between an argument expression and a chained function application or selection. This limitation can be solved by prefixing the target type expression with a dollar sign.\footnote{Which is still way shorter than having to explicitly type out the full target type name.}





\subsubsection{Compared to Other Languages}

\Aml has a sort of unusual definition of function applications, for an object-oriented language. The definition is unlike that of C or similar languages, which has arguments following the function always enclosed in parentheses. The parentheses are actually only necessary to resolve precedences. It is more similar to function applications of the ML family of languages, most similar to that of OCaml. The most prominent difference from OCaml is that OCaml does not have member overloading, while \Aml does have that. If \Aml did not have that overloading, all functions could be seen as functions of one or no parameters (procedures), possibly returning another function curried with the given argument. But \Aml does have overloading, and therefore the number of declared parameters of each overloaded variant actually matters a lot. 





\subsubsection{Total Function Application}

\Aml follows roughly OCaml's definition of function applications. A total application for \Aml is such an application that fills all required parameters with arguments. Required parameters are those that are not optional, variadic, block capture or implicit: positional and labelled. A total application may be evaluated, while non-total applications are implicitly curried using the remaining unfilled parameters, in their order of appearance. 







\subsubsection{Arguments to Parameters Mapping}

A single function application may contain one or more arguments. The mapping of arguments to parameters follows these rules, given that parameters are ordered as specified by their function definition:
\begin{itemize}
  \item Argument without a label (positional) is mapped to the next unfilled parameter. Such mapped parameter may be non-labelled as well as labelled, without total application making any difference.\footnote{This is different from OCaml.} If there is are no more unfilled parameters to map the argument to, the argument belongs to a consecutive function application, if any. 
  \item Argument with a label is mapped to the next unfilled parameter bearing the same label. If there are multiple such parameters, the first is the one mapped. Thus, the order of parameters matters. If there is no such parameter, the argument belongs to a consecutive function application, if any. The mapped-to parameter may be also optional, that does not make a difference -- it is only important when considering whether a function application is or is not total. 
  \item Arguments do not need to appear in the same order as their mapped parameters, which is what parameter/argument labels are for. 
  \item Arguments that have no label can not commute among themselves, their order matters. 
  \item Arguments that bear the same label and belong to the same function application (meaning, there are parameters these can be mapped to), they can not commute among themselves, because their order matters. Although they can commute with other arguments within the boundaries of the same function application. 
  \item Arguments are typed with the type of the parameter they are mapped to as their expected type. 
  \item Arguments that can not be mapped to parameters by the previous rules can be mapped to variadic parameter (or variadic parameters, if both are specified), defined by the function (see \sref{sec:variadic-parameters} for details). 
  \item If a function application is total, the function defines an implicit parameter and there is an unmapped argument available (possibly a tuple argument), that argument is mapped to the implicit parameter. 
  \item A function application that is not total, is implicitly curried on the remaining unfilled parameters. The resulting function is a function of all the remaining parameters in order specified by the function definition, preserving also their labels.\footnote{The part about preserved labels should be obvious.}
  \item Arguments are not evaluated, until that is specified by the evaluation strategy of the mapped parameter, at the point when the function is actually applied (which is after any overloading resolution happens). Some arguments might be already evaluated though, e.g. local variables. Early argument evaluations are possible, if needed in overloading resolution.\footnote{E.g., when the parameter's type is a constrained type, or type of the argument is \code{Dynamic}, but the parameter requires a specific type.} In fact, arguments are passed as if they were wrapped in nested parameterless functions (including their closure over any local variables and the \code{self} references). 
  \item Positional arguments that are prefixed with a ``\,\code{?}\,'' are not wrapped in \code{Option[$T$]} type, and are expected to already be of type \code{Option[$T$]}. This is useful especially inside tuple arguments, when an optional extraction does not specify a default value expression. 
  \item Labelled arguments that are prefixed with a ``\,\lstinline!~?!\,'' are also not wrapped in \lstinline!Option[$T$]! type, and are expected to already be of type \lstinline!Option[$T$]! as well.
  \item An argument may also comprise multiple sub-arguments, inside a tuple argument. In that case, positional sub-arguments must always come before named sub-arguments, as required by tuple expressions. 
  \begin{itemize}
    \item Additionally, the rules for arguments prefixed with a ``\,\code{?}\,'' apply. 
    \item Mapping of sub-arguments in a tuple argument is defined by tuple pattern matching (\sref{sec:tuple-patterns}). 
    \item No two sub-arguments inside a tuple argument can have the same label (does not apply to unlabelled sub-arguments). 
  \end{itemize}
  \item Arguments prefixed with a ``\,\code{*}\,'' are early evaluated, expected to result in a sequence, values are extracted from such a sequence and inserted in place of the argument, without labels, possibly spanning multiple function applications (unless used within a tuple argument). 
  \item Arguments prefixed with a ``\,\code{**}\,'' are early evaluated, expected to result in a dictionary from \code{Symbol} to any type, values are extracted from such a dictionary and inserted in place of the argument, with labels defined by each dictionary key, possibly spanning multiple function applications (unless used within a tuple argument). 
  \item Block argument is mapped to the block capture parameter, if any, otherwise made available only to \code{yield}. 
  \item Tuple argument's sub-arguments do not yield implicit currying. Explicit currying is possible though, see (\sref{sec:method-values}). 
  \item A labelled argument of the forms ~\lstinline!~$\id$!~ and ~\lstinline!~?$\id$!~ are referring to a local variable (usually parameter) and have the same label as is the name of the variable.
  \item Labelled arguments that do not specify either of the prefixes ``\,\lstinline!~!\,'' and ``\,\lstinline!~?!\,'', are implicitly prefixed with ``\,\lstinline!~!\,''. This is different from tuple expressions (\sref{sec:tuples}), where the explicitly written tilde prefix ``\,\lstinline!~!\,'' actually yields a slightly different data type. 
\end{itemize}





\subsubsection{Tail-call Optimizations}

A function application usually allocates a new stack frame on the program's runtime stack for the current thread. However, if at least one of the following conditions holds and function calls itself as its last action, the application is executed using the stack frame of the caller, replacing arguments and rewinding stack pointer to the first instruction, called {\em tail-call optimization}:
\begin{itemize}
  \item The function is local and not overloaded. 
  \item The function is \code{final}. 
  \item The function is \code{private} or ~\lstinline!private[self]!. 
  \item The function is annotated so that tail-call optimization is explicitly allowed. 
  \item A pragma allowing tail-call optimizations is effective in the scope of the tail call. 
\end{itemize}
The optimization will not happen if the application results in a different (possibly overloaded or overridden) variant of the caller function being applied, and a warning is issued if the tail-call optimization was explicitly expected (either via an annotation or a pragma). 





\subsubsection{Memoization}
\label{sec:memoization}

How to memoize a function's result is described in (\sref{sec:return-expressions}).

A memoized function's body is not evaluated, if it was once called with the same arguments (based on structural equality, not physical identity\footnote{Therefore, it is actually a good idea to memoize function's results based on arguments that have simple or physical structural equality.}), and if that result value is still memoized. If so, the memoized result value is immediately returned without evaluation of the function's body, which can speed up execution of some functions significantly. Such functions should however be referentially transparent in best-case scenario (\sref{sec:function-decls-defs} \& \sref{sec:statements}) or at least tolerant to being memoized. 

Memoization is better with small parameter numbers, so that searching the result values cache would not actually take longer than evaluation of the function's body. Functions that are defined with the \code{function} keyword (\sref{sec:function-decls-defs}) may opt-in to implicit memoization\footnote{E.g., based on the computed complexity of the function. If the function is decided to be simple, then memoization could actually worsen performance.}, as well as functions declared as \code{transparent} (\sref{sec:statements}). Functions declared as \code{opaque} (\sref{sec:statements}) should not be memoized. 

Parameters of memoization\footnote{Parameters include things like: cache policy, ttl, cache size and so on.} may be controlled, even on per-function basis, with use of specialized annotations and pragmas. 





\subsubsection{Application Shortcut}
\label{sec:function-application-shortcut}

A function application ~\lstinline!$f$.($e_1 \ldots e_m$) $b$!~ is a syntax sugar for a function application ~\lstinline!($f$())($e_1 \ldots e_m$) $b$!, which in turn is a shortcut for function application ~\lstinline!$f$().apply($e_1 \ldots e_m$) $b$!, as appropriate.\footnote{E.g. curried functions do not need any explicit \code{.apply()} applications, as these are implied, but would work anyway, therefore the second expanded form is equivalent to the first expanded form.}

This is especially useful for situations where a prefix appears to the function application and $f$ denotes a member that evaluates to a function, or maybe to a collection, but does not itself accept any arguments. 

A function application ~\lstinline!$p$.$f$.($e_1 \ldots e_m$) $b$!~ is a syntax sugar for a function application ~\lstinline!($p$.$f$)($e_1 \ldots e_m$) $b$!, which in turn is a shortcut for function application ~\lstinline!$p$.$f$().apply($e_1 \ldots e_m$) $b$!, where $p$ is some prefix expression. 






\subsubsection{Method Values \& Explicit Partial Applications}
\label{sec:method-values}

\grammar\begin{lstlisting}
Method_Expr ::= '&' Expr ['.' '(' Partially_Applied_Arguments ')']
                [Partially_Applied_Block_Argument]
              | '&(' Expr ['(' Partially_Applied_Arguments ')']
                [Partially_Applied_Block_Argument] ')'
              | '&(' Expr Partially_Applied_Arguments
                [Partially_Applied_Block_Argument2] ')'
              | '&(' (op_id | nary_op_id) ')' ['(' Partially_Applied_Arguments ')']
              | '&(' (op_id | nary_op_id) Partially_Applied_Arguments ')'
              | '(' op_id ')'
              | '(~' ? whitespace ? op_id ')'
Partially_Applied_Arguments
            ::= {Partially_Applied_Argument} 
Partially_Applied_Argument
            ::= Argument
              | Positional_Unapplied_Argument
              | Labelled_Unapplied_Argument
Positional_Unapplied_Argument
            ::= '_' ['as' Type]
              | Partially_Applied_Tuple_Argument
              | '(' Partially_Applied_Tuple_Argument ')'
Labelled_Unapplied_Argument
            ::= ('~' | '~?') id ':' '_' ['as' Type]
              |  '~'         id ':' Partial_Slice_Expr
              |  '~'         id ':' Partially_Applied_Tuple_Argument
              |  '~'         id ':' '(' [Partially_Applied_Tuple_Argument] ')'
Partially_Applied_Tuple_Argument
            ::= Positional_Partially_Applied_Tuple_Arguments 
                [',' Named_Partially_Applied_Tuple_Arguments]
              | Named_Partially_Applied_Tuple_Arguments
Positional_Partially_Applied_Tuple_Arguments 
            ::= Positional_Partially_Applied_Tuple_Argument
                {',' Positional_Partially_Applied_Tuple_Argument}
Positional_Partially_Applied_Tuple_Argument
            ::= Positional_Tuple_Argument
              | Positional_Unapplied_Argument
Named_Partially_Applied_Tuple_Arguments
            ::= Named_Partially_Applied_Tuple_Argument 
                {',' Named_Partially_Applied_Tuple_Argument}
Named_Partially_Applied_Tuple_Argument
            ::= Named_Tuple_Argument
              | Labelled_Unapplied_Argument
Partially_Applied_Block_Argument
            ::= Block_Argument
              | '&_' ['as' Type]
Partially_Applied_Block_Argument2
            ::= Block_Expr2
              | Method_Expr
              | '&_' ['as' Type]
Partial_Slice_Expr
            ::= Slice_Expr
              | '_' ['as' Type] ('..' | '..<') ['_' ['as' Type]]
              | ('..' | '..<') '_' ['as' Type]
\end{lstlisting}

The expression ~\lstinline!&$e$!~ (or alternatively ~\lstinline!&($e$)!) is well-formed if $e$ is of method type or if $e$ is a call-by-name parameter. If $e$ is a method with parameters, ~\lstinline!&$e$!~ represents $e$ converted to a function type by eta expansion (\sref{sec:eta-expansion}). If $e$ is a parameterless method or call-by-name parameter of type ~\lstinline!=> $T$!, ~\lstinline!&$e$!~ represents the function of type ~\lstinline!() -> $T$!, which evaluates $e$ when it is applied to the empty parameter list ~\lstinline!()!. 

\example The method values in the left column are each equivalent to the anonymous functions (\sref{sec:anonymous-functions}) on their right. 
\begin{lstlisting}[deletekeywords={range}]
&(Math.sin)             x -> { Math.sin x }
&(Array.range)          (x1, x2) -> { Array.range x1 x2 }
&(42.`*`)               x -> { 42 * x }
val vs = 1 .. 9 in &(vs.fold)
                        x1 -> x2 -> { vs.fold x1 x2 }
&((1 .. 9).fold z)      { let eta1 = z in
                          let eta2 = (1 .. 9) in
                          x -> eta2.fold eta1 x }
&((Some 1).fold `???`)  { let eta1 = fun () -> { `???` } in
                          let eta2 = Some 1 in
                          x -> { eta2.fold eta1 x } }
\end{lstlisting}

Note that if $e$ resolves to a parameterless method of type ~\lstinline!() -> $T$!~ or if $e$ has a method type ~\lstinline!() $\mapsto\ T$!, it is evaluated to type $T$ (\sref{sec:method-conversions}) -- and the method value syntax provides a way to prevent this. 

If $e$ resolves to an overloaded member, then the type of the expression is a type projection to that member, constrained to the matching alternatives. 

If $e$ contains sub-expressions of the forms ``\lstinline!_!'' or ``\lstinline!_ as $T$!'', called {\em argument placeholders}, then the method value contains only those overloaded alternatives that are applicable to the given sub-expressions, including the argument placeholders. Such an expression is then partially applied and resolves to an anonymous function, where the argument placeholders become parameters of the anonymous function. 





\subsubsection{Member Constraint Invocation Expressions}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Member_Constraint_Invocation_Expr
Member_Constraint_Invocation_Expr
    ::= '(' Type_Var ':' '(' Member_Signature ')' Arguments ')'
\end{lstlisting}





\subsection{Argument-Dependent Lookup in Scope}
\label{sec:adl-scope}

Argument-dependent lookup in scope is a mechanism that extends scope for unqualified name lookups (see \sref{sec:identifiers-names-scopes}) with all members of objects that belong to the argument-dependent scope, with priority lower than does not shadow already bound names in the scope (same as scope extension from type classes).  

The {\em argument-dependent scope} of a type $T$ consists of the type $T$ itself and all types, classes and class objects that are associated with the type $T$. Here, we say that a class or a type $C$ is {\em associated} with a type $T$, if it is a base class of some part of $T$, or it is one of the classes or structures that $T$ is nested in. The {\em parts} or a type $T$ are defined the same as for implicit scope (\sref{sec:implicit-parameters}). The argument-dependent scope is indeed possibly (and likely) broader than the implicit scope for the same type $T$. Overloading resolution may need to be used to determine a unique bound entity for the given name from the extended scope. 





\subsection{Attribute Selection Expressions}
\label{sec:attribute-selection}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Attribute_Expr
Attribute_Expr 
    ::= Expr '.'' Simple_Selection
\end{lstlisting}

Every function that has at least one parameter can be used as an attribute. 

An attribute selection ~\lstinline!$x$.'$a$!~ is then viewed as function application ~\lstinline!$a$($x$)!. An attribute selection ~\lstinline!$x$.'$a$($\args$)!~ is then viewed as function application ~\lstinline!$a$($x$)($\args$)!~ etc. (\sref{sec:function-applications}). 

\paragraph{Note}
Attribute selections are similar to function composition operators, but allow for a bit more concise code\footnote{Done by not requiring whitespace around the symbolic keyword, unlike whitespace being required around most infix operators.}, resembling designator selections (\sref{sec:designators}):
\begin{lstlisting}
let y = x.'a in
let z = x |> a in
y = z
\end{lstlisting}
The main difference between attribute selections and function compositions shows up when more arguments are needed or multiple functions are composed and attributes chained, compare: 
\begin{lstlisting}
{
  let y = x.'a(b) in    (* a(x)(b) *)
  let z = x |> a(b) in  (* a(b)(x) *)
  y /= z
}
\end{lstlisting}
\begin{lstlisting}
{
  let y = x.'a(b).'c(d) in      (* c(a(x)(b))(d) *)
  let z = x |> a(b) |> c(d) in  (* c(d)(a(b)(x)) *)
  y /= z
}
\end{lstlisting}





\subsection{Type Applications}
\label{sec:type-applications}

\grammar\begin{lstlisting}
Type_Application_Expr 
    ::= Expr Type_Args
\end{lstlisting}

A type application ~\lstinline!$e$[$T_1 \commadots T_n$]!~ instantiates a polymorphic value $e$ of type ~\lstinline![$a_1$ >: $L_1$ <: $U_1$ $\commadots$ $a_n$ >: $L_n$ <: $U_n$] $\mapsto\ S$!~ with argument types $T_1 \commadots T_n$. Every argument type $T_i$ must obey the corresponding bounds $L_i$ and $U_i$. That is, for each $i = 1 \commadots n$, we must have $\sigma L_i <: T_i <: \sigma U_i$, where $\sigma$ is the substitution $[a_1 \mapsto T_1 \commadots a_n \mapsto T_n]$. The type of the application is $\sigma S$. 

If the function part $e$ is of some value type, the type application is taken to be equivalent to ~\lstinline!$e$.apply[$T_1 \commadots T_n$]!, i.e. the application of an \code{apply} method defined by $e$. 

Type applications can be omitted if automatic type inference (\sref{sec:automatic-inference}) can infer best type arguments for a polymorphic function from the types of the actual function arguments and the expected result type. If any of the type arguments is specified as an underscore ``\code{_}'', it is locally inferred, therefore allowing for partially explicit type application, where the provided type arguments are taken as constant types. 





\subsection{Object Creation Expressions}
\label{sec:object-creation-exprs}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Object_Creation_Expr
Object_Creation_Expr 
    ::= 'new' Class_Parents 
      | 'new' [Immediate_Self_Ref] '{' [[Early_Defs] Class_Parents]
        [Do_Binding] 
        [Record_Extensions] '}'
Immediate_Self_Ref
    ::= '(' id ')'
\end{lstlisting}





\subsection{Blocks}
\label{sec:blocks}

\grammar\begin{lstlisting}
Block_Expr 
    ::= Block_Expr1 
      | Block_Expr2
Block_Expr1 
    ::= '{' [Block_Args] Expr '}'
Block_Expr2 
    ::= 'do' [Block_Args] Expr 'done'
Block_Args 
    ::= '|' [Params] '|' [':' Type [semi]]
Do_Block 
    ::= '{' Expr '}' 
      | 'do' Expr 'done'
Do_Binding 
    ::= 'do' Expr ['done']
\end{lstlisting}

A block expression ~\lstinline!{ $s_1$; $\ldots$; $s_n$; $e$ }!~ is constructed from a sequence of block statements $s_1 \commadots s_n$ and a final expression $e$. The statement sequence may not contain two definitions or declarations that bind the same name in the same namespace, except for local function definitions, which then create overloaded local function definitions (behaving pretty much like regular overloaded functions). The final expression may be omitted, in which case the unit value ~\lstinline!()!~ is assumed. 

The expected type of the final expression $e$ is the expected type of the block expression. The expected type of all preceding statements is undefined. 

The type of a block ~\lstinline!{ $s_1$; $\ldots$; $s_n$; $e$ }!~ is ~\lstinline!$T$ for-some { $Q$ }!, where $T$ is the type of $e$ and $Q$ contains existential clauses (\sref{sec:existential-types}) for every value or type name which is free in $T$ and which is defined locally in any of the statements $s_1 \commadots s_n$. We say that the existential clause {\em binds} the occurence of the value or type name. Specifically, 
\begin{itemize}

% TBD: new class grammar

\item A locally defined type definition ~\lstinline!type $t$ = $T$!~ is bound by the existential clause ~\lstinline!type $t$ >: $T$ <: $T$!. It is an error if $t$ carries type parameters. 

\item A locally defined value definition ~\lstinline!val $x$: $T$ = $e$!~ is bound by the existential clause ~\lstinline!val $x$: $T$!. 

\item A locally defined class definition ~\lstinline!class $c$ extends $t$!~ is bound by the existential clause ~\lstinline!type $c$ <: $T$!, where $T$ is the least class type of refinement type which is a proper supertype of the type $c$. It is an error if $c$ carries type parameters. 

\item A locally defined object definition ~\lstinline!object $x$ extends $t$!~ is bound by the existential clause ~\lstinline!val $x$: $T$!, where $T$ is the least class type of refinement type which is a proper supertype of the type ~\lstinline!$x$.type!.
\end{itemize}

Evaluation of the block entails evaluation of its statement sequence, followed by an evaluation of the final expression $e$, which defines the implicit result of the block. 





\subsubsection{Block Expression as Argument}
\label{sec:block-arguments}

A block expression may be used as the very last argument in a function application (\sref{sec:function-applications}), being equivalent to an anonymous function. 

As such, the block parameters section is optional to be defined, and its parameters are, unlike with anonymous functions, tolerant to different shapes of given arguments. If parameters of the block are typed and arguments for the corresponding parameters are given, the types of the arguments must be compatible with the expected parameter types. 

If less arguments are provided, the remaining parameters have default values of their types, and it is an error if such parameter is typed with a non-nullable type. 

If more arguments are provided, the extra arguments are discarded and released. 

An explicit return expression (\sref{sec:return-expressions}) within the block is interconnected with the innermost function that defines the block, i.e. evaluating it returns from the function (as well as from the block expression). This does not apply to anonymous functions (\sref{sec:anonymous-functions}), where the return expression is interconnected with the anonymous function itself. 






\subsubsection{Variable Closure}
\label{sec:variable-closure}

Aml uses variable closure when defining a block expression. 

If a block expression is used just as a statement, it implicitly inherits access to all variables and methods defined in the scope in which it itself is defined. 

Variables are made available via inner hidden instance variables of the implicit function. This includes the \code{self} object of the outer scope, if any methods are to be executed from within the block. Those variables are referenced with a strong reference, and therefore may cause in some situations retain cycles -- this can be solved by using {\em capture lists}, which can override this default behaviour and store the reference as either \code{weak}, \code{soft} or \code{unowned} reference, to break the retain cycle.\footnote{Quite useful with lazy definitions of instance variables, where the expression is wrapped in an implicit block.} 

If a block expression is used as an argument in a function application (\sref{sec:function-applications}), it is used as a functor, and is provided with read and write access to variables in the scope that the function application appears in, and with an access to the \code{self} reference, including any nested ~\lstinline!$C$.self!~ references (\sref{sec:self-this-super}). Write access to variables is provided in a manner equivalent to \code{out} arguments. 

Variable closure is applied to anonymous functions (\sref{sec:anonymous-functions}) as well. 

A block expression may opt-in to {\em shadow variables} that it would otherwise have access to from its scope, specified with the \code{Block_Shadowing} syntax element. Variables and methods with the same names as those of the shadowing variables will not be a part of the variable closure. 





\subsection{Yield Expressions}
\label{sec:yield-expressions}

\grammar\begin{lstlisting}
Yield_Expr 
    ::= [id '.'] 'yield' [Arguments]
\end{lstlisting}

A yield expression ~\lstinline!yield $a_1 \commadots a_n$!~ is an universal \code{yield} operation:
\begin{enumerate}
  \item A way to invoke the block argument (\sref{sec:function-applications} \& \sref{sec:block-arguments}) and pass it arguments. It's expected type is the result type of the given block argument. The value of the expression is then whatever the block argument returned. 
  \item When no block argument was given and the invocation happens inside a fiber that is not the thread's main fiber, a way to return from a fiber without destroying it's stack. The value of the expression is then whatever value is passed to the method that resumes the fiber (so that it continues with that value in place of the \code{yield} expression). 
  \item A part of workflows (\sref{sec:workflows}).
  \item A part of generators (\sref{sec:generator-expressions}) and collection comprehensions (\sref{sec:collection-comprehensions}).
  \item In other cases, it is an error to use \code{yield}. 
\end{enumerate}

A yield expression ~\lstinline!$T$.yield $a_1 \commadots a_n$!~ is a specialized case of the previous definitions of \code{yield}, where $T$ may be one of:
\begin{itemize}
  \item \code{Block}, for invoking block argument. To test if a block argument is available, use \code{Yield.block_available?}, defined in Aml's \code{Language} module. 
  \item \code{Fiber}, for yielding from a fiber. To test if a yield from a fiber is available, use \code{Yield.fiber_available?}, defined in Aml's \code{Language} module. 
\end{itemize}





\subsection{Prefix \& Infix Operations}
\label{sec:prefix-infix-ops}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Infix_Expr
Infix_Expr 
    ::= Prefix_Expr ['use' Expr]
      | Expr op_id Expr ['use' Expr]
      | Expr nary_op_id Expr {':' Expr} ['use' Expr] 
      | Range_Expr
Op_Application_Expr
    ::= (* binary operator application *)
        '(' op_id ')' Expr Expr ['use' Expr]
      | '(' op_id Expr Expr ['use' Expr] ')'
        (* n-ary operator application *)
      | '(' nary_op_id ')' Expr {Expr} ['use' Expr]
      | '(' nary_op_id Expr {Expr} ['use' Expr] ')'
        (* unary operator application *)
      | '(~' ? whitespace ? op_id ')' Expr ['use' Expr]
      | '(~' ? whitespace ? op_id Expr ['use' Expr] ')'
Prefix_Expr 
    ::= [op_id | 'not' | '...' | '~...' | Try_Op] Expr
Range_Expr
    ::= Expr ('..' | '..<') Expr [FP_Delta [FP_Digits]]
Slice_Expr
    ::= (* slice of 1 element *)
        Expr 
        (* slice from index to last *)
      | Expr '..'
        (* slice from first to index *)
      | ('..' | '..<') Expr
        (* slice from index to index *)
      | Expr ('..' | '..<') Expr
        (* slice from first to last (identity view) *)
      | '*'
\end{lstlisting}

Expressions can be constructed from operands and operators. 





\subsubsection{Prefix Operations}

A prefix operation $\op\ e$ consists of a prefix operator $\op$, which may be any operator identifier, but must not be followed by any whitespace, only identifiers or parentheses (except for the special operator \code{not}, which has to be separated by a space from the expression that it prefixes). The expression $\op\ e$ is equivalent to the function application ~\lstinline!($\op\ e$)!.

There is also a keyword prefix operator: \code{not}, which must be followed by a whitespace and is always prefix.

The precedence of prefix operators is higher than that of infix operators (\sref{sec:infix-operations}). For example, \code{-a + b} is read as \code{-(a) + b}, and \code{-(a + b)} as just that. 

Prefix operations may also appear in the forms $(\op)\ e$ or $(\op\ e)$. 





\subsubsection{Postfix Operations}

Apart from standard function applications (\sref{sec:function-applications}) that may be viewed as postfix, Aml does not include support for postfix operations. 





\subsubsection{Infix Operations}
\label{sec:infix-operations}

An infix operator can be an arbitrary identifier, usually an operator identifier. Infix operators have static {\em precedence} and {\em associativity} defined as follows:

Infix operators have to be separated from both sides by whitespace from the expressions that they connect. If the following whitespace is a newline character, then precedence rules can not be followed (due to line-by-line parsing and evaluation) and usual behaviour described in (\sref{sec:newlinecharacters}) is followed. The only infix operator that can be separated either from both sides or from neither side by whitespace is ``\code{^}'' (power), and this exception is applied only to this particular operator, not to operators derived from it. 

Infix operations and $n$-ary operations may alternatively appear in the form $(\op)\ e_1 \ldots e_n$, which is equivalent to a function application. 

After associativity of an infix operation is determined and a form ~\lstinline!$e_1$.`$\op$`($e_2$)!~ is known:
\begin{enumerate}
  \item If type of $e_1$ defines $\op$, that definition is used. 
  \item Otherwise, if the type of $e_1$ is a class, and the class object defines $\op$, that definition is used. 
\end{enumerate}

The {\em precedence} of an infix operator is determined by the operator's first character. Characters are listed below in increasing order of precedence, with characters on the same line having the same precedence.

\begin{lstlisting}
$\mbox{\rm\sl(all alphanumeric characters)}$
|
&
< > ~
= !
: @
$\mbox{\rm\sl(all other special characters)}$
+ -
* / %
^
\end{lstlisting}

That is, operators starting with ``\lstinline!|!'' have the lowest precedence, followed by operators starting with ``\lstinline!&!'', etc. 

There's one exception to this rule, which concerns {\em assignment operators} (\sref{sec:assignment-operations}). The precedence of an assignment operator is the same as the one of simple assignment (\lstinline!:=!). That is, it is lower than the precedence of any other operator. 

A number of left-associative alphanumeric operators with different precedence exist:
\begin{itemize}
  \item \code{and}, with precedence of ~\lstinline!&!. 
  \item \code{and also}, with precedence of ~\lstinline!&!. 
  \item \code{or}, with precedence of ~\lstinline!|!.  
  \item \code{or else}, with precedence of ~\lstinline!|!.  
  \item \code{xor}, with precedence of ~\lstinline!|!.  
  \item \code{rem}, with precedence of ~\lstinline!/!. 
  \item \code{mod}, with precedence of ~\lstinline!/!. 
  \item \code{div}, with precedence of ~\lstinline!/!. 
  \item \code{quot}, with precedence of ~\lstinline!/!.   
\end{itemize}

The {\em associativity} of an operator is determined by the operator's last character, if not explicitly defined (using one of \code{infix}, \code{infixl} or \code{infixr}). Operator ``\lstinline!=~!'' is right-associative and operators ending in a greater-than sign ``\lstinline!>!'' are right-associative, if they consist of more than one operator character. All other operators are left-associative. 

Precedence and associativity of operators determine the grouping of parts of an expression as follows.

\begin{itemize}
  \item If there are several infix operations in an expression, then operators with higher precedence bind more closely than operators with lower precedence. 
  
  \item If there are consecutive infix operations $e_0\ \op_1\ e_1\ \op_2 \ldots \op_n\ e_n$ with operators $\op_1 \ldots \op_n$ of the same precedence, then all those operators must have the same associativity (i.e. it is an error if they don't). If all operators are left-associative, then the sequence is interpreted as ~\lstinline!(($e_0\ \op_1\ e_1$) $\op_2 \ldots$) $\op_n\ e_n$!. Otherwise, if all operators are right-associative, the sequence is interpreted as ~\lstinline!$e_0\ \op_1$ ($e_1\ \op_2$ ($\ldots \op_n\ e_n$))!.

  \item A left-associative binary operation $e_1\ \op\ e_2$ is interpreted as ~\lstinline!($\op$) $e_1\ e_2$!. If $\op$ is right-associative, the same operation is interpreted as ~\lstinline!{ let x = $e_1$ in ($\op$) $x\ e_2$ }!, where $x$ is a fresh name. 

  \item Operators in a group with the same precedence must have the same associativity. 

\end{itemize}





\paragraph{Solution to Ambiguity between Infix Operations and Function Applications}

There is a syntactic overlap between syntaxes of function applications and infix operations. It's solution is not based on any extra syntactic elements, but rather on static AST resolution. The overlap occurs when an identifier is used in a place of a function application, where it could as well be an infix operation. 

Identifiers are then resolved with the following precedence:
\begin{enumerate}
  \item Variables and values that are declared in the scope always come first. The variable is a part of a function application. 
  \item In an ambiguous sequence of expressions $e_1\ e_2\ e_3$, where $e_2$ is an identifier, if the type of $e_1$ defines an infix operator of the name $e_2$, is implicitly convertible\footnote{Only statically known implicit conversions are available.} to a type that defines it, or if an infix operator exists in the scope where the sequence of expressions appears, it is a part of an infix operation. 
  \item Otherwise, it is a part of a function application.  
\end{enumerate}

\example Distinction between infix operations and function applications. 
\begin{lstlisting}[deletekeywords={open}]
(* function application *)
file.open "hello_world.txt"
(* is equivalent to function application *)
file.open ("hello_world.txt")

(* whereas expression *)
a shift-left b
(* is an infix expression equivalent to *)
shift-left a b
(* and not to the less obvious *)
a (shift-left) (b)
(* but only if `shift-left` is an infix operator in the scope *)
\end{lstlisting}

Infix operations can be grouped together. If there is an even number of expressions separated by whitespace (i.e., no right-hand side of an infix operation), the last one is an argument in ``poetry''-style function application, but such code is considered suspicious and a warning is issued during compilation. 





\paragraph{Tuple Arguments}

If the left hand side of an infix operator is of a tuple type, then an infix expression $(e_{01} \commadots e_{0n})\ \op\ (e_{11} \commadots e_{1n})$ is always seen as $\op(e_{01} \commadots e_{0n})(e_{11} \commadots e_{1n})$. Two tuple arguments are used to distinguish which arguments come from the left side and which from the right side. 





\paragraph{Standard Operators}

This is a short extract of the full set of standard operators. Not all classes implement these operators, e.g. \code{Object} implements none, not even ``\code{=}''. 

Language-reserved operators:
\begin{lstlisting}
a == b       (* value physical identity *)
a /== b      (* not physically identical *)
not (a == b) (* quite the same as `not physically identical' *)
\end{lstlisting}

Standard arithmetic operators:
\begin{lstlisting}
a + b     (* addition *)
a +. b    (* real addition *)
a +: b    (* integral addition *)
a - b     (* subtraction *)
a -. b    (* real subtraction *)
a -: b    (* integral subtraction *)
a * b     (* multiplication *)
a *. b    (* real multiplication *)
a *: b    (* integral multiplication *)
a / b     (* any number division *)
a /. b    (* real division *)
a // b    (* rational division *)
a //. b   (* rational division with real numerator *)
a div b   (* integral division *)
a mod b   (* modulo *)
a quot b  (* quotient *)
a rem b   (* remainder *)
a ^ b     (* power *)
\end{lstlisting}

Standard comparison operators:
\begin{lstlisting}
a = b    (* equality *)
a /= b   (* non-equality; unordered, less than or greater than *)
a =~ b   (* custom pattern matching, a matches b *)
a > b    (* greater than *)
a >= b   (* greater than or equal *)
a < b    (* less than *)
a <= b   (* less than or equal *)
a <> b   (* less than or greater than *)
a <>= b  (* less than, greater than or equal; ordered *)
a /<>= b (* unordered *)
a /<> b  (* unordered or equal *)
a /<= b  (* unordered or greater than *)
a /< b   (* unordered, equal or greater than *)
a />= b  (* unordered or less than *)
a />     (* unordered, less than or equal *)
a <=>    (* compare *)
\end{lstlisting}

Extended comparison operators (arguments are a tuple on the right hand side of the operator):
\begin{lstlisting}
a = ($\ldots$)   (* `a` equal to all arguments *)
a /= ($\ldots$)  (* `a` not equal to all arguments,
            but arguments may be equal to each other *)
a > ($\ldots$)   (* `a` greater than all arguments *)
a >= ($\ldots$)  (* `a` greater than or equal all arguments *)
a < ($\ldots$)   (* `a` less than all arguments *)
a <= ($\ldots$)  (* `a` less than or equal all arguments *)
(* etc. *)
\end{lstlisting}

Standard bitwise operators: 
\begin{lstlisting}
a << b   (* arithmetic (& logical) shift left *)
a <<< b  (* shift left, preserving the least significant bit *)
a >> b   (* arithmetic shift right *)
a >>> b  (* logical shift right *)
a <<@ b  (* rotate left *)
a >>@ b  (* rotate right *)
a and b  (* bitwise and (when applied to numbers) *)
a &&& b  (* bitwise and *)
a or b   (* bitwise or (when applied to numbers) *)
a ||| b  (* bitwise or *)
a xor b  (* bitwise xor (when applied to numbers) *)
a ^^^ b  (* bitwise xor *)
---a     (* bitwise not (prefix, unary) *)
not a    (* bitwise not (prefix, unary; when applied to numbers) *)
\end{lstlisting}

Standard boolean (logical) operators:
\begin{lstlisting}
(* short circuited: *)
a & b        (* boolean and *)
a and b      (* boolean and *)
a | b        (* boolean or *)
a or b       (* boolean or *)
(* non short circuited: *)
a && b       (* boolean and *)
a and also b (* boolean and *)
a || b       (* boolean or *)
a or else b  (* boolean or *)
a xor b      (* boolean xor *)
not a        (* boolean not (prefix, unary; when applied to booleans) *)
\end{lstlisting}

% Standard fuzzy logic operators:
% \begin{lstlisting}
% \end{lstlisting}





\paragraph{Range Expressions}
A range expression (the \code{Range_Expr} syntax category) is a special case of an infix expression, which can optionally be followed by delta and digits specifications, so that a range that may result from it the expression can swap a floating point type with a fixed point type, and thus allowing more operations on the range, e.g. iteration (where the delta defines the ``step'' of each iteration). 

If the expression contains both delta and digits specifications, the expected type of both operands is a decimal fixed point type with corresponding specification of delta and digits. The range of the type is implementation-defined. 

If the expression contains only a delta specification, the expected type of both operands is an ordinary fixed point type with corresponding specification of delta. The range of the type is implementation-defined. 




\paragraph{Slice Expression}
A slice expression (the \code{Slice_Expr} syntax category) is a special case of an infix expression, which can only appear in function applications as an argument. 

The expression is a representation of a range that has optional bounds, and if the bound is missing, it is \code{None}. This has special meaning for functions that accept slices as arguments -- usually, missing left bound means ``from first'', missing right bound means ``to last inclusive''. 




\subsubsection{Assignment Operations}
\label{sec:assignment-operations}

An assignment operator is an operator symbol that ends in an ``equals'' character ``\lstinline!=!'', with the exception of operators for which one of the following conditions holds: 
\begin{enumerate}
  \item the operator also starts with an equals character and has more than one character, or
  \item the operator is one of ``\lstinline!<=!'', ``\lstinline!>=!'', ``\lstinline!/<=!'', ``\lstinline!/>=!'', ``\lstinline!/=!'', ``\lstinline!<>=!'', ``\lstinline!/<>=!'' or ``\lstinline!/==!''\footnote{This one effectively disqualifies ``\lstinline!$l$ /= $\ r$!'' from being treated as ``\lstinline!$l$ := $\ l$ / $\ r$!'', very intentionally: to prevent floating/fixed point division from being privileged to integral division, ``\code{div}''.}.
\end{enumerate}

Assignment operators are treated specially in that they can be expanded to assignments if no other interpretation is valid, as previously defined. Assignment operators can be defined as members of a type. 

Let's consider an assignment operator, such as ``\lstinline!+=!'', in an infix operation ~\lstinline!$l$ += $r$!, where $l$ \& $r$ are expressions. This operation can be re-interpreted as an assignment
\begin{lstlisting}
$l$ := $l$ + $r$
\end{lstlisting}
except that the operations's left-hand-side $l$ is evaluated only once. 

The re-interpretation is occurs if the following conditions are fulfilled:
\begin{enumerate}
  \item The left hand side $l$ does not have a member named ``\lstinline!+=!'', and also can not be converted by an implicit conversion (\sref{sec:implicit-conversions}) to a value with a member named ``\lstinline!+=!'', applicable to a value of type of $r$. 
  \item The assignment ~\lstinline!$l$ := $l$ + $r$! is type-correct. In particular, this implies that $l$ refers to an object that is convertible to a value with a member named ``\lstinline!+!'' (or itself has such a member without conversion, in the ideal case, indeed). 
  \item The variable $l$ is assignable, defined, not immutable. This implies that it is defined as a ~\lstinline!var $l$!. 
\end{enumerate}

The re-interpretation is built into the compiled bytecode in such a way that first tries the assignment operator, and then the re-interpretation only in case where the assignment operator approach failed.\footnote{No appropriate implicit conversion was found, or if implicit conversions are disabled for the expression, the value referred to by $l$ does not have the appropriate member.} It is indeed an error if none of the two approaches succeeded. 

Assignment operations are right-associative, despite any rules defined for other operators. The value of an assignment expression is the left-hand side argument after the assignment operation was evaluated. 

\example Right-associativity of assignment operations, using mutable variables as left-hand sides. 
\begin{lstlisting}
(* the assignment *)
a := b := c
(* is equivalent to *)
a := (b := c)

(* the assignment *)
(a := b) := c
(* is equivalent to *)
a := b; a := c

(* this works as well *)
a := let b = c
(* as *)
a := (let b = c)
\end{lstlisting}




\subsubsection{$N$-ary Infix Expressions}
\label{sec:nary-infix-expressions}

\grammar\begin{lstlisting}
nary_op_id  ::= '?' {op_char}
Infix_Expr  ::= Infix_Expr nary_op_id Infix_Expr {':' Infix_Expr}
\end{lstlisting}

Operators that begin with a question mark ``\code{?}'' (and may as well consist only of that one character) have the special ability to create an $n$-ary infix expression. Those are recognized by the ``\,\code{:}\,'' symbol (separated by whitespace from both sides), which is otherwise not allowed as an operator. Here, it serves as a separator of arguments to the $n$-ary infix operation. The expression is viewed as if it were a regular infix expression, where the infix expressions following the $n$-ary operator are all right-hand side arguments to the operation. 

The following infix expression and the function application are equivalent.
\begin{lstlisting}
a ? b : c : d
(? a b c d)
\end{lstlisting}

\example The most widely used $n$-ary operator is the ternary conditional operator ``\code{?}'', which could be defined as follows:

\begin{lstlisting}
operator ? 
    ['a <% Boolean_Like, 'b, 'c <: 'b, 'd <: 'b]
    (eager tested: 'a) (lazy when_yes: 'c) (lazy when_no: 'd): 'b
  if tested as Boolean
    when_yes
  else
    when_no
  end
end
\end{lstlisting}

Such definition of the conditional operator includes lazy evaluation of the arguments. A shorthand version could use an object definition from which the operator name may be imported into scope:

\begin{lstlisting}
operator ?: 
    ['a <% Boolean_Like, 'b <: 'a]
    (eager tested: 'a) (lazy when_no: 'b): 'a
  if tested as Boolean
    tested
  else
    when_no
  end
end
\end{lstlisting}

Then, one may use these operators as follows: 

\begin{lstlisting}
val a = b ? c : d
val e = b ?: d  (* which is equal to b ? b : d *)
\end{lstlisting}





\subsubsection{Operator Name Resolution}

In any operator-related expression (prefix, infix, $n$-ary), the operator name is first searched in the receiver. Then, if not found, the name scope in which the operator expression appears, is searched for an operator of the given name and arity of arguments count incremented with 1 (for the original receiver). After that, implicit conversions are applied to the receiver, to a type that contains operator with the given name. 

If the found operator does not accept $n$ arguments, but instead has $n$ type parameters, then:
\begin{itemize} 
  \item If the operator references a type, the infix expression is equivalent to an infix type (\sref{sec:infix-types}), and has to be a part of a type reference expression (\sref{sec:type-ref-expressions}). 
  \item If the operator does not reference any type, then the infix expression is equivalent to a type application (\sref{sec:type-applications}). 
\end{itemize}





\subsection{Assignments}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Rebind_Expr
      | Update_Expr
Rebind_Expr 
    ::= [Expr '.'] id ':=' Expr
      | Expr '.' Selection ':=' Expr
      | Atomic_Pattern ':=' Expr
Update_Expr
   ::= Expr '.' '(' [Arguments] ')' ':=' Expr
     | '(' Regular_Precedence_Application_Expr ')' ':=' Expr
\end{lstlisting}

The interpretation of an assignment to a simple variable ~\lstinline!$x$ := $e$!~ depends on the definitions of $x$. If $x$ denotes a mutable variable, then the assignment changes the current value of $x$ to the result of evaluating the expression $e$. The type of $e$ is expected to conform to the type of $x$. 

If $x$ is defined as a property of some template, or the template contains a setter function ~\lstinline!set_$x$!~ as a member, then the assignment is interpreted as the invocation ~\lstinline!set_$x$($e$)!~ of that setter function. 

Analogously, an assignment ~\lstinline!$x$.$f$ := $e$!~ is interpreted as the invocation ~\lstinline!$x$.set_$f$($e$)!. 

An assignment ~\lstinline!$x$.?$f$ := $e$!~ is interpreted as the invocation ~\lstinline!$x$.?set_$f$ ($e$)!. If $f$ is evaluated to \code{nil}, then the invocation is evaluated to \code{nil}. See (\sref{sec:designators}) for more on behaviour of the ``\lstinline!.?!'' navigation. 

An assignment ~\lstinline!$x$ ($\args$) := $e$!~ with a function application to the left of the ``\lstinline!:=!'' operator is interpreted as ~\lstinline!$x$.update ($\args$)($e$)!, i.e. the invocation of an \code{update} function defined by $x$.  

The interpretation of an assignment ~\lstinline!$x$ := $e$!~ has scope augmented with names from the expected type of $x$.

\example Here are some assignment expressions and their equivalent interpretations.
\begin{lstlisting}
f := e                       set_f (e)  (* or, self.set_f (e) *)
x () := e                    x.update () (e)
x (i) := e                   x.update (i) (e)
x (i, j) := e                x.update (i, j) (e)
x.f := e                     x.set_f (e)
x.f () := e                  x.f.update () (e)
x.f (i) := e                 x.f.update (i) (e)
x.f (i, j) := e              x.f.update (i, j) (e)
x () () := e                 x().update () (e)
x (i) () := e                x(i).update () (e)
x () (i) := e                x().update (i) (e)
x (i) (j) := e               x(i).update (j) (e)
x (i, j) (k) := e            x(i, j).update (k) (e)
x (i, j) (k, l) := e         x(i, j).update (k, l) (e)
x (i, j) := (e_1, e_2)       x.update (i, j) (e_1, e_2)
\end{lstlisting}





\section{Definition Expressions}
\label{sec:def-expressions}

\grammar\begin{lstlisting}
Expr 
    ::= ...
      | Binding_Expr
Binding_Expr 
    ::= ['implicit'] Val_Def In_Sep Expr ['end']
      | ['implicit'] Var_Def In_Sep Expr ['end']
      | 'let' 'structure' id {'(' [id ':' Struct_Type] ')'} [':' Struct_Type]
        '=' Struct_Expr In_Sep Expr ['end']
\end{lstlisting}





\section{Type-Related Expressions}





\subsection{Typed Expressions}
\label{sec:typed-expressions}

\grammar\begin{lstlisting}
Cast_Expr 
    ::= Expr ('as' | 'as!' | 'as?') Type
Infix_Expr 
    ::= Expr ('is' ['not' | 'not!'] | 'is!') Type
\end{lstlisting}

The typed expression ~\lstinline!$e$ as $T$!~ has type $T$. The type of expression $e$ is expected to conform to $T$. The result of the expression is the value of $e$ converted to type $T$. If the type conversion fails, a runtime error is raised. The conversion can take these forms, preferred in the following order:
\begin{enumerate}
  \item No conversion, if $e$ conforms to $T$ directly. 
  \item If an implicit conversion $c$ from expression type $E$ of method type ~\lstinline!($E$) $\mapsto\ T$!~ exists in the scope, then the conversion is of the form ~\lstinline!$c$($e$)!. 
  \item Otherwise, the conversion is of the form ~\lstinline!$e$.as_instance_of[$T$]()!, and the type of $e$ must implement \code{Type_Convertible[$S$]}, where $S$ conforms to $T$.
\end{enumerate}

The conformance check expression ~\lstinline!$e$ is $T$!~ has type \code{Boolean} and tests whether $e$ conforms to $T$, basically by asking a question ``Can $e$ be of type $T$?'', answering either ``It can be'' or ``It can't be''. The expression $e$ conforms to type $T$ if at least one of the following conditions hold:
\begin{enumerate}
  \item Type of $e$ is a subtype of $T$. 
  \item An implicit conversion $c$ from expression type $E$ of method type ~\lstinline!($E$) $\mapsto\ T$!~ exists in the scope. 
  \item As a last resort, type of $e$ implements \code{Type_Convertible[$S$]} and $S$ conforms to $T$.
\end{enumerate}

\paragraph{Flow Based Typing} 
If the conformance check expression is performed on a variable, as defined here, it shadows the type of the variable, if used as a condition in a conditional expression (\sref{sec:conditional-expressions}), in the related branch. Therefore, it is also used in resolution of function applications (\sref{sec:function-applications}). Furthermore, if the type of the variable was already known in the outer code, then it can both restrict and extend the expected type $T$ with $U$ into $T$: 
\begin{itemize}
  \item If the type $T$ did not contain $U$, then $T'$ is ~\lstinline!$T$ with $U$!.
  \item If the type $T$ did contain $U$ and was a union type, then $T'$ is only $U$, dropping the other member types. 
  \item In the other branches of a conditional expression, it means that $T$ does not conform to $U$, whatever that implies. Also, the same happens to the same branch, if the conformance check is negated (e.g., ~\lstinline!$e$ is not $U$!). 
\end{itemize}

The conformance check expression ~\lstinline!$e$ is not $T$!~ has type \code{Boolean} and tests whether $e$ does not conform to $T$, basically by asking a question ``Can $e$ not be of type $T$?'', answering either ``It can't be'' or ``It can be''.

The typed expression ~\lstinline@$e$ as! $T$@~ works like ~\lstinline!$e$ as $T$!, but only uses the first form. Similarly, the conformance check expression ~\lstinline@$e$ is! $T$@~ works like ~\lstinline!$e$ is $T$!, but it uses only the first condition, and the conformance check expression ~\lstinline@$e$ is not! $T$@~ works like ~\lstinline!$e$ is not $T$!, but also uses only the first condition. The bang character ``\lstinline@!@'' signalizes that the operation is more dangerous, in means of that its easier for the expression $e$ to not successfully convert to the target type or conform to it. 

The typed expression ~\lstinline!$e$ as? $T$!~ has a result of type ~\lstinline!$T$?!, resulting in a \code{nil} value instead of an error if no conversion is available to treat $e$ as $T$. 

If an expression is typed to a dynamic path of a (syntactic) type, then the value referenced by such path is expected to be a type, and it is an error if it is not. 

Typed expressions do not allow checks against target type expressions (\sref{sec:target-type-expressions}) and conversions to them, as such checks and conversions would make no sense at all. 





\subsection{Type Reference Expressions}
\label{sec:type-ref-expressions}

\grammar\begin{lstlisting}
Expr 
    ::= ...
      | Type_Ref_Expr
Type_Ref_Expr 
    ::= '(' 'type' Type ')'
      | Annot_Type - (Type_Var, Postfix_Parameterized_Type)
\end{lstlisting}

A type reference expression is a way to refer to a type and use it as a first-class value, which it already is. 





\subsection{Structure Reference Expressions}
\label{sec:structure-ref-expressions}

\grammar\begin{lstlisting}
Expr 
    ::= ...
      | Structure_Ref_Expr
Structure_Ref_Expr 
    ::= '(' 'structure' Struct_Expr ['as' Pkg_Type] ')'
\end{lstlisting}





\subsection{Annotated Expressions}
\label{sec:annotated-exprs}

\grammar\begin{lstlisting}
Expr
    ::= ...
      | Annotated_Expr
Annotated_Expr
    ::= {Annotation}+ Expr
\end{lstlisting}

An annotated expression $a_1\ \ldots\ a_n\ e$ attaches annotations $a_1\ \ldots\ a_n$ to the expression $e$ (\sref{sec:annotations}). 





\section{Control Flow Expressions}





\subsection{Conditional Expressions}
\label{sec:conditional-expressions}
% TBD: finish this grammar, find references to old one
\grammar\begin{lstlisting}
Expr
    ::= ...
      | Conditional_Expr
Conditional_Expr
    ::= Cond_Block_Expr 
      | Cond_Mod_Expr
Cond_Block_Expr 
    ::= Cond_Block_Expr1 
      | Cond_Block_Expr2
Cond_Block_Expr1 
    ::= 'if' Condition ('then' | semi) Expr 
        {[semi] 'elsif' Condition ('then' | semi) Expr}
        [[semi] Else Expr] 'end' ['if']
Cond_Block_Expr2 
    ::= 'unless' Condition ('then' | semi) Expr 
        {[semi] 'elsif' Condition ('then' | semi) Expr}
        [[semi] Else Expr] 'end' ['unless']
Cond_Mod_Expr
    ::= Expr Cond_Modifier
Cond_Modifier 
    ::= Cond_Modifier1 [Else (Expr - Conditional_Expr)]
Cond_Modifier1
    ::= ('if' | 'unless') Condition 
Else 
    ::= 'else' | 'otherwise'
Condition 
    ::= Condition1 
      | Condition2
Condition1 
    ::= (Expr - Conditional_Expr) 
Condition2 
    ::= [Mutability_Modifier] ('val?' | 'let?' | 'var?') Let_Binding 
        ['and' Condition2]
\end{lstlisting}

The conditional expression ~\lstinline!if $e_1$ then $e_2$ else $e_3$!~ chooses one of the values of $e_2$ and $e_3$, depending on the value of $e_1$. The condition $e_1$ is expected to conform to type \code{Boolean}, but can be virtually any type -- if it is not a \code{Boolean}, then it is equal to \code{yes} if it implements the method ~\lstinline!to_boolean(): Boolean! and that implementation returns \code{yes}, or can be converted to \code{yes} (\sref{sec:typed-expressions}), and \code{no} otherwise. If the $e_1$ is the single instance ``\lstinline!()!'' of type \code{Unit}, it is an error. The \code{then}-part $e_2$ and the \code{else}-part $e_3$ are both expected to conform to the expected type of the conditional expression, but are not required to. The type of the conditional expression is the weak least upper bound (\sref{sec:weak-conformance}) of the types of $e_2$ and $e_3$. A semicolon preceding the \code{else} symbol of a conditional expression is ignored. 

The conditional expression is evaluated by evaluating first $e_1$. If this evaluates to \code{true}, the result of evaluating $e_2$ is returned, otherwise the result of evaluating $e_3$ is returned. 

The evaluation of $e_1$ utilizes the so-called {\em short-circuit evaluation}. The expression $e_1$ is split by binary boolean operators. Then every first argument is evaluated, but the second argument is evaluated only if the evaluation of the first argument does not suffice to determine the value of the expression. When the first argument of ``\lstinline!&!'' evaluates to \code{no}, the overall value must be \code{no} and the result of evaluating the second argument does not change that. When the first argument of ``\lstinline!|!'' evaluates to \code{yes}, the overall value must be \code{yes}. These boolean operators are in fact short-circuited source-code-wide, not only as part of conditional expressions. Word equivalents of these operators are also short-circuited (``\code{and}'' and ``\code{or}'' respectively). To prevent short-circuited behaviour, one has to use a non short circuiting version of the operator (``\code{and also}'' and ``\code{or else}'', or ``\code{&&}'' and ``\code{||}'').\footnote{This is different from SML, where the short circuiting behaviour is the other way around with ``\code{and also}'' and ``\code{or else}''. The reason is that Aml prefers the ``lazy'' behaviour of short circuiting these infix expressions, so it also requires less typing.}

\example The following examples show how short-circuit evaluation behaves. Let's mark the short-circuited ``\lstinline!&&!'' as ``\lstinline!sand!'' and the short-circuited ``\lstinline!||!'' as ``\lstinline!sor!''. On the right side are the equivalent conditional expressions. 
\begin{lstlisting}
$x$ sand $y$          if $x$ then $y$ else no
$x$ sor $y$           if $x$ then yes else $y$
\end{lstlisting}

A short form of the conditional expression eliminates the \code{else}-part. The conditional expression ~\lstinline!if $e_1$ then $e_2$!~ is evaluated as if it was ~\lstinline!if $e_1$ then $e_2$ else ()!, and is therefore expected to be the weak least upper bound of the type \code{Unit} and the type of $e_2$. 

The conditional expression 
\begin{lstlisting}
if $e_1$ then $e_2$ elsif $e_3$ then $e_4$ $\ldots$ elsif $e_n$ then $e_{n+1}$ else $e_{n+2}$
\end{lstlisting} 
is evaluated as if it was 
\begin{lstlisting}
if $e_1$ then $e_2$ else if $e_3$ then $e_4$ $\ldots$ else if $e_n$ then $e_{n+1}$ else $e_{n+2}$
\end{lstlisting}
Basically, \code{elsif} is a simple syntax sugar for the little longer \code{else if} keyword tokens sequence. 

The alternative conditional expression ~\lstinline!unless $e_1$ then $e_2$ else $e_3$!~ is evaluated as if it was ~\lstinline@if not $e_1$ then $e_2$ else $e_3$@. Unlike in Ruby, the \code{elsif}-part is allowed to appear with this conditional expression. However, there is no syntax sugar for the \code{else unless} keyword tokens sequence. 

The modifier-fashion conditional expression ~\lstinline!$e_1$ if $e_2$ else $e_3$!~ is interpreted as if it was ~\lstinline!if $e_2$ then $e_1$ else $e_3$!. Similarly with the \code{unless} version and the short form of the modifier conditional expression (without the explicit \code{else}-part). 

Unlike in some languages, conditional expressions do not require to place parentheses around the conditions -- but it is possible to do so, the result is equivalent. That might be useful when the condition is inevitably long and needs to span multiple lines -- so that boolean operators may be situated at the beginning of each new line, instead of being at the end of the previous line. 

\paragraph{Note}
Aml provides two equivalent alternatives of the usual ``\code{else}'' keyword: ``\code{else}'' (obviously) and ``\code{otherwise}''. This is only provided so that certain conditions may be read better.

\paragraph{Conditional Variable Binding}
The conditional variable definition ~\lstinline!if $p$ = $e_1$ then $e_2$ else $e_3$!, where ~\lstinline!$p$ = $e_1$!~ is a variable binding using one of \code{let?}, \code{val?} or \code{var?}, works the same way as other conditional expressions, with the following difference: if $e_1$ evaluates to \code{nil} or even \code{()} (\code{Unit} value), then the condition is regarded as \code{no}. Beware that if $e_1$ evaluates to \code{no} (literally), the condition is still met (because \code{no} is not \code{nil} neither \code{()}) and $e_2$ is evaluated. Note that if type required by $p$ does not allow \code{nil} or \code{()} value, then no error happens and $e_3$ is evaluated instead. The condition in this case says ``if the variable definition ~\lstinline!$p$ = $e_1$!~ can be realized, then proceed with $e_2$, otherwise proceed with $e_3$''. In case the \code{unless} keyword is used instead of \code{if}, then the variable binding is effective in $e_3$ (and possible other \code{elsif} branches), but not in $e_2$. Multiple conditional variable bindings may be combined, and in that case, all of them must successfully bind for the condition to be true. 






\subsection{Loop Expressions}

Aml has an elaborate support for loop expressions. Not all structures known from other languages are supported though, e.g. the ~\lstinline[language=Java]!do $\ldots$ while!~ expression, which is expressed differently in Aml. 






\subsubsection{Loop Control Expressions}
\label{sec:loop-control-expressions}

\grammar\begin{lstlisting}
Loop_Ctrl_Expr 
    ::= Break_Expr
      | Skip_Expr
      | Next_Expr
      | Redo_Expr
      | Exhausted_Expr
      | Broken_Expr
Break_Expr 
    ::= 'break' [label_name] [Cond_Modifier1]
Skip_Expr
    ::= 'skip' [integer_literal] [Cond_Modifier1]
Next_Expr
    ::= 'next' [label_name] [Cond_Modifier1]
Redo_Expr 
    ::= 'redo' [label_name] [Cond_Modifier1]
Exhausted_Expr 
    ::= 'exhausted' Do_Block
Broken_Expr
    ::= 'broken' Do_Block
\end{lstlisting}

Loop control expressions are made available inside of loop expressions to allow control of the enclosing loops.

In the following paragraphs, a {\em loop identified by the label $l$} is a loop expression preceded in its syntax with the syntax element \code{Label_Dcl} (\sref{sec:local-jump-expressions}). All annotations (\sref{sec:annotated-exprs}) that precede the label declaration are applied to the following loop expression, never to the label. 

The ~\lstinline!break $l$!~ expression stops the loop labeled with $l$, and omitting the $l$ label stops the directly enclosing loop. 

The ~\lstinline!skip $i$!~ expression skips $i$ loop iterations, or with the $i$ omitted, skips $1$ loop iteration (the current iteration). 

The ~\lstinline!next $l$!~ expression skips the current loop iteration and every other enclosing iteration until the loop identified by the given label $l$ is found, and continues with its next iteration. If the label $l$ is omitted, then its behaviour is equal to ~\lstinline!skip 1!. 

The ~\lstinline!redo $l$!~ restarts the loop identified by the label $l$ (and stops all loops in between), or if $l$ is omitted, restarts the directly enclosing loop. 

The ~\lstinline!exhausted $e$!~ expression evaluates the expression $e$ only if the directly enclosing loop {\em was not broken} with the \code{break} keyword. 

The ~\lstinline!broken $e$!~ expression evaluates the expression $e$ only if the directly enclosing loop {\em was broken} with the \code{break} keyword. 

The standard library provides loop-like methods, where these loop control structures are not available as keywords, but as methods instead (either imported or available on some given loop-control object) -- they might be implemented e.g. using the \code{throw} expressions (\sref{sec:throw-catch-expressions}), that the enclosing loop-like method catches and resolves as appropriate. Only the \code{exhausted} and \code{broken} constructs need to be simulated, possibly by optional parameters or additional parameter sections.\footnote{In fact, all loop expressions may be interpreted as syntax sugar to such methods. How exactly -- that may get into this specification as soon as it is clearly defined.} 





\subsubsection{Iterable For Expressions}
\label{sec:iterable-expressions}

\grammar\begin{lstlisting}
Loop_Expr 
    ::= [Label_Dcl] 'for' Val_Dcls 'in' Expr 
        ['step' Expr] For_Loop
For_Loop 
    ::= 'loop' Loop_Block_Expr 'end' ['loop']
      | 'do' Loop_Block_Expr 'done'
Loop_Block_Expr 
    ::= Expr + Loop_Ctrl_Expr
Val_Dcls 
    ::= id {',' id}
      | id ':' Type
      | Pattern
\end{lstlisting}

The {\em iterable expression} is typed as \code{Unit}, so there is no point in using its value. 

In an expression ~\lstinline!for $e_1$ in $e_2$ loop $e_3$ end!, the type of $e_2$ is expected to conform to ~\lstinline!Iterable_Like[$E$]!. The type of $e_1$ is expected to conform to the type $E$. The type of $e_3$ is evaluated to ``\lstinline!()!'' anyway. The scope of variables defined in $e_1$ extends to the $e_3$ expression. 

In expression ~\lstinline!for $e_1$ in reverse $e_2$ loop $e_3$ end!, the type of $e_2$ is expected to conform to \code{Reverse_Iterable_Like}. 

Iterable expressions make use only of the two mentioned traits and the methods defined by them, and therefore advanced iterating mechanisms, such as parallel computations, are not performed -- they are simply too complex to be generalized by a simple language construct. 

Iterable expression repeats evaluation of the expression $e_3$ for every value that comes from the \code{Iterable_Like}'s \code{Iterator}, unless the loop controls alter this flow (\sref{sec:loop-control-expressions}).

Iterable expressions can be seen as simple comprehensions over iterating a single iterable value. For more complex iterating expressions, see generators (\sref{sec:generator-expressions}).

An expression 
\begin{lstlisting}
for $e_1$ in $e_2$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}
$e_2$.each { when $e_1$ then $e_3$ }
\end{lstlisting} 

An expression 
\begin{lstlisting}
<<$l$>> for $e_1$ in $e_2$ loop $e_3$ end
\end{lstlisting} 
where $l$ is a label name, is translated to the invocation
\begin{lstlisting}[deletekeywords={label}]
$e_2$.each({ when $e_1$ then $e_3$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

An expression 
\begin{lstlisting}
for $e_1$ in $e_2$ step $i$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}[deletekeywords={step}]
$e_2$.each({ when $e_1$ then $e_3$ }, step: $i$)
\end{lstlisting} 

Analogously, other combinations of \code{reverse}, \code{skip} and labeled loops are translated. If the $e_3$ expression contains a \code{exhausted} expression, then it's block is passed to the \code{each} method as an argument named \lstinline[deletekeywords={exhausted}]{exhausted}, and analogously, if the $e_3$ expression contains a \code{broken} expression, then it's block is passed to the \code{each} method as an argument named \lstinline[deletekeywords={broken}]{broken}.







\subsubsection{While \& Until Loop Expressions}

\grammar\begin{lstlisting}
Loop_Expr
    ::= ...
      | [Label_Dcl] ('while' | 'until') Condition For_Loop
      | Loop_Modifier_Expr
Loop_Modifier_Expr 
    ::= Expr Loop_Modifier
Loop_Modifier 
    ::= ('while' | 'until') Condition1
\end{lstlisting}

The {\em while loop expression} ~\lstinline!while $e_1$ loop $e_2$ end!~ is typed as \code{Unit}, so there is no point in using its value. 

In an expression ~\lstinline!while $e_1$ loop $e_2$ end!, the expression $e_1$ is treated the same way as the condition part in conditional expressions (\sref{sec:conditional-expressions}). The type of $e_2$ is evaluated to ``\lstinline!()!'' anyway.

The while loop expression ~\lstinline!while $e_1$ loop $e_2$ end!~ is alone typed and evaluated as if it was an application of a hypothetical function ~\lstinline!while_loop ($e_1$) ($e_2$)!, where the function \code{while_loop} would be defined as follows, with the $e_1$ and $e_2$ would be passed by-name: 
\begin{lstlisting}
method while_loop (condition: => Boolean) (body: => Unit): Unit = {
<<repeat>>
  if condition 
  then body; goto repeat 
  else ()
  end
}
\end{lstlisting}
The real implementation has to handle loop control expressions (\sref{sec:loop-control-expressions}) around the evaluation of \code{body} and also handle a label, if one is given; so it is not this simple. 

A while loop expression repeats evaluation of the expression $e_2$ as long as $e_1$ evaluates to \code{yes}, unless the loop controls alter this flow (\sref{sec:loop-control-expressions}).

A while loop expression with variable definition works like a regular while loop expression, but the condition is treated as in conditional variable definition, and can be an immutable value definition, since it is local to each loop. 





\subsubsection{Pure Loops}
\label{sec:pure-loops}

\grammar\begin{lstlisting}
Loop_Expr 
    ::= [Label_Dcl] 'loop' semi 
        Loop_Block_Expr 'end' ['loop']
\end{lstlisting}

The {\em pure loop expression} ~\lstinline!loop $e$ end!~ is typed as \code{Unit}, so there is no point in using its value. 

A pure loop expression repeats evaluation of the expression $e$ as long as the loop controls don't alter this flow (\sref{sec:loop-control-expressions}). It is basically equivalent to an iterable expression (\sref{sec:iterable-expressions}) that iterates over an endless iterator. 

This expression may also be used to replace the ~\lstinline[language=Java]!do { $e_1$ } while ($e_2$)!~ expression, known from other languages, using the following structure: 
\begin{lstlisting}
loop
  $e_1$
  break if $e_2$
end loop
\end{lstlisting}

A pure loop expression is the only expression that is not translated into a method call, but rather into another expression. The following constructs are practically the same: 
\begin{lstlisting}
(* construct with loop *)
loop
  $\ldots$
end loop

(* construct with goto *)
label loop_begin
  $\ldots$
  goto loop_begin
\end{lstlisting}
However, the loop construct has built-in support for loop control expressions. 





\subsubsection{Counter Loops}

\grammar\begin{lstlisting}
Loop_Expr 
    ::= ...
      | 'for' id '=' Expr ('to' | 'downto') Expr For_Loop
\end{lstlisting}

The {\em counter loop expressions} ~\lstinline!for $i$ = $e_1$ to $e_2$ loop $e_3$ end!~ is typed as \code{Unit}, same as ~\lstinline!for $i$ = $e_1$ downto $e_2$ loop $e_3$ end!~, so there is no point in using their value. 

The expression ~\lstinline!for $i$ = $e_1$ to $e_2$ loop $e_3$ end!~ first evaluates the expressions $e_1$ and $e_2$ (boundaries) as \code{Integer_Like} values $a$ and $b$. Types of both must be equivalent, and the value $i$ is typed with their type. The loop body $e_3$ is then evaluated in an environment where $i$ is successively bound to the values $a, a+1 \commadots b-1, b$. The loop body is never evaluated if $a > b$. It is an error if ~\lstinline!e_1 as? Integer_Like!~ or ~\lstinline!e_2 as? Integer_Like!~ results in \code{nil}. 

The expression ~\lstinline!for $i$ = $e_1$ downto $e_2$ loop $e_3$ end!~ evaluates similarly, except that $i$ is successively bound to the values $a, a-1 \commadots b+1, b$, and the loop body is also never evaluated if $a < b$. 







\subsection[Pattern Matching, Case Expressions \& Switch Expressions]{Pattern Matching, Case Expressions \\\& Switch Expressions}
\label{sec:case-exprs}

% TBD: add use of `parallel`

\grammar\begin{lstlisting}
Match_Expr     
    ::= Pat_Match_Expr 
      | Switch_Expr
Pat_Match_Expr 
    ::= 'match' Expr Match_Body
Match_Body 
    ::= [nl] When_Clauses 'end' ['match']
When_Clauses
    ::= When_Clause {semi When_Clause} 
        [semi Else [nl] Expr]
        [semi 'rescue' [nl] Rescue_Clauses]
When_Clause 
    ::= 'when' Pattern [Guard] ('then' | semi) Expr
Switch_Expr 
    ::= 'switch' Expr Switch_Body
Switch_Body 
    ::= [nl] Switch_Clauses 'end' ['switch']
Switch_Clauses 
    ::= Switch_Clause {['next'] semi Switch_Clause}
        [['next'] semi Else Expr]
        [semi 'rescue' [nl] Rescue_Clauses]
Switch_Clause 
    ::= 'when' Switches ('then' | semi) Expr
Switches 
    ::= Switch {',' Switch}
Switch_Scalar 
    ::= (Literal - Collection_Literal)
      | Long_Id  (* provided that the value is constant and scalar *)
Switch 
    ::= Switch_Scalar [('..' | '..<') Switch_Scalar]
\end{lstlisting}

Pattern matching is described in (\sref{sec:pattern-matching}). Here, the syntax of expressions that make use of pattern matching is given. 

Switch expressions 
\begin{lstlisting}
switch $e$ { when $c_1$ then $b_1\ \ldots$ when $c_n$ then $b_n$ else $b_{n+1}$ }
\end{lstlisting}
are extremely simplified pattern matching expressions, though they do not use patterns from pattern matching expressions, but {\em equality} and/or {\em range membership} instead. Therefore, switch expressions do not aim at matching the selector expression $e$, thus decomposing the selector $e$, but rather tests if it falls into a particular set of values, defined using the equality or range membership:
\begin{itemize}
  \item number types are matched based on their value,
  \item string types are matched based on their hash code,
  \item boolean types are considered \code{1} for \code{yes} and \code{0} for \code{no}.
\end{itemize}

Compiler adds extra code to determine the value to switch on if the switched expression is of an unknown type, or not of one of the mentioned types. Generally, there are two internal kinds of switch instructions:
\begin{enumerate}
  \item Single entry switch table, for switch expressions without ranges,
  \item Triplet entry switch table, for switch expressions with ranges, where the triplet consists of the two marginal values and an indicator whether the range is inclusive (\code{..}) or exclusive (\code{...} or \code{..<}) of the upper limit. 
\end{enumerate}

Switch expressions therefore do not involve any other implicit conversions or user code evaluation, other than that required to get the value to switch on. If a switch branch uses a guard, that guard becomes a part of the conditional expression that follows. 

\paragraph{Difference from Java etc}
Java (and countless other languages) does not allow switching on other values than integral numbers (and strings since Java 1.7), where Aml allows all scalar literals, including floating point numbers. It is quite unreliable to switch on floating point numbers, due to rounding errors, whereas switching on fixed point numbers is reliable. Both switching on floating point numbers and fixed point numbers should only be involved in switch expressions with ranges. 

\paragraph{NaN in a switch}
The {\em not a number} (\code{Number.NaN}) value is treated specially in switch expressions -- it simply never matches anything else but the \code{else} branch. The comparisons of values involved are safe from errors that could be raised from regular unsuspecting comparison with a \code{NaN} value. 






\subsection{Unconditional Expressions}

Unconditional expressions change the flow of programs without a condition. 






\subsubsection{Return Expressions}
\label{sec:return-expressions}

\paragraph{Implicit return expressions}
Implicit return expression is always the value of the last expression in a code execution path. 

\paragraph{Explicit return expressions}
Explicit return expressions unconditionally change the flow of programs by making the enclosing function definition return a value early (or return no value). 

\grammar\begin{lstlisting}
Return_Expr 
    ::= ['memoize'] 'return' [Expr] [Cond_Modifier1]
      | ['memoize'] 'tailcall' Arguments [Block_Expr2 | Method_Expr]
      | ['memoize'] 'tailcall' Block_Argument
\end{lstlisting}

A return expression ~\lstinline!return $e$!~ must occur inside the body of some enclosing method, or inside a block nested in the body of the innermost enclosing method. Unlike in Scala, the innermost enclosing method in a source program, $f$, does not need to have an explicitly declared result type, as the result type can be inferred as the weak least upper bound of all return paths, including the explicit return path. The return expression evaluates the expression $e$ and returns its value as the result of $f$. The evaluation of any statements or expressions following the return expression is omitted.The type of a return expression is \code{Nothing}.

The expression $e$ may be omitted, then the return expression \code{return} is type-checked and evaluated as if it was ~\lstinline!return ()!, typed as \code{Unit}. 

Returning from a nested block is implemented by throwing and catching a specialized exception, which may be seen by \code{throw}-\code{catch} expressions (\sref{sec:throw-catch-expressions}) between the point of return and the enclosing method. If such a block is captured and run later, at the point where the original call stack frame is long gone, the exception might propagate up the call stack that ran the captured block. Returning from anonymous functions does not affect the enclosing method. 

\paragraph{Memoized return expressions}
A returned expression may optionally be memoized, by using the keyword \code{memoize} right before the returned expression $e$ or ~\lstinline!return $e$!. In that case, arguments and reference to \code{self} are captured and stored along the returned value, so that further calls to the same method with the same arguments may be sped up significantly (\sref{sec:memoization}). Memoization is not available from within anonymous functions and blocks. 






\subsubsection{Local Jump Expressions}
\label{sec:local-jump-expressions}

\grammar\begin{lstlisting}
Jump_Expr 
    ::= Goto_Expr 
      | Label_Dcl
Goto_Expr 
    ::= 'goto' label_name [Cond_Modifier1]
Label_Dcl
    ::= 'label' label_name 
      | '<<' label_name '>>'
label_name 
    ::= plain_id
\end{lstlisting}

Local jumps transfer control from the points of \code{goto} statements to the statements following a \code{label}. Such a jump may only occur inside of the same function, i.e. it is not possible to jump from one method to another. Also, the jump can't happen to be from outside of a loop into a loop, but the other way around is possible. The only loop expressions that may be jumped out of are the pure loop (\sref{sec:pure-loops}) and a \code{while} loop, which are not transformed as comprehensions into method calls. 






\subsubsection{Continuations}
\label{sec:continuations}






\paragraph{Unlimited continuations}

Unlimited continuations are defined by the whole program, as the unlimited continuation allows almost arbitrary non-local jumps. The unlimited continuation is captured with \code{call/cc} function. 

\paragraph{Definitions}
The following code shows how a function that create unlimited continuations might be defined. 
\begin{lstlisting}
protocol Continuation [-A, +B] extends Function[A, B] {$\ldots$}
protocol Unlimited_Continuation [-A] extends Continuation[A, Unit] {$\ldots$}
def call/cc [A, B <: A] &(ctx: Unlimited_Continuation[A] -> B?): A end
\end{lstlisting}

A continuation, while internally holding a copy of the call stack that it was created in, is basically a function from the value that is passed into it to some other type. Unlimited continuations are restricted in the means that the input and output type has to be the same, as an unlimited continuation directly changes its result value based on that without any further modification -- the modification is to be actually performed by the code that invokes the unlimited continuation. Delimited continuations do not have this restriction, as the captured continuation is well defined and delimited to a particular scope. 

To vindicate the signature of \code{Unlimited_Continuation[A]}, it extends \code{Continuation[A, Unit]} because when invoked, it does not return any value and instead the given argument is what its \code{call/cc} application returns -- and therefore \code{call/cc} has to return a value of the same type that the unlimited continuation accepts as argument. This is unlike a delimited continuation, where invocation of the continuation does not continue from \code{reset}. 

\example The following shows how to invoke a continuation. 
\begin{lstlisting}
call/cc {|cont| cont () }
call/cc {|cont| cont 1 }
call/cc {|cont| cont 1, 2, 3 }
\end{lstlisting}
In this example, each line captures the current continuation, with unlimited scope -- the whole call stack is duplicated for that to be possible. Once a continuation is invoked, the code that follows the corresponding \code{call/cc} is resumed, with the passed arguments being the result value. On the first line, the continuation is immediately invoked with no arguments, therefore the \code{call/cc} returns the unit value ``\code{()}''. On the second line, the continuation is immediately invoked with argument \code{1}, therefore the \code{call/cc} returns the value \code{1}. On the third line, the continuation is immediately invoked with arguments \code{1, 2, 3}, therefore the \code{call/cc} returns the value \code{Sequence(1, 2, 3)}. 

Since invoking the continuation changes history and the return value of \code{call/cc}, the values passed as arguments to its invocation are limited to the expected type of the original application of \code{call/cc}. It is an error if a continuation is invoked with a value of an incompatible type. A similar restriction applies to delimited continuations as well. 

There is no requirement for functions that use unlimited continuations to define their result type with any special annotations regarding continuation passing style -- there would not be any result type available, since the whole remaining program is the result. 

The initial application of \code{call/cc} returns whatever the given block returns, and such value has to be compatible with the expected type of the \code{call/cc} application. If the block itself invokes the continuation, then its return value is discarded and replaced with the arguments of the continuation invocation. 







\paragraph{Delimited continuations}

Delimited continuations are defined with \code{reset} and \code{shift} functions. Reset and shift expressions are actually not language constructs, but rather regular functions that have a native implementation capable of unconditionally changing the standard control flow of a program. Moreover, the first \code{shift} expression (which captures the delimited continuation) controls the return value of the \code{reset} expression, which overrides the implicit return expression (\sref{sec:return-expressions}).

The difference between unlimited and delimited continuations is in the scope where the call stack is captured. With delimited continuations, that is defined by the scope of \code{reset} -- once \code{reset} is applied, there is no changing of its value, unlike with unlimited continuations, where the \code{call/cc} is similar to delimited continuation's \code{shift}. 

If the delimited continuation is stored to be used outside of \code{reset}'s bounds, then it can possibly return a value, but never modify the value of the original \code{reset} application.

A \code{reset} application is typed with its expected type and its result type is derived from the statically known contents of its passed block. If at any point there is a \code{Any} type occurring, it might propagate down into the result type. 

\paragraph{Definitions}
The following code shows how functions that create delimited continuations might be defined. 
\begin{lstlisting}
class Shift [+A, -B, +C] (val cont: Continuation[A, B] -> C) = object
  method map [A1] 
      (f: A -> A1): 
      Shift[A1, B, C] =
    Shift.new (k: Continuation[A1, B]) -> { cont((x: A) -> k(f(x))) }

  method flat_map [A1, B1, C1 <: B] 
      (f: A -> Shift[A1, B1, C1]): 
      Shift[A1, B1, C] = 
    Shift.new (k: Continuation[A1, B1]) -> { f(x).cont(k) }
}
message reset [A, C] (ctx: => @[CPS_Param[A, C]] A): C end
message shift [A, B, C] (cont: Continuation[A, B] -> C): 
    @[CPS_Param[B, C] A end

annotation CPS_Param [-B, +C] = object $\ldots$ end
type CPS_Type ['a] = CPS_Param['a, 'a]
type Suspendable = CPS_Param[Unit, Unit]
\end{lstlisting}

Here, the \code{ctx} parameter represents the block that is passed to \code{reset}. For typing, each \code{shift} block is virtually converted to a \code{for}-comprehension:
\begin{lstlisting}
let ctx == for {
  $x$ in Shift.new($y$)
} yield ($b$)
\end{lstlisting}
where $x$ is a name representing the value that is assigned with the value of the \code{shift} application, $y$ is the block passed to \code{shift}, and $b$ is the code continuation that follows the application of \code{shift} (and which may possibly include more \code{shift} applications). 

\paragraph{Note}
Here, the \code{ctx} parameter is causing the passed block to be used as a positional argument. But for the type system, the annotation \code{@[CPS_Param[A, C]]} makes the type of the argument convert to a \code{for}-comprehension as specified, similar to what workflows (\sref{sec:workflows}) do with their passed blocks. Both conversions may happen dynamically at runtime. Therefore, the passed block is eventually a regular positional argument anyway. 

\example An example of a delimited continuation in use. 
\begin{lstlisting}
reset do
  shift {|cont: Integer -> Integer|
    cont(5)
  } + 1
end
\end{lstlisting}
For the type system, it looks as if it was the following code:
\begin{lstlisting}
let ctx = for {
  x in Shift.new {|cont: Integer -> Integer|
    cont(5)
  }
} yield (x + 1)
reset(ctx)
\end{lstlisting}

\paragraph{Note}
Aml uses saguaro stack mechanisms instead of code conversions to actually implement both continuations. Due to this, the continuations are technically less limited, but the typing of its expressions may get complicated easily, as the control flow is manipulated on VM level.

% TBD: add the example from http://dcsobral.blogspot.cz/2009/07/delimited-continuations-explained-in.html and explain it step-by-step, incl. the double flat_map





\subsection[Conditions, Throwables, Raiseables \& Abandonments]{Conditions, Throwables, Raiseables\\\& Abandonments}

Aml includes an elaborate system for handling various situations that can happen while executing a program: the {\em condition system}, inspired by the one found in Common Lisp (\url{http://clhs.lisp.se/Body/09_a.htm}). 

A situation is the evaluation of an expression in a specific context, in a specific thread. A condition is an object that represents a specific situation that was detected. Condition objects are instances of the \code{Condition} trait. A hierarchy of classes of such instances is predefined in Aml, and can be indeed extended with new ones. A condition is not necessarily an error, as can be seen from the variety of use cases of the instances, including, but not limited to custom flow control operators. 

The principal traits that comprise the condition system in Aml are: 
\begin{itemize}
  \item \code{Condition}, the root condition trait. 
  \item \code{Throwable}, which extends \code{Condition}. 
  \item \code{Raiseable}, which extends \code{Throwable}. Instances of this trait represent various errors that may occur. 
  \item \code{Abandonment}, which extends \code{Raiseable}. Instances of this trait represent such conditions in program's execution, that its execution is no longer possible.\footnote{A similar thing is called fatal error or logic exception in other languages.}
\end{itemize}

An error is a situation in which normal program execution path can no longer continue correctly without some form of intervention, either interactive or under program's control. All errors are conditions, but not all conditions are errors. 

Signalling is the process by which a detected condition can alter the flow control of a program. The condition then can be handled. Aml defines \code{signal} as the major low-level function (a keyword in fact) used to signal conditions, and also a few more functions that make use of it: \code{warn} and \code{error}. 

The process of signalling involves the selection and evaluation of a handler from a list of active handlers in the thread that performs the evaluation. There are multiple ways to define a handler. One such way is to use one of the predefined functions provided by Aml that define a handler as a function of one argument (the condition object). Signalling a condition has no side-effects on the condition object. 

An invoked handler can address the situation in one of these ways: 
\begin{description}
  \item[Decline] \hfill \\
    It can decline to handle the condition, by simply returning rather than transferring control elsewhere. When this happens, any values returned by the handler are discarded and the next handler in line is invoked instead. If there is no such handler, the \code{signal} expression simply returns (with result type of \code{Unit}, the ``\,\lstinline!()!\,'' value). The function that signalled the condition may make use of that. 
  \item[Handle] \hfill \\
    It can handle the condition by performing transfer of control. There are many ways to do that, including raising an exception or invoking a restart. 
  \item[Defer] \hfill \\
    It can put off the decision, by many different ways, e.g. signalling another condition, resignalling the same condition, or even entering the debugger. 
\end{description}





\subsubsection{Signal Expressions}
\label{sec:signal-expressions}

\grammar\begin{lstlisting}
Signal_Expr 
    ::= 'signal' Expr
\end{lstlisting}

A signal expression ~\lstinline!signal $e$!~ evaluates the expression $e$. The type of this expression must conform to \code{Condition}. It is an error if $e$ evaluates to \code{nil} or ~\lstinline!()!.

Signalling a condition does not unwind the call stack.\footnote{Yes, you read it correctly. No stack unwinding when signalling a condition. Implementations of Aml may achieve this by registering handlers in thread-local storage.}





\subsubsection{Try Operator}
\label{sec:try-operator}

\grammar\begin{lstlisting}
Prefix_Expr 
    ::= Try_Op Expr
Try_Op 
    ::= 'try' 
      | 'try?' 
      | 'try!'
\end{lstlisting}

The {\em try operator} is required to be applied on expressions, where the expressions contains a function application, one such that the function to be applied are statically known to possibly raise errors (instances of \code{Raiseable}), or reraise them. 

The ~\lstinline!try!~ form is the basic form that simply allows one to use a raising function. 

The ~\lstinline!try?!~ form returns \code{nil} in case of any raised error (except for abandonments, as specified). If the result type of the applied function is default-nullable or not nullable, it is made locally nullable.\footnote{Whether the result type does not allow \code{nil} values is not important, because that only applies to the type itself without nullability specification.}

The ~\lstinline@try!@~ form works like the basic form, but does not expect the applied function to ever raise, and if it does, a runtime error is raised -- an abandonment. This has implications on the surrounding context -- the application does not need to be surrounded in \code{begin}-\code{rescue} block and the function in which the application appears does not need to declare itself as raising the unexpected error. 

The purpose of the try operator is to allow readers of the code to quickly spot the place where things can go south.





\subsubsection{Throw, Handle, Catch \& Ensure Expressions}
\label{sec:throw-catch-expressions}

\grammar\begin{lstlisting}
Catch_Expr
    ::= 'begin' (Expr - ('begin' Expr 'end'))
        ['handle' [nl] Handle_Clauses]
        'catch' [nl] Catch_Clauses
        ['ensure' [nl] Expr] 'end'
      | 'begin' (Expr - ('begin' Expr 'end')) 
        'handle' [nl] Handle_Clauses
        ['ensure' [nl] Expr] 'end'
Throw_Expr
    ::= 'throw' Expr
Catch_Clauses 
    ::= Catch_Clause {semi Catch_Clause}
        [semi Else Catch_Block]
Catch_Clause 
    ::= 'when' Pattern [Guard] ('then' | semi) Catch_Block
Catch_Block 
    ::= Expr + Rethrow_Expr
Rethrow_Expr
    ::= 'rethrow' [Cond_Modifier1]
Handle_Clauses 
    ::= Handle_Clause {semi Handle_Clause}
        [semi Else Handle_Block]
Handle_Clause 
    ::= 'when' Pattern [Guard] ('then' | semi) Handle_Block
Handle_Block
    ::= Expr + Resignal_Expr
Resignal_Expr 
    ::= 'resignal' [Cond_Modifier1]
\end{lstlisting}

A throw expression ~\lstinline!throw $e$!~ evaluates the expression $e$. The type of this expression must conform to \code{Throwable}. It is an error if $e$ evaluates to \code{nil} or ~\lstinline!()!. If there is an active \code{begin}-\code{catch} expression that handles the thrown value, evaluation is resumed with the handler, otherwise a thread executing the \code{throw} is aborted. The type of a \code{throw} expression is \code{Nothing}. 

A \code{begin}-\code{catch} expression is of the form ~\lstinline!{ $b$ } catch $h$!, where $h$ is a handler pattern matching anonymous function (\sref{sec:pattern-matching-anon-fun})
\begin{lstlisting}
{ when $p_1$ then $b_1$ $\ldots$ when $p_k$ then $b_k$ else $b_{k+1}$ } .
\end{lstlisting}

This expression is evaluated by evaluating the block $b$ -- if evaluation of $b$ does not throw any value, the result of $b$ is returned, otherwise the handler $h$ is applied to the thrown value. If the handler $h$ contains a \code{when} clause matching the thrown value, the first such clause is invoked (and may throw another value, or the same value). If the handler contains no such clause, the value is re-thrown. 

Let $T$ be the expected type of the \code{begin}-\code{catch} expression. The block $b$ is expected to conform to $T$. The handler $h$ is expected to conform to type ~\lstinline!Partial_Function[Throwable, $T$]!. The type of the \code{begin}-\code{catch} expression is the weak least upper bound (\sref{sec:conformance}) of the type of $b$ and the result type of $h$. 

A \code{begin}-\code{ensure} expression ~\lstinline!{ $b$ } ensure { $e$ }!~ evaluates the block $b$. If evaluation of $b$ does not cause any value to be thrown, the block $e$ is evaluated. If any value is thrown during evaluation of $e$, the evaluation of the whole expression is aborted with the thrown value. If no value is thrown during evaluation of $e$, the result of $b$ is returned as the result of the whole expression, unless $e$ contains an explicit \code{return} (\sref{sec:return-expressions}) -- in that case, the value returned from $e$ replaces the value returned from $b$, even if $b$ returns a value explicitly. 

If a value is thrown during evaluation of $b$, the \code{ensure} block $e$ is also evaluated. If another value is thrown during evaluation of $e$, evaluation of the whole expression is aborted with the new thrown value and the previous is discarded. If no value is thrown during evaluation of $e$, the original value thrown from $b$ is re-thrown once evaluation of $e$ has completed, unless $e$ again contains an explicit \code{return} (\sref{sec:return-expressions}) -- in that case, the value thrown from $b$ is discarded, and the value returned from $e$ is returned. 


The block $b$ is expected to conform to the expected type of the whole expression and the \code{ensure} block $e$ is expected to conform to type \code{Unit}. 

An expression ~\lstinline!{ $b$ } catch $e_1$ ensure { $e_2$ }!~ is a shorthand for ~\lstinline!{{ $b$ } catch $e_1$ } ensure { $e_2$ }!. 






\subsubsection{Raise, Handle \& Rescue Expressions}

\grammar\begin{lstlisting}
Raise_Expr     ::= 'raise' Raiseable
Raiseable      ::= string_literal
                 | Stable_Id [',' string_literal]
                 | Expr
Rescue_Expr    ::= [Label_Dcl] (Rescue_Expr1 | Rescue_Expr2)
Rescue_Expr1   ::= 'begin' Block 
                   ['handle' [nl] Handle_Clauses]
                   ['catch' [nl] Catch_Clauses]
                   'rescue' [nl] Rescue_Clauses
                   ['ensure' semi Block_Stat {semi Block_Stat}] 'end'
Rescue_Expr2   ::= '{' Block '}' 
                   ['handle' '{' Handle_Clauses '}']
                   ['catch' '{' Catch_Clauses '}']
                   'rescue' '{' Rescue_Clauses '}'
                   ['ensure' '{' Block_Stat {semi Block_Stat} '}']
Fun_Stats      ::= Block
                   ['handle' [nl] Handle_Clauses]
                   ['catch' [nl] Catch_Clauses]
                   ['rescue' [nl] Rescue_Clauses]
                   ['ensure' semi Block_Stat {semi Block_Stat}]
Rescue_Clauses ::= Rescue_Clause {semi Rescue_Clause}
Rescue_Clause  ::= 'when' Pattern [Guard] ('then' | semi) Rescue_Block
Rescue_Block   ::= {Rescue_Stat semi} [Result_Expr]
Rescue_Stat    ::= Block_Stat | Retry_Expr | Reraise_Expr
Retry_Expr     ::= 'retry' [label_name] [Cond_Modifier1]
Reraise_Expr   ::= 'reraise' [Cond_Modifier1]
\end{lstlisting}

A raise expression ~\lstinline!raise $e$!~ is similar to ~\lstinline!throw $e$! (\sref{sec:throw-catch-expressions}), it throws a value (raises an error) that is expected to be of type \code{Raiseable}. It has three variants: 
\begin{itemize}
\item[] \lstinline!raise $s$!, where $s$ is a string provided to constructor of the type \code{Runtime_Error}. 
\item[] \lstinline!raise $T$, $s$!, where $s$ is a string provided to constructor of the type $T$. 
\item[] \lstinline!raise $e$!, where $e$ is an expression, whose type is expected to conform to \code{Raiseable}, and whose result value will be raised after its evaluation. 
\item[] \lstinline!raise!, which raises a value of type \code{Runtime_Error} without any message. Such errors should not propagate outside of the method that raises them. 
\end{itemize}

\code{Raiseable} is a subtype of \code{Throwable}. 

Rescue expression ~\lstinline!rescue $h$!~ is similar to catch expression (\sref{sec:throw-catch-expressions}), with two major differences: First, each \code{rescue} is followed by \code{when} clause; second, all \code{rescue} expressions in the same scope form together a handler $h$, where rules from catch expressions apply, only that $h$ is expected to conform to type ~\lstinline!Partial_Function[Raiseable, $T$]!, where $T$ is the expected type of the whole \code{begin}-\code{rescue} expression. 

The syntactic overlap with \code{ensure} expression signifies that the same expression with the exact same behaviour may be used with \code{rescue} expressions as well. 

Optionally, the \code{rescue} may appear before any \code{begin} keyword, being connected to the function body instead as the expression protected agains raiseables (this does not apply to \code{catch}), where the \code{begin} is implied to be at the very start of the function's body. 

The ~\lstinline!retry $l$!~ expression is available inside of each raiseable handler block, and evaluating it restarts evaluation of the whole expression since \code{begin} of the labeled rescue expression, or if no label is given, then of the innermost (if nested) rescue expression. Again, it is not available in catch handler block. 

The keyword ~\lstinline[language=Java]!try!~ is not available in Aml -- in Aml, there is no trying, there is doing or not doing.  






\section{Quoted Expressions}
\label{sec:syntactic-forms}






\subsection{Quasi-quotation}
\label{sec:quasi-quotation}

\grammar\begin{lstlisting}[mathescape=false]
Quasiquote_Expr ::= '<@' Expr '@>'
Splice_Expr     ::= '#{' Expr '}'
                  | '${' Expr '}'
                  | '%%' Expr (* as prefix operator *)
\end{lstlisting}

Quasi-quote expression ``~\lstinline!<@ $e$ @>!~'' is basically a well-formed piece of Aml source code, wrapped in parentheses preceded by a backtick. The expression represents the compiled expression $e$ in means of an AST node. Alternative way to define a quasi-quoted expression is with the annotation \code{@[quasi-quote]}.

Quasi-quote expressions may optionally be interpolated, so that values or other nodes may be injected into the represented AST. There are the following ways to interpolate the AST:
\begin{itemize}
  \item Interpolating expression ``~\lstinline!#{ $e$ }!~'', where $e$'s value is expanded into the AST as is. If the expression would require parentheses around it in the source, then parentheses have to be around the interpolating expression.\footnote{Note that the same delimiters are used to interpolate string literals.}
  \item The \code{@[unquote]} annotation, which puts parentheses around the annotated expression.
  \item The \code{@[splice]} annotation, where the annotated expression is expanded into the AST as it is. Otherwise equivalent to ``~\lstinline!#{ $e$ }!~''.
\end{itemize}

A quasi-quote without any interpolation is equivalent to a quote (\sref{sec:quotation}). 

Quasi-quotes are useful in combination with macros (\sref{sec:macros}). 

An interpolating (splice or unquote) expression (like ``~\lstinline!#{ $e$ }!~'') appearing outside of a quasi-quote expression produces a compile-time warning and is replaced with $e$ directly. 





\subsection{Quotation}
\label{sec:quotation}

\grammar\begin{lstlisting}
Quote_Expr      ::= '<@@' Expr '@@>'
\end{lstlisting}

A quote expression ``~\lstinline!<@@ $e$ @@>!~'' is similar to a quasi-quote, but without any interpolation, therefore, any apparent interpolation within a quote stays just that and is never expanded (unquoted or spliced). The annotation that marks an expression for quotation is \code{@[quote]}. 





\section{Statements}
\label{sec:statements}

\grammar\begin{lstlisting}[deletekeywords={for}]
Template_Stat  ::= ? Expr, which includes the following extra elements for Expr:  ?
                   ['public'] Use_Clause
                 | [Opt_Req] {Modifier} Dcl
                 | Opt_Req [Alias_Id {',' Alias_Id}]
                 | {Modifier} Val_Def
                 | {Modifier} Var_Def
                 | {Modifier} Fun_Def
                 | {Modifier} Op_Def
                 | {Modifier} Method_Def
                 | {Modifier} Att_Def
                 | {Modifier} Multi_Fun_Def
                 | {Modifier} Multi_Op_Def
                 | {Modifier} Multi_Method_Def
                 | {Modifier} Multi_Att_Def
                 | {Modifier - 'implicit'} Macro_Def
                 | {Modifier} Ctor_Def
                 | {Modifier} PCtor_Def
                 | {Modifier} CCtor_Def
                 | {Modifier} UCtor_Def
                 | {Modifier} Dtor_Def
                 | {Modifier - Local_Modifier} Struct_Def
                 | Tmpl_Member [In_Sep Expr ['end']]
                 | Tmpl_Ifc_Impl
                 | Tmpl_Ifc_Dcl
                 | {Modifier} Struct_Spec
                 | {Modifier} Prop_Dcl
                 | {Modifier} Prop_Def
                 | {Modifier} Constraint_Dcl
                 | {Modifier} Constraint_Def
                   (* parent: *)
                 | 'inherit' Long_Id [Arguments] ['as' id] [Cond_Modifier]
                   (* mixin: *)
                 | 'inherit' 'val' (Expr - Binding_Expr) 'as' id [Cond_Modifier]
                 | 'include' Long_Id [Cond_Modifier]
                 | Expr
                 | Alias_Expr
                 | Struct_Expr
                 | Struct_Spec
                 | ()
                 | Access_Modifier [Alias_Id {',' Alias_Id}]
                 | 'invariant' '{' Block '}'
                 | Do_Binding
Scope_Stat     ::= 'scope' '(' Scope_Id ')' (Do_Block | Expr)
                 | 'defer' (Do_Block | Expr)
Scope_Id       ::= [label_name] Scope_Ending
Scope_Ending   ::= 'exit' | 'success' | 'failure' | 'throws' | 'raises'
Tmpl_Member    ::= {Modifier} 'member' Def
Tmpl_Ifc_Impl  ::= 'interface' Annot_Type
                   'with' {Annotation} Tmpl_Member {'and' {Annotation} Tmpl_Member} 
                   'end' ['interface']
Tmpl_Ifc_Dcl   ::= 'interface' Annot_Type 
                   'end' ['interface']
Alias_Expr     ::= 'alias' Alias_Id 'is' Alias_Id
Alias_Id       ::= symbol_literal
                 | id
                 | op_id
Capture_Usage  ::= 'use' Capture_List In_Sep Block_Stat ['end']
Capture_List   ::= Capture_Items {'and' Capture_Items}
Capture_Items  ::= (id {',' id} | Let_Binding) 'as' Reference_Modifier
Opt_Req        ::= 'optional' | 'required'
\end{lstlisting}

Statements occur as parts of blocks and templates. Despite their name, they are actually generally expressions as well, except that for some statements, their value is not much of a use, i.e. use clauses, whose value is a \code{()}, or the empty statement/expression, whose value is again \code{()}. Within template statements, the \code{Expr} element includes elements defined for the statement element. 






\subsection{Function-Specific Statements}

Function statements is an umbrella term for a series of statements and expressions, so their effective value is more complex. 

An expression that is used as a statement can have an arbitrary value type. An expression statement $e$ is evaluated by evaluating $e$ and discarding and releasing the result of the evaluation. 

Block statements may be definitions, which bind local names in the block. The only modifier allowed in all block-local definitions is \code{implicit}. When prefixing a class or object definition, modifiers \code{abstract}, \code{final} and \code{sealed} are also permitted (\sref{sec:modifiers}).

Evaluation of a statement sequence entails evaluation of the statements in the order they are written. This behaviour can be overridden for statement sequences in workflows (\sref{sec:workflows}).

Statement can be an import via a use clause (\sref{sec:use-clauses}), a definition or an expression, or it can be empty. Statements used in the template of a class definition can also be declarations. 

A function that is declared with \code{transparent} in its \code{declare} block, is visible as referentially transparent, and therefore the compiler and possibly the runtime as well are given the possibility to replace function applications of this same function with its previously computed result with the same arguments on the same receiver instance. In that sense, it is similar to memoization (\sref{sec:memoization}), but skips one call stack frame and works better during compilation, unlike memoization, which is a runtime feature. Moreover, all function parameters are then marked as \code{constant}. 

On the other hand, a function that is declared with \code{opaque} in its \code{declare} block, is visible as referentially opaque and those optimizations are disabled for it, so the function is re-evaluated each time it is applied. 

A function that is declared with \code{pure} has no access to the \code{self} object, the \code{Function.self} object is marked \code{constant}, and moreover, it has disabled access to all expressions that were not passed to it via arguments. However, \code{constant} is not added to its parameters. A function that is declared with \code{pure} can't be declared with \code{opaque}, as that would be contradictory. A function that is declared with \code{transparent} combines restrictions from both keywords. 

A function that is declared with \code{native} in its \code{declare} block, has its body defined outside of Aml source files. Compilation of a source code that contains such functions result in generation of necessary header files, so that the native implementation may interface with a particular Aml VM implementation. Every Aml VM that has the ability to run native functions defines its own extra annotations that may be attached to the function, to influence the header file somehow (implementation-defined). 

A function that is declared with \code{immutable} in its \code{declare} block, has the \code{self} value treated as immutable, therefore it presents a guarantee that applying it will never modify the target value. On the other hand, a function that is declared with \code{mutable} in its \code{declare} block, is no different from a function that is declared without \code{immutable} or \code{mutable}, but it presents a requirement that the target object will be mutable, and thus it is an error if it is not, and also it is an error if a function with such modifier is a member of a template that is declared \code{immutable}, because all of its member values are inherently immutable. 

An alias to a function name creates a duplicate record in method table of a class or a duplicate variable pointing to the aliased function name. From that scope on, the functions are bound by name, and aliased function names are also inherited. If a subtype attempts to override an aliased method, then all methods with that alias are overridden as well. 

The \code{Capture_Usage} syntax construct (of the forms ~\lstinline{use $\id_1 \commadots \id_n$ as weak}, ~\lstinline{use $\id_1 \commadots \id_n$ as unowned} and ~\lstinline{use $\id_1 \commadots \id_n$ as soft}), or combinations of those, provide a way to define ownership of captured variables in blocks and anonymous functions. Every captured variable is stored as a property within the function object, and therefore it takes an ownership of the pointed object. By using this construct, the default strong reference can be replaced with a \code{Weak_Reference[T]}, an \code{Unowned_Reference[T]} or a \code{Soft_Reference[T]}, with automatic unwrapping and wrapping of read and written values. It is an error if $\id_i$ is not a variable name in an enclosing scope. If a let binding is used in the capture usage syntax construct, all variables bound by it are captured with the given ownership






\subsection{Template-Specific Statements}

When \code{optional} or \code{requires} appear in a template, the following message declarations are either optional or required. When a message declaration is optional, then its result type is always nullable. No restriction is put on required messages. When those keywords appear alone on a line, then all following message members are affected. When the keywords directly precede a message member declaration, then only that member is affected. If the keyword precedes a list of identifiers or symbols, message members of those names are affected. 

When \code{public}, \code{protected} or \code{private} appear in a template, the following member declarations have their accessibility affected. When those keywords appear alone on a line, then all following message members are affected. When the keywords directly precede a message member declaration, then only that member is affected. If the keyword precedes a list of identifiers or symbols, message members of those names are affected. 

The \code{public use} combination, besides importing names into scope as per (\sref{sec:use-clauses}), also defines the imported names. Another way to see that is to say that the combination re-exports the imported names. 





\subsection{Contracts}

A body of a contract should consist only of assert expressions, in form of \lstinline!assert $e$!, and also be side-effect free. As a contract, an assert expression represents a guarantee that the code in its expression must uphold. The expected type of the asserted expression is \code{Boolean}, and can employ implicit conversions to get a boolean value, but only those available in the scope. If the asserted expression evaluates to \code{no}, then the contract is broken and \code{Contract_Broken} is raised. 

A function be declared with contract blocks in its definition:
\begin{itemize}
  \item Input contracts ({\em preconditions}) in form of \lstinline!in { $e$ }!.
  \item Output contracts ({\em postconditions}) in forms of either \lstinline!out { |$p$| $e$ }! or \lstinline!out { $e$ }!. If the variable $p$ is specified, its type is inferred from the result type of the function. The variable $p$ references the result value, and the contract code can't change its content. 
\end{itemize}

A template may contain an invariant contract in its definition, in form of \lstinline!invariant { $e$ }!.

Contracts are by default always evaluated when needed, unless they are marked as only debugging by annotations. The times contract have to be evaluated are after constructors are finished and around calls to public methods. Contracts are inherited by traits and classes alike, and the implicit ordering is to run inherited contracts before own contracts. 

The exact location of evaluation of an inherited contract can be overridden by application of \code{super} (without arguments) in the contract's code. Contract blocks can access all parameters (except the invariant contract) of the function application, but the output contract may\footnote{Well, only if somebody does update those variables.} see updated values of parameters in mutable variables. 
% TBD: add names for those annotations

The evaluation order of contracts code is:
\begin{enumerate}
  \item Preconditions (excluding parameter-less constructors)
  \item Invariant (excluding constructor, where the invariant may not yet be met)
  \item Constructor chain or function body
  \item Invariant
  \item Postconditions
\end{enumerate}

Applications of public methods on the object tested for invariant that are nested in any contract's code do not repeat invariant contract evaluations, instead, only the first and last are evaluated. Preconditions and postconditions are evaluated for every such nested application. 

Every type can have only up to one own invariant contract. There is no limit on inheritance of invariant contracts -- there is always only up to one from each parent type. 





\subsection{Scope Guard Statements}

A {\em scope guard statement} ~\lstinline!scope ($l$ $x$) do $e$ done!~ executes the immediately following block or expression ($e$) at the end of an enclosing scope, rather than at the point where it appears. Values defined at the point of its appearance are available also in the executed block or expression. A scope guard statements comprise also a scope ending identifier (combination of optional label $l$ and required ending type $x$). 

\begin{itemize}
  \item \lstinline!scope (exit)!~ executes no matter how the enclosing scope ended. 
  \item \lstinline!scope (success)!~ executes if the enclosing scope ended normally. 
  \item \lstinline!scope (failure)!~ and ~\lstinline!scope (raises)!~ executes if the enclosing scope ended due to stack unwinding caused by a raised error.\footnote{It is possible that a particularly annotated \code{goto} may be treated as scope failure, then the former one executes.}
  \item \lstinline!scope (throws)!~ executes if the enclosing scope ended due to stack unwinding caused by a thrown value, including raised errors.
\end{itemize}

A scope guard statement with a specified label is executed always at end of the closest enclosing scope that has the same label.\footnote{Useful to execute scope guards conditionally.} If no label is specified, then the directly enclosing scope is taken. 

Scope guard statements are executed in reverse order of their lexical appearance (like if they were stacked). 

Scope guard statements are not allowed to exit by throwing a value, jumping out with a \code{goto}, using loop control expressions (such as \code{continue} or \code{break}) or return expressions, nor they may be entered with a \code{goto}.

The scope guard statement ~\lstinline!defer do $e$ done!~ is equivalent to ~\lstinline!scope (exit)!.





\section{Implicit Conversions}
\label{sec:implicit-conversions}

Implicit conversions can be applied to expressions whose type does not match their expected type, to qualifiers in selections, and to unapplied methods. The available implicit conversions are given in the next two sub-sections.

We say that a type $T$ is {\em compatible} to a type $U$ if $T$ weakly conforms to $T$ after applying eta-expansion (\sref{sec:eta-expansion}) and view applications (\sref{sec:views}), if necessary.






\subsection{Value Conversions}
\label{sec:value-conversions}

The following implicit conversions can be applied to an expression $e$, which is of some value type $T$ and which is type-checked with some expected type $\exptype$. Some of these implicit conversions may be disabled with pragmas.

\paragraph{Overloading resolution}
If an expression denotes several possible members of a class, overloading resolution (\sref{sec:overloading-resolution}) is applied to pick a unique member. 
\paragraph{Numeric widening}
If $e$ is of a number type which weakly conforms (\sref{sec:conformance}) to the expected type, it is widened to the expected type. 

\paragraph{Numeric narrowing}
If the expected type has smaller range than the number type of $e$, but the value of $e$ fits into the expected type, it is narrowed to the expected type. 

\paragraph{Value discarding}
If $e$ is of some value type and the expected type is \code{Unit}, $e$ is converted to the expected type by embedding it in the block ~\lstinline!{ $e$; () }!. 

\paragraph{View application}
If none of the previous conversions applies, view applications are not disallowed by pragmas (implicitly they are allowed), and $e$'s type does not conform to the expected type $\exptype$, an attempt is made to convert $e$ to the expected type with a view application (\sref{sec:views}). This can happen in compile time only if all necessary type information is available, otherwise, runtime handles it by using specialized instructions (and those instructions are disabled from compilation when view applications are disabled). 

\paragraph{Dynamic member selection}
If none of the previous conversions applies, and $e$ is a prefix of a selection ~\lstinline!$e$.$x$!, then if $e$'s type conforms to \code{Dynamic_Member_Selecting}, the selection is rewritten according to rules for dynamic member selection (\sref{sec:dynamic-member-selection}). 

% TBD: explain in a GFR how dynamic member selecting actually works on the Aml VM level - registering a method fallback chain if a member is not found, here it is like %[:apply_dynamic; :member_not_found], and determine what happens when this is not done (no-op maybe? error maybe? language config error maybe?)





\subsection{Method Conversions}
\label{sec:method-conversions}

The following implicit conversions can be applied to methods which are not applied to any arguments. 

\paragraph{Evaluation}
A parameterless method $m$ of type ~\lstinline!() -> $T$!~ is always converted to type $T$ by evaluating the expression to which $m$ is bound. 

\paragraph{Implicit application}
If the method takes only implicit parameters, implicit arguments are passed following the rules of (\sref{sec:implicit-parameters}).

\paragraph{Eta expansion}
Otherwise, if the expected type $\exptype$ is a function type ~\lstinline!($\Ts'$) -> $T'$!, eta-expansion (\sref{sec:eta-expansion}) is performed on the expression $e$. 

\paragraph{Empty application}
Otherwise, if $e$ is of a method type ~\lstinline!() $\mapsto\ T$!, it is implicitly applied to the empty argument list, yielding ~\lstinline!$e$()!. 






\subsection{Overloading Resolution}
\label{sec:overloading-resolution}

\paragraph{Deprecated}
Will need to rewrite this with respect to the updated function application forms, and automatic type inference. 

If an identifier or selection $e$ references several members of a class, the context of the reference is used to identify a unique member, if possible. The way this is done depends on whether or not $e$ is used as a function. Note that even if overloaded resolution picks up a unique member, that member still may not be applied in regard of the actual expected types of the function application. Let $\mathcal{A}$ be the set of members referenced by $e$. Overloading resolution of $e$ is applied after local type inference, although local type inference may play part in overloading resolution of nested argument expressions, which are applied separately. 

\subsubsection{Function in an application}

Assume first that $e$ appears as a function in an application, as in ~\lstinline!$e$($e_1 \commadots e_m$)!.

\paragraph{Shape-based overloading resolution}
One first determines the set of functions that are potentially applicable based on the {\em shape} of the arguments. 

The shape of an argument expression $e$, written ~\lstinline!$\shape$($e$)!, is a type that is defined as follows:
\begin{itemize}
\item For a function expression ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$) -> $b$!, the shape is ~\lstinline!(Any$\commadots\,$Any) -> $\shape$($b$)!, where \code{Any} occurs $n$ times in the argument type. 
\item For a named argument ~\lstinline!$n$: $e$!, the shape is ~\lstinline!@[named_arg :$n$] $\shape$($e$)!, which is an annotated type.\footnote{This is different from e.g. Scala, since Aml supports capturing named arguments, which make the definition of applicable functions different.} % TBD: fix the name of the annotation as it will be chosen over time. 
\item For all other expressions, the shape is \code{Nothing}. 
\end{itemize}

Let $\mathcal{B}$ be the set of alternatives in $\mathcal{A}$ that are {\em applicable} (\sref{sec:function-applications}) to expressions ~\lstinline!($e_1 \commadots e_n$)!~ of types ~\lstinline!($\shape$($e_1$)$\commadots \shape$($e_n$))!. If there is precisely one alternative in $\mathcal{B}$, that alternative is chosen. It is an error if that alternative is not applicable to the expected types of the argument expressions -- the method is unapplied (\sref{sec:value-conversions}). 

\paragraph{Argument counts based overloading resolution}
Otherwise, let $S_1 \commadots S_m$ be the vector of types obtained by typing each argument with an undefined expected type (kind of equivalent to typing it with \code{Any}), keeping the annotations of named arguments attached (from the previous step with the shape of arguments). For every member $m$ in $\mathcal{B}$, one determines whether it is applicable to expressions ~\lstinline!($e_1 \commadots e_m$)!~ of types $S_1 \commadots S_m$, which drops requirements set up by ~\lstinline!$\shape$($e$)!, namely those for function expressions, and therefore members in $\mathcal{B}$ are more likely to be selected. It is an error if none of the members in $\mathcal{B}$ are applicable -- the method is unapplied. If there is one single applicable alternative, that alternative is chosen. 

\paragraph{Applicability based overloading resolution}
Otherwise, let $\mathcal{C}$ be the set of applicable alternatives in the application to $e_1 \commadots e_m$. It is again an error if $\mathcal{C}$ is empty. Otherwise, one chooses the {\em most specific} alternative among the alternatives in $\mathcal{C}$, according to the following definition of being  ``more specific than''.

\paragraph{Triggered early evaluation}
If any of the corresponding parameter types of any alternative in $\mathcal{C}$ is a constrained type (\sref{sec:constrained-types}) or non-trivial pattern\footnote{Non-trivial patterns are all patterns that are not variable patterns or typed patterns -- but a typed pattern with a constrained type is considered non-trivial as well.}, an early argument evaluation is triggered, exactly once per each corresponding argument, to detect whether the alternative is applicable to the constrained type or if the pattern matches. 

\begin{definition}
The {\em relative weight} of an alternative $A$ over an alternative $B$ is defined as the sum of relative weights of each argument $e_i$ in the application to $e_1 \commadots e_m$. In the following equation, $A_i$ is the type of the parameter corresponding to $e_i$ in the alternative $A$, and $B_i$ is the type of the parameter corresponding to $e_i$ in the alternative $B$. 

\[\begin{array}{l l}
\weight(A, B) &= \sum_{i=1}^{m} \pweight(A_i, B_i) \\
\pweight(t, u) &= \cweight(t, u) + \rweight(t)
\end{array}
\]

\[\begin{array}{l l}
\cweight(t, u) &= \left\{ 
  \begin{array}{l l}
    1 & \textrm{if $t \conforms u$}\\
    0 & \textrm{otherwise}
  \end{array} \right. \\
\rweight(t) &= \left\{ 
  \begin{array}{l l}
    1 & \textrm{unless $t$ is a variadic or a capturing named parameter}\\
    0 & \textrm{otherwise}
  \end{array} \right.
\end{array}\]
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the relative weight of $A$ over $B$ is greater than the relative weight of $B$ over $A$. 

\paragraph{Generics based overloading resolution}
If there are more alternatives in $\mathcal{C}$ that are equally most specific, then let $\mathcal{D}$ be those equally most specific alternatives. One chooses the most specific alternative from $\mathcal{D}$ based on the following redefinition of being ``more specific than''. 

\begin{definition}
The {\em generic relative weight} of an alternative $A$ over an alternative $B$ is a number between $0$ and $1$, defined as follows:
\begin{itemize}
  \item $1$, if $A$ is not polymorphic and $B$ is polymorphic. 
  \item $0$, in any other case. 
\end{itemize}
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the generic relative weight of $A$ over $B$ is greater than the generic relative weight of $B$ over $A$. 

If there are more alternatives in $\mathcal{D}$ that are equally most specific, continue with overloading resolution on $\mathcal{D}$ using preference declarations. If that fails, one chooses one alternative from $\mathcal{D}$ as in overloading resolution without any application (\sref{sec:overloading-resolution-no-app}), where $\mathcal{A}$ is the same as $\mathcal{D}$ here, and the expected type is the expected type of the function application, unless there are consecutive function applications. 

\paragraph{Consecutive applications based overloading resolution}
If there are any consecutive function applications (\sref{sec:curried-functions}) involved, then let $\mathcal{E}$ be those alternatives from $\mathcal{D}$ that have no following parameter lists, and let $\mathcal{F}$ be those alternatives from $\mathcal{D}$, for which one of the following conditions is true:
\begin{itemize}
  \item There are $a$ following consecutive function applications and the alternative has $a$ more parameter lists. The last parameter list may or may not be marked \code{implicit}, it does not matter. 
  \item There are $a$ following consecutive function applications and the alternative has $a + 1$ more parameter lists, and the last one is marked \code{implicit}. Note that $a$ might be 0, so that methods with an extra implicit parameter list are preferred. 
  \item There are $a$ following consecutive function applications and the alternative has more than $a$ more parameter lists, and the whole expression containing the consecutive function applications is enclosed in a method value, for partial application. 
\end{itemize}
Then, if $\mathcal{F}$ is not empty, apply overloading resolution on $\mathcal{F}$ recursively, omitting the already processed parameter list and argument list in each turn. If overloading resolution on $\mathcal{F}$ selects a unique member, that one is chosen. If no unique alternative from $\mathcal{F}$ could be selected (either because none was applicable, or there were multiple applicable alternatives at the end of recursion), continue with overloading resolution on alternatives from $\mathcal{E}$ using preference declarations. If $\mathcal{E}$ is empty, it is an error. 

\paragraph{Declared preference based overloading resolution, using arguments preference}
Let $\mathcal{G}$ be those alternatives that are supposed to be resolved based on declared preference (there are two points from which this can happen). One finds all preference declarations using arguments filter (not limited to) for each alternative over other alternatives in $\mathcal{G}$. If there is one alternative in $\mathcal{G}$ that is preferred strictly more times than any other alternative, then that one is chosen. Otherwise, one continues with overloading resolution without any application (\sref{sec:overloading-resolution-no-app}), where $\mathcal{A}$ is the same as $\mathcal{G}$ (i.e. no elements from $\mathcal{G}$ are left out). 

\paragraph{Note}
Nested overloading resolutions happen in depth-first order. If an alternative is polymorphic, it needs to be type-reified with local type inference to first determine what the types are. If an argument expression is itself overloaded, overloading resolution needs to be applied on it first and alone, and the expected type of the argument expression defined by the local type inference algorithm. Notice that this is safe in regard to local type inference of the enclosing alternative, since the type of the argument expression is just a part of type bounds for the enclosing alternative. Indeed, ambiguities may need to be resolved explicitly. 

\example Assume the following overloaded function definitions:
\begin{lstlisting}
def f (*x: Integer) end             (* 1. *)
def f (x: Integer) end              (* 2. *)
def f (x: Integer, y: Integer) end  (* 3. *)
\end{lstlisting}

In the application \code{f(1)}, there are two applicable alternatives in regard to both shape and argument counts -- the first two. Applicability test gives relative weight to $(1)$ over $(2)$ of $1$, since it has a repeated parameter, and relative weight to $(2)$ over $(1)$ of 2, therefore the second is chosen. 

In the application \code{f(1, 2)}, there are again two applicable alternatives -- the first and the last. Applicability test gives relative weight to $(1)$ over $(3)$ of $2$, since it has a repeated parameter matching both arguments, and relative weight to $(3)$ over $(1)$ of $4$, therefore the second is chosen. 

In the application \code{f(1, 2, 3)}, there is only one applicable alternative (the first), which can be detected (as soon as) based on the shape of its argument expressions. 






\subsubsection{Function in a type application}

Assume next that $e$ appears as a function in an explicit type application (not inferred), as in ~\lstinline!$e$[$\targs$]!. Then let $\mathcal{B}$ be the set of all alternatives in $\mathcal{A}$ which take the same number of type parameters as there are type arguments in $\targs$ are chosen. It is an error if no such alternative exists -- the type application is unapplied. If there is one such alternative, that one is chosen. 

Otherwise, let $\mathcal{C}$ be the set of those alternatives in $\mathcal{B}$ that are applicable to the type arguments, so that the bounds defined by the alternative's type parameters are satisfied. It is an error if no such alternative exists. If there are several such alternatives, overloading resolution (different than this case: so either in a function application or not in a function application) is applied to the whole expression ~\lstinline!$e$[$\targs$]!. 






\subsubsection{Expression not in any application}
\label{sec:overloading-resolution-no-app}

Assume finally that $e$ does not appear as a function in either an application or a type application, (or that overloading resolution on a function in an application was left with several most specific alternatives). If an expected type is given, let $\mathcal{B}$ be the set of those alternatives in $\mathcal{A}$ which are compatible (\sref{sec:implicit-conversions}) to it. Otherwise, let $\mathcal{B}$ be the same as $\mathcal{A}$. It is an error if there is no such alternative. If there is one such alternative, that one is chosen. 

Otherwise, one chooses the {\em most specific} alternative among the alternatives in $\mathcal{B}$, according to the following definition of being ``more specific than'':

\begin{definition}
The {\em relative weight} of an alternative $A$ over an alternative $B$ is defined as a number from $0$ to $2$, defined as the sum of:
\begin{itemize}
  \item $1$ if $A \conforms B$, $0$ otherwise, and
  \item $1$ if $A$ is not polymorphic and $B$ is polymorphic, $0$ otherwise.
\end{itemize}
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the relative weight of $A$ over $B$ is greater than the relative weight of $B$ over $A$. 

If there are multiple most specific alternatives in $\mathcal{B}$, one chooses an alternative from $\mathcal{B}$, which is strictly more times preferred to the other alternatives in $\mathcal{B}$, based on preference declarations that include a result type filter for that alternative.\footnote{This is needed to resolve ambiguities in cases such as when the expected type is the least upper bound of the result types of two or more overloaded alternatives.}

It is an error if there is no alternative in $\mathcal{B}$ which is more specific than all other alternatives in $\mathcal{B}$ -- the method is unapplied.\footnote{This can be fixed e.g. by using typed expressions (\sref{sec:typed-expressions}).}

\paragraph{Note}
An important note is that when an identifier $e$ references several members of a class, it also references only those members that are visible (\sref{sec:modifiers}) from the scope where $e$ appears. 

% TBD: maybe add more examples? including named arguments, optional arguments...





\subsection{Eta-Expansion}
\label{sec:eta-expansion}

{\em Eta-expansion} converts an expression of a method type (not a function application) to an equivalent expression of a function type. It is especially useful to prevent re-evaluation of the expression's subexpressions, if the expression is passed using a by-name strategy. It proceeds in two steps. 

First, one identifies the maximal subexpressions of $e$, let's say these are $e_1 \commadots e_m$. For each of these, one creates a fresh name $x_i$. Let $e'$ be the expression resulting from replacing every maximal subexpression $e_i$ in $e$ by the corresponding fresh name $x_i$. Second, one creates a fresh name $y_i$ for every argument type $T_i$ of the method, for $i = 1 \commadots n$, using named arguments and parameters as defined by the method. The result of eta-expansion is then: 
\begin{lstlisting}
{
  let $x_1$ = $e_1$ in
  $\ldots$
  let $x_m$ = $e_m$ in
  do |$y_1$: $T_1 \commadots y_n$: $T_n$| $e'$($y_1 \commadots y_n$) done
}
\end{lstlisting}

\example A few examples of eta-expansion, the original expression and eta-expanded below it:
\begin{lstlisting}
(* expression: *)
&((1 .. 9).fold(z))
(* expands to: *)
{ let eta1 = z in
  let eta2 = (1 .. 9) in
  do |x| eta2.fold(eta1)(x) done 
}
\end{lstlisting}







\subsection{Dynamic Member Selection}
\label{sec:dynamic-member-selection}

Aml defines a trait \code{Dynamic_Member_Selecting} that enables dynamic invocations rewriting. 

% TBD: define the trait, make use of ?- operator










