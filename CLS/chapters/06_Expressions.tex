%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\chapter{Expressions}

% TBD: update this chapter and the syntax gradually as the CLS evolves

\syntax\begin{lstlisting}
Expr        ::= Cond_Expr
              | Loop_Expr
              | Rescue_Expr
              | Raise_Expr
              | Throw_Expr
              | Catch_Expr
              | Return_Expr
              | Assign_Expr
              | Update_Expr
              | Yield_Expr
              | Infix_Expr
              | Simple_Expr
              | Match_Expr
              | Binding
              | Annot_Expr
              | Cast_Expr
              | Use_Expr
              | Jump_Expr
              | Anon_Fun
              | Anon_Class
              | Metaclass_Access
              | Workflow_Expr
              | Quasiquote_Expr
Infix_Expr  ::= Prefix_Expr
              | Infix_Expr [op_id Infix_Expr]
Simple_Expr ::= Block_Expr
              | ['&'] Simple_Expr1
              | '&' '(' Simple_Expr1 ')'
Result_Expr ::= Anon_Params '->' Block 
              | ['memoize'] Expr
\end{lstlisting}

Expressions are composed of various keywords, operators and operands. Expression forms are discussed subsequently. 







\section{Expression Typing}
\label{sec:expression-typing}

The typing of expressions is often relative to some {\em expected type} (which might be undefined). When we write ``expression $e$ is expected to conform to type $T$'', we mean:
\begin{enumerate}
\item The expected type of $e$ is $T$.
\item The type of expression $e$ must conform to $T$. 
\end{enumerate}

Usually, the type of the expression is defined by the last element of an execution branch, as discussed subsequently with each expression kind. 

What we call ``statement'', in context of Coral is in fact yet another kind of an expression, and those expressions themselves always have a type and a value. 





\section{Literals}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Literal
\end{lstlisting}

Typing of literals is as described in (\sref{sec:literals}); their evaluation is immediate, including non-scalar literals (collection literals). 






\subsection{The Nil Value}

\syntax\begin{lstlisting}
Simple_Expr1 ::= 'nil'
\end{lstlisting}

The \code{nil} value is of type \code{Nothing}, and is thus compatible with every type that is nullable (\sref{sec:nullability}), either preferably or explicitly.

The \code{nil} represents a ``no object'', and is itself represented by an object. This object overrides methods in \code{Object} as follows: 
\begin{itemize}
\item 
\lstinline!equals($x$)! and \lstinline!=($x$)! return \code{yes} if the argument $x$ is also the \code{nil} object. 

\item 
\lstinline@!=($x$)@ return \code{yes} if the argument $x$ is not the \code{nil} object.

\item
\lstinline[mathescape=false]!as_instance_of[$T]()! returns always \code{nil}. 

\item
\lstinline!hash_code()! returns \code{0}. 
\end{itemize}

A reference to any other member of the \code{nil} object causes \code{Method_Not_Found_Error} or \code{Member_Not_Found_Error} to be raised, unless the member in fact exists.\footnote{It is even possible to use a refinement to actually implement some methods of \code{nil} locally (preferred approach), or globally implement those methods (discouraged, causes warnings).} 






\section{Designators}
\label{sec:designators}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Path
               | '(' Anon_Class ')' '.' Selection
               | Simple_Expr '.' Selection
Selection    ::= ['?'] id
\end{lstlisting}

A designator refers to a named term. It can be a {\em simple name} or a {\em selection}.

A simple name $x$ refers to a value as specified in (\sref{sec:identifiers-names-scopes}). If $x$ is bound by a definition or a declaration in an enclosing class or object $C$, it is taken to be equivalent (at the resolution time) to the selection ~\lstinline!$C$.self.$x$!, where $C$ is taken to refer to the class or object containing $x$, even if the type name $C$ is shadowed at the occurrence of $x$. 

If $r$ is a stable identifier (\sref{sec:type-paths}) of type $T$, the selection ~\lstinline!$r$.$x$!~ refers to a member $m$ of $r$ that is identified in $T$ by the name $x$. 

For other expressions $e$, ~\lstinline!$e$.$x$!~ is typed as if it was ~\lstinline!{ val $y$ := $e$; $y$.$x$ }!, for some fresh name $y$. 

The selection ~\lstinline!$e$.?$x$!~ is typed as if it was 
\begin{lstlisting}
{ val $y$ := $e$; if $y$ != nil then $y$.$x$ else nil }
\end{lstlisting}
for some fresh name $y$; also called {\em safe navigation} or {\em safe selection}. 

The expected type of a designator's prefix is undefined. The type of a designator is the type $T$ of the entity it refers to. 

The selection ~\lstinline!$e$.$x$!~ is evaluated by first evaluating the qualifier expression $e$, which yields an object $r$. The selection's result is then the member $m$ of $r$ that is either defined by $m$ or defined by a definition overriding $m$. 







\section{Self, This \& Super}
\label{sec:self-this-super}

\syntax\begin{lstlisting}
Simple_Expr1 ::= [Path '.'] 'self' ['[' ('cloned' | 'origin') ']']
                 ['.' Selection]
               | [Path '.'] 'this' ['[' ('cloned' | 'origin') ']']
                 ['.' Selection]
               | [Path '.'] 'super' ['[' ('cloned' | 'origin') ']']
                 [Class_Qualifier] 
                 ['.' Selection]
               | [Path '.'] Selection
\end{lstlisting}

The expression \code{self} stands always for the current instance in the context (and in function resolution searches in the actual class of the instance) in the innermost template containing the reference (thus excluding blocks and anonymous functions). 

The expression \code{this} is the same as \code{self}, except that function resolution searches from the class that this expression appears in, possibly skipping overrides in subtypes of the actual class of \code{self}. The \code{this} expression is interchangeable with \code{self} in the following paragraphs, although use of \code{self} is preferred. 

The expression ~\lstinline!$C$.self!~ refers to the current instance in the context of the enclosing (or even directly enclosing) type $C$. It is an error if $C$ is not an enclosing type. The type of the expression is the same as ~\lstinline!$C$.self.type!. 

A reference ~\lstinline!super.$m$!~ refers to a method or type $m$ in the least proper supertype of the innermost template containing the reference. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

A reference ~\lstinline!$C$.super.$m$!~ refers to a method or type $m$ in the least proper supertype of the innermost class or object definition named $C$, which encloses the reference. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

The \code{super} prefix may be followed by a qualifier ~\lstinline![$T$]!, as in ~\lstinline!$C$.super[$T$].$m$!. In this case, the reference is to the type or method $m$ in the parent class or trait of $C$, whose simple name is $T$. The qualifier allows also paths, in case multiple supertypes had the same simple name, working as a suffix search -- the name $T$ then refers the parent class or trait of $C$, whose qualified name ends with $T$. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 






\section{Use Expressions}
\label{sec:use-expressions}

\syntax\begin{lstlisting}
Use_Expr    ::= Use_Expr_As | Use_Aspect
Use_Expr_As ::= 'use' Simple_Expr ('as' | 'as!' | 'as?')
                [id ':'] Type [Block_Expr]
Use_Aspect  ::= 'use' 'aspect' Path [Block_Expr]
\end{lstlisting}

Use expressions of the form ~\lstinline!use $e$ as $a$: $T$!~ are similar to typed expressions (\sref{sec:typed-expressions}). Their intention is to rebind an expression to a specific type (changing its expected type), and then either have this type to be effective in the same scope from that point onward, or, if a \code{Block_Expr} is syntactically given, only in the scope of that block expression. If a block is given, then the return value of the block is the value of this expression, otherwise, the value retrieved by evaluation of \code{Simple_Expr} is the value of this expression. Conversions described in typed expressions (\sref{sec:typed-expressions}) apply in these expressions as well, including the differences between \code{as} and ~\lstinline@as!@. 

Use expressions of the form ~\lstinline!use aspect $T$!~ enable the specified aspect, either in the scope defined by the given block, or if no block is given, then from that point onward. If the expression is used as a template statement, then the aspect is enabled for the whole template anywhere, if it does not have the block part. 








\section{Function Applications}
\label{sec:function-applications}

\syntax\begin{lstlisting}
Simple_Expr1   ::= Simple_Expr1 Argument_Exprs 
Argument_Exprs ::= Parens_Args {Parens_Args} [Block_Expr] 
                 | Poetry_Args [Block_Expr2]
                 | Block_Expr
                 
Parens_Args ::= '(' Args_Expr ')'
Poetry_Args ::= Args_Expr
Args_Expr   ::= [[Arg_Exprs ','] '*' Expr ','] Arg_Exprs [',' '**' Expr]
              | [Arg_Exprs ','] '*' Expr [',' '**' Expr]
              | '**' Expr
Arg_Exprs   ::= Arg_Expr {',' Arg_Expr}
Arg_Expr    ::= [['out'] [id ':'] | '&'] Expr
\end{lstlisting}

A function application ~\lstinline!$f$($e_1 \commadots e_m$) $b$!~ applies the function $f$ to the argument expressions $e_1 \commadots e_n$ and passes the block expression $b$ (\sref{sec:blocks}) into it. If $f$ has a method type ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$) $\mapsto\ U$!, the type of each argument expression $e_i$ is typed with the corresponding parameter type $T_i$ (\sref{sec:corresponding-parameters}) as expected type. Let $S_i$ be type of argument $e_i$ (for $i = 1 \commadots m$). If $f$ is a polymorphic method, local type inference (\sref{sec:local-type-inference}) is used to determine type arguments for $f$. If $f$ is of a value type, the application is taken to be equivalent to ~\lstinline!$f$.apply($e_1 \commadots e_m$)!, i.e. the application of an \code{apply} method defined by $f$. 






\subsection{Argument Evaluation Strategies}
\label{sec:arg-eval-strategies}

Coral defers evaluation of arguments up to the point of function application, and happens then as specified in parameter evaluation strategies (\sref{sec:param-eval-strategies}). The type that each argument is type-checked against the corresponding parameter type (defined as follows) is the expected type of the argument expression, i.e. not its actual concrete type, which is known only after its evaluation. If the expected type is undefined, then \code{Object} is assumed. Typed expressions (\sref{sec:typed-expressions}) may be used to give the argument expression a concrete expected type. When the argument expression is evaluated, it is evaluated as if it were in the scope of the function application (which it is), so that visibility rules from that scope apply. 






\subsection{Corresponding Parameters}
\label{sec:corresponding-parameters}

The argument expressions $a_1 \commadots a_n$ can be split up to 3 virtual sections: 
\begin{itemize}

\item[] {\em Positional parameters}. Let's refer to them as $p_{1,i,j}$. These are defined by any number of mandatory parameters (where $i = 1$), followed by any number of optional parameters (where $i = 2$), followed by at most one repeated parameter (where $i = 3$ and $j = 1$), ended by any number of post mandatory parameters (where $i = 4$). 

\item[] {\em Named parameters}. Let's refer to them as $p_{2,i}$, where $i$ is the position of the named parameter among the section of named parameters. 

\item[] {\em Block capturing parameter}. Let's refer to it as $p_{3,1}$

\end{itemize}
To pair argument expressions with corresponding parameters, the following steps are to be taken:
\begin{enumerate}

\item Say that a {\em positional argument} is of the form $a_i$. 

\item Say that a {\em named argument} is of the form ~\lstinline!$x_i$: $a'_i$!, where $x_i$ is one of the named parameter names from the named parameters section. 

\item Say that $n_1$ is the count of positional arguments. If the last argument is prefixed with ``\lstinline!&!'':
\begin{itemize} 
\item If the captured block parameter is defined and a block $b$ is given, count the last argument also as a positional argument. It is an error if there are named arguments before it. 
\item If the captured block parameter is defined and a block $b$ is not given, do not count the last argument as a positional argument. 
\item If the captured block parameter is not defined and a block $b$ is given, count the last argument also as a positional argument. It is an error if there are named arguments before it. 
\item If the captured block parameter is not defined and a block $b$ is not given, count the last argument also as a positional argument. It is an error if there are named arguments before it. 
\end{itemize}

\item Say that $m_1$ is the count of mandatory parameters. Pair each $a_i$ for $1 \leq i \leq m_1$ with $p_{1,1,i}$. 

\item Say that $m_2$ is the count of post mandatory parameters. Pair each $a_i$ for $(n_1 - m_2) \leq i \leq m_2$ with $p_{1,4,i}$.

\item Say that $m_3$ is the count of optional parameters. Pair each $a_i$ for $m_1 < i < m_2$ with $p_{1,2,i}$, if $p_{1,2,i}$ is an optional parameter. If $p_{1,2,i}$ is not an optional parameter, collect the arguments that don't have a corresponding optional parameter into a sequence and pair it as a single argument with $p_{1,3,1}$. This finishes the positional arguments section. 

\item Let $\sigma i$ be a substitution from the named argument name's position in the function application's named arguments section to its position in the named parameters section of the function parameters definition. If the named argument has a name that is not defined in the function parameters definition, then the position of the capturing named parameter is returned, if it exists. It is an error if the substitution does not return any position, in the sense that the function is not applicable to the given arguments, defined also as follows. 

\item Say that $n_2$ is the count of named arguments. Pair each $a_{\sigma i}$ for $1 \leq i \leq n_2$ with $p_{2,i}$. 

\item Say that $n_3$ is the count of arguments given after the section of named arguments. If $n_3 = 0$, then pair the given block $b$ with $p_{3,1}$, or pair \code{nil} with $p_{3,1}$, if no block $b$ is given. If $n_3 = 1$, then pair the last unpaired argument with $p_{3,1}$. If $n_3 > 1$, it is an error, in the sense that the function is not applicable to the given arguments, defined also as follows. 
\end{enumerate}

The type of each argument expression $a_i$ is typed with the corresponding parameter type $T_i$ as expected type. 






\subsection{Applicable Function}

The function $f$ must be applicable to its arguments $a_1 \commadots a_n$ of types $S_1 \commadots S_n$. 

If $f$ has a method type ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$)$R$!, the function $f$ is applicable if all of the following conditions hold:
\begin{itemize}

\item For every named argument ~\lstinline!$x_i$: $a'_i$!, the type $S_i$ is compatible (\sref{sec:implicit-conversions}) with the parameter type $T_j$, whose name $p_j$ matches $x_i$, or if $f$ defines a capturing named parameter and $x_i$ does not match name of any $p_j$, then the type $S_i$ is compatible with the parameter type $T_j$, whose name $p_j$ matches the name of the capturing named parameter.

\item For every positional argument $a_i$, the type $S_i$ is compatible (\sref{sec:implicit-conversions}) with its corresponding $T_i$. 

\item The given block or the last argument prefixed with ``\lstinline!&!'' is of a type compatible (\sref{sec:implicit-conversions}) with the type of the captured block parameter, if such parameter is defined. 

\item If the expected type of the function application is defined, the result type $R$ is compatible (\sref{sec:implicit-conversions}) to it. 

\item For every argument $a_i$, if the corresponding parameter is defined as \code{out}, the argument is prefixed with \code{out} as well and must be a local variable. If the corresponding parameter is defined as only \code{out} and not \code{in} at the same time, the argument is converted to \code{out} argument and any previous value of the argument variable is released. See (\sref{sec:io-arguments}) for details. 

\item Every formal parameter $p_j$: $T_j$ which is not specified by either a positional or a named argument has a default value (\sref{sec:optional-parameters} \& \sref{sec:named-parameters}). 
\end{itemize}

If $f$ is a polymorphic method, it is applicable if local type inference (\sref{sec:local-type-inference}) can determine type arguments, so that the instantiated method is applicable. If $f$ is of a value type, it is applicable if it has a method member named \code{apply}, which is applicable. Note that if explicit type parameters are given to the polymorphic method, type application (\sref{sec:type-applications}) happens prior to function application. 

If a function application appears to be an argument to another function application (let's call it a nested function application), the expected type of the nested function application is used to determine, whether the outer function is applicable, but the nested function application is not evaluated until time specified by argument evaluation strategy (\sref{sec:arg-eval-strategies}) corresponding to the argument. Local type inference may indeed occur for the nested function application, if it involves a polymorphic method, but again, only using the available expected types. 

If an argument expression is prefixed with ``\lstinline!*!'' (let's call it a {\em sequence argument expression}, or {\em sequence-splat}, or just {\em splat}), it is expanded into multiple argument expressions, as its expected type is ~\lstinline!Sequence[$S$]! and $S$ is the expected (and usually actual) type of the arguments resulting from the expansion. The expansion uses methods of the \code{Sequence} type to determine the length of the sequence and its type, which are then inserted instead of the sequence argument (and the contents of the sequence have their evaluation deferred). The sequence should have a reasonable length, and must not be infinite. Such sequence arguments can appear in the function application multiple times (unlike the repeated parameter), but only in the section of positional arguments. 

If an argument expression is prefixed with ``\lstinline!**!'' (let's call it a {\em map argument expression}, or {\em map-splat}), it is expanded into multiple argument expressions, as its expected type is ~\lstinline!Map[Symbol, $S$]! and $S$ is the expected (and usually actual) type of the arguments resulting from the expansion. The expansion uses methods of the \code{Map} type to determine the length of the map and its type, which are then inserted instead of the map argument (and the contents of the map have their evaluation deferred). The map should have a reasonable length, and must not be infinite. Such map arguments can appear in the function application multiple times (unlike the repeated parameter), but only in the section of named arguments. 

\example Assume the following function, which computes the sum of variable number of arguments:
\begin{lstlisting}
def sum (*xs: Integer) := (O /: xs) ((x, y) -> { x + y })
\end{lstlisting}
Then 
\begin{lstlisting}
sum 1, 2, 3, 4
sum (1, 2, 3, 4)
sum *%[1, 2, 3, 4]
sum (*%[1, 2, 3, 4])
sum 1, 2, *%[3, 4]
sum (1, 2, *%[3, 4])
sum 1, *%[2, 3], 4
sum (1, *%[2, 3], 4)
\end{lstlisting}
all yield $10$ as result. On the other hand,
\begin{lstlisting}
sum %[1, 2, 3, 4]
\end{lstlisting}
would not be applicable. Moreover, (note the extra space before the sequence-splat operator),
\begin{lstlisting}
sum * %[1, 2, 3, 4]
\end{lstlisting}
would be interpreted as 
\begin{lstlisting}
sum.`*`(%[1, 2, 3, 4])
\end{lstlisting}
which is an infix expression rather than a function application. On the other hand, a space may appear between the function name and the arguments list.





\subsection{Tail-call optimization}

A function application usually allocates a new stack frame on the program's runtime stack for the current thread. However, if at least one of the following conditions holds and function calls itself as its last action, the application is executed using the stack frame of the caller, replacing arguments and rewinding stack pointer to the first instruction, called {\em tail-call optimization}:
\begin{itemize}
\item The function is local and not overloaded. 
\item The function is \code{final}. 
\item The function is \code{private} or ~\lstinline!private[self]!. 
\item The function is annotated so that tail-call optimization is explicitly allowed. 
\item A pragma allowing tail-call optimizations is effective in the scope of the tail call. 
\end{itemize}
The optimization will not happen if the application results in a different (possibly overloaded or overridden) variant of the caller function being applied, and a warning is issued if the tail-call optimization was explicitly expected (either via an annotation or a pragma). 





\subsection{Named \& Optional Arguments}
\label{sec:named-optional-arguments}

If an application uses named arguments ~\lstinline!$p_i$: $e_i$!~ or default arguments, the following conditions must hold:
\begin{itemize}
\item No named argument appears left of a positional argument in the argument list. 
\item No positional argument appears right of a named argument. A bit of an exception is the captured block argument, which appears to be positional, but is treated specially. 
\item The names $p_i$ of all named arguments are pairwise distinct. There is no way for named arguments to specify positional arguments -- this is also ensured by a similar requirement for the parameters lists. 
\item Every formal parameter ~\lstinline!$p_j$: $T_j$!, which is not specified by a positional argument, has a default argument. 
\item Every formal parameter ~\lstinline!^$p_j$: $T_j$!, which is not specified by a named argument, has a default argument. 
\item If there are more named arguments than named parameters (excluding the capturing named parameter), a capturing named parameter is defined. (If it is not, the function is not applicable.)
\end{itemize}

No transformation is applied to convert a function application into an application without named or default arguments -- the runtime handles the application itself. 






\subsection{By-Name, By-Need \& By-Future Arguments}
\label{sec:by-name-arguments}
\label{sec:by-need-arguments}
\label{sec:by-future-arguments}

None of these argument types require any syntactically special treatment. The user of a function that uses these types should however consider the implications of their types on their evaluation. 






\subsection{Input \& Output Arguments}
\label{sec:io-arguments}

Output arguments must be prefixed with the \code{out} keyword, so that the runtime can pass in a reference to the variable, and not to the value. The \code{in} modifier is implied and not used explicitly in the application. If the actual parameter is \code{out}-only, the original value of the variable is released upon being written to by the applied function, but not sooner. 

A variable that is defined with \code{val} is not useable as an \code{out} argument. A variable that is declared with \code{val} (but not defined) is useable as an \code{out} argument. 

When it comes to closures, variables in variable closures are implicitly also \code{out}, if the anonymous function contains an assignment to them. 

An assignment to an output parameter that was released is a no-op, and issues a warning. This can happen when the execution of an anonymous function or a block is delayed past the point where the original stack frame of the calling function is already released. 






\subsection{Curried Functions \& Partial Applications}
\label{sec:curried-functions}
\label{sec:partial-applications}

A curried function can appear in two distinct forms:
\begin{itemize}
\item[] {\em Implicitly curried form}, which is defined by using multiple parameters lists. 
\item[] {\em Explicitly curried form}, which is defined by using function types as return types of functions, or simply by returning a function from within a function. 
\end{itemize}

Each form has some implications on function applications. 

Let's define {\em consecutive function applications}. Such function applications are a continuous sequence of function applications, where each following function application is directly applied to the result of the previous function application, without storing the intermediate values anyhow. 

\example The following is an example of consecutive function applications:
\begin{lstlisting}
f(a, b)(c, d)
\end{lstlisting}
The following are not consecutive function applications:
\begin{lstlisting}
val e := f(a, b)
e(c, d)
\end{lstlisting}

An implicitly curried function requires a consecutive function application for all of its parameters lists, excluding the implicit parameters list. If the implicitly curried function is intended to be {\em partially applied} (not providing all the parameters lists with arguments lists), then a method value (\sref{sec:method-values}) can be used. This also applies to the implicit parameters list -- if providing it is to be deferred, a method value that encloses arguments lists up to the implicit parameters list can be used, but then the implicit arguments list has to be provided later in order to evaluate the curried function. 

On the other hand, explicitly curried functions do not care about consecutive function applications. 

The consecutive function applications meta-construct is also a solution to providing explicitly the implicit parameters list an arguments list. Without it, the function application would handle the implicits from it and the consecutive application would be applied to the result of the whole function. Therefore, if a consecutive function application is present, the evaluation of implicit parameters list is deferred to this consecutive function application, so that arguments for it can be specified. If there is no consecutive function application, then the implicit parameters list is evaluated as usual. 





\subsection{Function Compositions \& Pipelines}
\label{sec:function-compositions}
\label{sec:function-pipelines}

These expressions are not in fact syntax features, but rather an implementation on functions and their traits. 

A {\em function composition} is a way to compose two functions and return a function. A {\em function pipeline} is a way to pass a value to a function and return a value, which can be again passed to another function in a pipeline. 

Function composition is usually defined by operators such as ``\lstinline!|>>!'' for unary functions, ``\lstinline!||>>!'' for binary functions and so on, and ``\lstinline!<<|!'' for unary functions, ``\lstinline!<<||!'' for binary functions, in reverse order. 

Function pipeline is usually defined by operators such as ``\lstinline!|>!'' for unary functions, ``\lstinline!||>!'' for binary functions and so on, and ``\lstinline!<|!'' for unary functions, ``\lstinline!<||!'' for binary functions, in reverse order. 

These operators for unary functions can be defined as follows, e.g.:
\begin{lstlisting}
trait Function_1 [-T, +R]
begin

  // right-associative
  operator |>> [T1] (g: T1 -> T): T1 -> R := 
    (a: T1) -> { self(g(a)) }

  // left-associative
  operator <<| [T1] (g: T1 -> T): T1 -> R :=
    (a: T1) -> { self(g(a)) }

  // right-associative
  operator |> (a: T): R :=
    self(a)

  // left-associative
  operator <| (a: T): R := 
    self(a)
    
end trait
\end{lstlisting}

Function composition and pipelining makes more sense with the use of positional parameters rather than with named parameters, although with some more verbose syntax, it can be achieved as well, e.g. by assuming that the composed functions or pipelines share the same names of their named parameters. 





\subsection{Memoization}
\label{sec:memoization}

How to memoize a function's result is described in (\sref{sec:return-expressions}).

A memoized function's body is not evaluated, if it was once called with the same arguments (based on equality, not identity), and if that result value is still memoized. If so, the memoized result value is immediately returned without evaluation of the function's body, which can speed up execution of some functions significantly. Such functions should however be referentially transparent in best-case scenario (\sref{sec:function-decls-defs} \& \sref{sec:statements}) or at least tolerant to being memoized. 

Memoization is better with small parameter numbers, so that searching the result values cache would not actually take longer than evaluation of the function's body. Functions that are defined with the \code{function} keyword (\sref{sec:function-decls-defs}) may opt-in to implicit memoization\footnote{E.g., based on the computed complexity of the function. If the function is decided to be simple, then memoization could actually worsen performance.}, as well as functions declared as \code{transparent} (\sref{sec:statements}). Functions declared as \code{opaque} (\sref{sec:statements}) should not be memoized. 

Parameters of memoization\footnote{Parameters include things like: cache policy, ttl, cache size and so on.} may be controlled, even on per-function basis, with use of specialized annotations and pragmas. 





\section{Type Applications}
\label{sec:type-applications}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Simple_Expr Type_Args
\end{lstlisting}

A type application ~\lstinline!$e$[$T_1 \commadots T_n$]!~ instantiates a polymorphic value $e$ of type ~\lstinline![$a_1$ >: $L_1$ <: $U_1$ $\commadots$ $a_n$ >: $L_n$ <: $U_n$] $\mapsto\ S$!~ with argument types $T_1 \commadots T_n$. Every argument type $T_i$ must obey the corresponding bounds $L_i$ and $U_i$. That is, for each $i = 1 \commadots n$, we must have $\sigma L_i <: T_i <: \sigma U_i$, where $\sigma$ is the substitution $[a_1 := T_1 \commadots a_n := T_n]$. The type of the application is $\sigma S$. 

If the function part $e$ is of some value type, the type application is taken to be equivalent to ~\lstinline!$e$.apply[$T_1 \commadots T_n$]!, i.e. the application of an \code{apply} method defined by $e$. 

Type applications can be omitted if local type inference (\sref{sec:local-type-inference}) can infer best type arguments for a polymorphic function from the types of the actual function arguments and the expected result type. 





\section{Tuples}
\label{sec:tuples}

\syntax\begin{lstlisting}
Simple_Expr ::= '(' [Exprs] ')'
\end{lstlisting}

A tuple expression ~\lstinline!($e_1 \commadots e_n$)!~ is an alias for the class instance creation ~\lstinline!Tuple_$n$($e_1 \commadots e_n$)!, where $n \geq 2$. The empty tuple ~\lstinline!()!~ is the unique value of type \code{Unit}. A tuple with only one value is only the value itself, without being wrapped in a tuple. 






\section{Instance Creation Expressions}
\label{sec:instance-creation-exprs}

Unlike languages like Java, Scala, C\# and similar, Coral does not have dedicated language construct for creating new instances of classes. Instead, all such attempts are made through the ~\lstinline!Class#new!~ method (not to be confused with ~\lstinline@Class.new@), which in the end\footnote{Because constructor currying can happen, the constructor is invoked by a native implementation from outside of the \code{new} method, by the curried function, which is a mechanism inaccessible to users otherwise than via the constructor definition.} has all arguments for a constructor, which gets invoked by a native implementation. 






\section{Blocks}
\label{sec:blocks}

\syntax\begin{lstlisting}
Block_Expr      ::= Block_Expr1 | Block_Expr2
Block_Expr1     ::= '{' [Block_Args semi] Block '}'
Block_Expr2     ::= 'do' [Block_Args semi] Block 'end'
Block_Args      ::= '|' [Params] [Block_Shadowing] '|' [':' Type]
Block_Shadowing ::= ';' [Shad_Val_Dcl {',' Shad_Val_Dcl}]
Shad_Val_Dcl    ::= 'val' Val_Dcl
                  | 'var' Var_Dcl
                  | 'def' Def_Dcl
Block           ::= {Block_Stat semi} [Result_Expr]
\end{lstlisting}

A block expression ~\lstinline!{ $s_1$; $\ldots$; $s_n$; $e$ }!~ is constructed from a sequence of block statements $s_1 \commadots s_n$ and a final expression $e$. The statement sequence may not contain two definitions or declarations that bind the same name in the same namespace, except for local function definitions, which then create overloaded local function definitions (behaving pretty much like regular overloaded functions). The final expression may be omitted, in which case the unit value ~\lstinline!()!~ is assumed. 

The expected type of the final expression $e$ is the expected type of the block expression. The expected type of all preceding statements is undefined. 

The type of a block ~\lstinline!{ $s_1$; $\ldots$; $s_n$; $e$ }!~ is ~\lstinline!$T$ for-some { $Q$ }!, where $T$ is the type of $e$ and $Q$ contains existential clauses (\sref{sec:existential-types}) for every value or type name which is free in $T$ and which is defined locally in any of the statements $s_1 \commadots s_n$. We say that the existential clause {\em binds} the occurence of the value or type name. Specifically, 
\begin{itemize}

\item A locally defined type definition ~\lstinline!type $t$ := $T$!~ is bound by the existential clause ~\lstinline!type $t$ >: $T$ <: $T$!. It is an error if $t$ carries type parameters. 

\item A locally defined value definition ~\lstinline!val $x$: $T$ := $e$!~ is bound by the existential clause ~\lstinline!val $x$: $T$!. 

\item A locally defined class definition ~\lstinline!class $c$ extends $t$!~ is bound by the existential clause ~\lstinline!type $c$ <: $T$!, where $T$ is the least class type of refinement type which is a proper supertype of the type $c$. It is an error if $c$ carries type parameters. 

\item A locally defined object definition ~\lstinline!object $x$ extends $t$!~ is bound by the existential clause ~\lstinline!val $x$: $T$!, where $T$ is the least class type of refinement type which is a proper supertype of the type ~\lstinline!$x$.type!.
\end{itemize}

Evaluation of the block entails evaluation of its statement sequence, followed by an evaluation of the final expression $e$, which defines the implicit result of the block. 





\subsection{Block Expression as Argument}
\label{sec:block-arguments}

A block expression may be used as the very last argument in a function application (\sref{sec:function-applications}), being equivalent to an anonymous function. 

As such, the block parameters section is optional to be defined, and its parameters are, unlike with anonymous functions, tolerant to different shapes of given arguments. If parameters of the block are typed and arguments for the corresponding parameters are given, the types of the arguments must be compatible with the expected parameter types. 

If less arguments are provided, the remaining parameters have default values of their types, and it is an error if such parameter is typed with a non-nullable type. 

If more arguments are provided, the extra arguments are discarded and released. 

An explicit return expression (\sref{sec:return-expressions}) within the block is interconnected with the innermost function that defines the block, i.e. evaluating it returns from the function (as well as from the block expression). This does not apply to anonymous functions (\sref{sec:anonymous-functions}), where the return expression is interconnected with the anonymous function itself. 






\subsection{Variable Closure}
\label{sec:variable-closure}

Coral uses variable closure when defining a block expression. 

If a block expression is used just as a statement, it implicitly inherits access to all variables and methods defined in the scope in which it itself is defined. 

Variables are made available via inner hidden instance variables of the implicit function. This includes the \code{self} object of the outer scope, if any methods are to be executed from within the block. Those variables are referenced with a strong reference, and therefore may cause in some situations retain cycles -- this can be solved by using {\em capture lists}, which can override this default behavior and store the reference as either \code{weak}, \code{soft} or \code{unowned} reference, to break the retain cycle.\footnote{Quite useful with lazy definitions of instance variables, where the expression is wrapped in an implicit block.} 

If a block expression is used as an argument in a function application (\sref{sec:function-applications}), it is used as a functor, and is provided with read and write access to variables in the scope that the function application appears in, and with an access to the \code{self} reference, including any nested ~\lstinline!$C$.self!~ references (\sref{sec:self-this-super}). Write access to variables is provided in a manner equivalent to \code{out} arguments. 

Variable closure is applied to anonymous functions (\sref{sec:anonymous-functions}) as well. 

A block expression may opt-in to {\em shadow variables} that it would otherwise have access to from its scope, specified with the \code{Block_Shadowing} syntax element. Variables and methods with the same names as those of the shadowing variables will not be a part of the variable closure. 





\section{Yield Expressions}

\syntax\begin{lstlisting}
Yield_Expr ::= 'yield' (Parens_Args | Poetry_Args | ())
\end{lstlisting}

A yield expression ~\lstinline!yield $a_1 \commadots a_n$!~ is a way to invoke the block argument (\sref{sec:function-applications} \& \sref{sec:block-arguments}) and pass it arguments. It's expected type is the result type of the given block argument. 

The \code{yield} keyword is also used in collection comprehensions (\sref{sec:collection-comprehensions}) and generators (\sref{sec:generator-expressions}), with a different meaning. 





\section{Prefix \& Infix Operations}
\label{sec:prefix-infix-ops}

\syntax\begin{lstlisting}
Infix_Expr  ::= Prefix_Expr
              | Infix_Expr [op_id Infix_expr]
Prefix_Expr ::= [op_id] Simple_Expr
\end{lstlisting}

Expressions can be constructed from operands and operators. 





\subsection{Prefix Operations}

A prefix operation $\op\ e$ consists of a prefix operator $\op$, which may be any operator identifier, unlike in Scala, but must not be followed by any whitespace, only identifiers or parentheses. The expression $\op\ e$ is equivalent to the method application ~\lstinline!$e$.$\op$()!. 





\subsection{Postfix Operations}

Apart from standard function applications (\sref{sec:function-applications}) that may be viewed as postfix, Coral does not include support for postfix operations. 





\subsection{Infix Operations}
\label{sec:infix-operations}

An infix operator can be an arbitrary operator identifier. Infix operators have static precedence and associativity borrowed from Scala, and defined as follows:

The {\em precedence} of an infix operator is determined by the operator's first character. Characters are listed below in increasing order of precedence, with characters on the same line having the same precedence.

\begin{lstlisting}
|
^
&
< > ~
= !
:
$\mbox{\rm\sl(all other special characters)}$
+ -
* / %
\end{lstlisting}

That is, operators starting with ``\lstinline!|!'' have the lowest precedence, followed by operators starting with ``\lstinline!^!'', etc. 

There's one exception to this rule, which concerns {\em assignment operators} (\sref{sec:assignment-operations}). The precedence of an assignment operator is the same as the one of simple assignment (\lstinline!:=!). That is, it is lower than the precedence of any other operator. 

The {\em associativity} of an operator is determined by the operator's last character. Operators ending in a colon ``\lstinline!:!'' are right-associative, and operators ending in a greater-than sign ``\lstinline!>!'' are right-associative, if they consist of more than one operator character. All other operators are left-associative. 

Precedence and associativity of operators determine the grouping of parts of an expression as follows.

\begin{itemize}
\item If there are several infix operations in an expression, then operators with higher precedence bind more closely than operators with lower precedence. 

\item If there are consecutive infix operations $e_0\ \op_1\ e_1\ \op_2 \ldots \op_n\ e_n$ with operators $\op_1 \ldots \op_n$ of the same precedence, then all those operators must have the same associativity (i.e. it is an error if they don't). If all operators are left-associative, then the sequence is interpreted as ~\lstinline!(($e_0\ \op_1\ e_1$) $\op_2 \ldots$) $\op_n\ e_n$!. Otherwise, if all operators are right-associative, the sequence is interpreted as ~\lstinline!$e_0\ \op_1$ ($e_1\ \op_2$ ($\ldots \op_n\ e_n$))!.

\item A left-associative binary operation $e_1\ \op\ e_2$ is interpreted as ~\lstinline!$e_1$.`$\op$`($e_2$)!. If $\op$ is right-associative, the same operation is interpreted as ~\lstinline!{ val x := $e_1$; $e_2$.`$\op$`($x$) }!, where $x$ is a fresh name. 

\item The right-hand operand of a left-associative operator may consist of several arguments enclosed in parentheses, e.g. ~\lstinline!$e\ \op$ ($e_1 \commadots e_n$)!. This expression is then interpreted as ~\lstinline!$e$.`$\op$`($e_1 \commadots e_n$)!. 

\item The left-hand operand of a right-associative operator may consist of several arguments enclosed in parentheses, e.g. ~\lstinline!($e_1 \commadots e_n$) $\op\ e$!. This expression is then interpreted as ~\lstinline!$e$.`$\op$`($e_1 \commadots e_n$)!. 
\end{itemize}






\subsection{Assignment Operations}
\label{sec:assignment-operations}

An assignment operator is an operator symbol that ends in an ``equals'' character ``\lstinline!=!'', with the exception of operators for which one of the following conditions holds: 
\begin{enumerate}
\item the operator also starts with an equals character and has more than one character, or
\item the operator is one of ``\lstinline!<=!'', ``\lstinline!>=!'' or ``\lstinline@!=@''.
\end{enumerate}

Assignment operators are treated specially in that they can be expanded to assignments if no other interpretation is valid, as previously defined. Assignment operators can be defined as members of a type. 

Let's consider an assignment operator, such as ``\lstinline!+=!'', in an infix operation ~\lstinline!$l$ += $r$!, where $l$ \& $r$ are expressions. This operation can be re-interpreted as an assignment
\begin{lstlisting}
$l$ := $l$ + $r$
\end{lstlisting}
except that the operations's left-hand-side $l$ is evaluated only once. 

The re-interpretation is occurs if the following conditions are fulfilled:
\begin{enumerate}
  \item The left hand side $l$ does not have a member named ``\lstinline!+=!'', and also can not be converted by an implicit conversion (\sref{sec:implicit-conversions}) to a value with a member named ``\lstinline!+=!'', applicable to a value of type of $r$. 
  \item The assignment ~\lstinline!$l$ := $l$ + $r$! is type-correct. In particular, this implies that $l$ refers to an object that is convertible to a value with a member named ``\lstinline!+!'' (or itself has such a member without conversion, in the ideal case, indeed). 
  \item The variable $l$ is assignable, not immutable. This implies that it is defined as a ~\lstinline!var $l$!. 
\end{enumerate}

The re-interpretation is built into the compiled bytecode in such a way that first tries the assignment operator, and then the re-interpretation only in case where the assignment operator approach failed.\footnote{No appropriate implicit conversion was found, or if implicit conversions are disabled for the expression, the value referred to by $l$ does not have the appropriate member.} It is indeed an error if none of the two approaches succeeded. 





\section{Typed Expressions}
\label{sec:typed-expressions}

\syntax\begin{lstlisting}
Cast_Expr  ::= Infix_Expr ('as' | 'as!' | 'as?') (Type | Simple_Expr1)
Infix_Expr ::= Infix_Expr ('is' | 'is!') (Type | Simple_Expr1)
\end{lstlisting}

The typed expression ~\lstinline!$e$ as $T$!~ has type $T$. The type of expression $e$ is expected to conform to $T$. The result of the expression is the value of $e$ converted to type $T$. The conversion can take these forms, preferred in the following order:
\begin{enumerate}
\item No conversion, if $e$ conforms to $T$ directly. 
\item If an implicit conversion $c$ from expression type $E$ of method type ~\lstinline!($E$) $\mapsto\ T$!~ exists in the scope, then the conversion is of the form ~\lstinline!$c$($e$)!. 
\item Otherwise, the conversion is of the form ~\lstinline!$e$.as_instance_of[$T$]()!. 
\end{enumerate}

The conformance check expression ~\lstinline!$e$ is $T$!~ has type \code{Boolean} and tests whether $e$ conforms to $T$, basically by asking a question ``Can $e$ be of type $T$?'', answering either ``It can be'' or ``It can't be''. The expression $e$ conforms to type $T$ if at least one of the following conditions hold:
\begin{enumerate}
\item Type of $e$ is a subtype of $T$. 
\item An implicit conversion $c$ from expression type $E$ of method type ~\lstinline!($E$) $\mapsto\ T$!~ exists in the scope. 
\item As a last resort, type of $e$ overrides the method ~\lstinline!is_instance_of[$T$]()!~ and evaluating it results in \code{yes} value. 
\end{enumerate}

\paragraph{Note} 
The conformance check expression as defined here is not used in resolution of function applications (\sref{sec:function-applications}).

The typed expression ~\lstinline@$e$ as! $T$@~ works like ~\lstinline!$e$ as $T$!, but only uses the first form. Similarly, the conformance check expression ~\lstinline@$e$ is! $T$@~ works like ~\lstinline!$e$ is $T$!, but it uses only the first condition. The bang character ``\lstinline@!@'' signalizes that the operation is more dangerous, in means of that its easier for the expression $e$ to not successfully convert to the target type or conform to it. 

The typed expression ~\lstinline!$e$ as? $T$!~ triggers $T$ to be nullable type (and it is an error if $T$ explicitly disallows overriding of nullability) and results in a \code{nil} value instead of an error, if no conversion is available to treat $e$ as $T$. 

If an expression is typed to a dynamic path of a (syntactic) type, then the value referenced by such path is expected to be a type, and it is an error if it is not. 






\section{Annotated Expressions}
\label{sec:annotated-exprs}

\syntax\begin{lstlisting}
Annot_Expr ::= Annotation {Annotation} Infix_Expr
\end{lstlisting}

An annotated expression $a_1\ \ldots\ a_n\ e$ attaches annotations $a_1\ \ldots\ a_n$ to the expression $e$ (\sref{sec:annotations}). 






\section{Assignments}

\syntax\begin{lstlisting}
Assign_Expr ::= [Simple_Expr '.'] id ':=' Expr
              | Mul_Assign_Expr
Update_Expr ::= Simple_Expr1 Argument_Exprs ':=' Expr
\end{lstlisting}

The interpretation of an assignment to a simple variable ~\lstinline!$x$ := $e$!~ depends on the definitions of $x$. If $x$ denotes a mutable variable, then the assignment changes the current value of $x$ to the result of evaluating the expression $e$. The type of $e$ is expected to conform to the type of $x$. 

If $x$ is defined as a property of some template, or the template contains a setter function ~\lstinline!$x$_=!~ as a member, then the assignment is interpreted as the invocation ~\lstinline!$x$_=($e$)!~ of that setter function. 

Analogously, an assignment ~\lstinline!$f$.$x$ := $e$!~ is interpreted as the invocation ~\lstinline!$f$.$x$_=($e$)!. If $f$ is evaluated to \code{nil}, then the invocation is forwarded to \code{nil}.\footnote{This likely results in a runtime error being raised, unless \code{nil} would actually implement method \code{x_=}.} 

An assignment ~\lstinline!$f$.?$x$ := $e$!~ is interpreted as the invocation ~\lstinline!$f$.?$x$_=($e$)!. If $f$ is evaluated to \code{nil}, then the invocation is evaluated to \code{nil}. See (\sref{sec:designators}) for more on behavior of the ``\lstinline!.?!'' navigation. 

An assignment ~\lstinline!$f$($\args$) := $e$!~ with a function application to the left of the ``\lstinline!:=!'' operator is interpreted as ~\lstinline!$f$.update($\args$)($e$)!, i.e. the invocation of an \code{update} function defined by $f$. If $f$ is evaluated to \code{nil}, then the invocation is forwarded to \code{nil}. The ``\lstinline!.?!'' navigation is not available with this expression. 

\example Here are some assignment expressions and their equivalent interpretations. 
\begin{lstlisting}
f := e                       f_=(e)
f() := e                     f.update()(e)
f(i) := e                    f.update(i)(e)
f(i, j) := e                 f.update(i, j)(e)
x.f := e                     x.f_=(e)
x.f() := e                   x.f.update()(e)
x.f(i) := e                  x.f.update(i)(e)
x.f(i, j) := e               x.f.update(i, j)(e)
f()() := e                   f().update()(e)
f(i)() := e                  f(i).update()(e)
f()(i) := e                  f().update(i)(e)
f(i)(j) := e                 f(i).update(j)(e)
f(i, j)(k) := e              f(i, j).update(k)(e)
f(i, j)(k, l) := e           f(i, j).update(k, l)(e)
f(i, j) := (e_1, e_2)        f.update(i, j)((e_1, e_2))
\end{lstlisting}






\subsection{Multiple Assignments}
\label{sec:multiple-assignments}

\syntax\begin{lstlisting}
Mul_Assign_Expr ::= Mul_Vars ':=' Mul_Exprs
Mul_Vars        ::= [(id | '_') {',' (id | '_')} ',']
                    ['*'] (id | '_') {',' (id | '_')}
Mul_Exprs       ::= [Expr {',' Expr} ',']
                    ['*'] Expr {',' Expr}
\end{lstlisting}

Multiple assignment is a way to assign multiple variables at once. On the left-hand side of the assignment are variables separated by commas, where at most one of which may be prefixed with an asterisk ``\lstinline!*!''. On the right-hand side of the assignment are expressions separated by commas, where one or more expressions may be prefixed with an asterisk ``\lstinline!*!'' as a sequence-splat operator. 

The left-hand side of the multiple assignment must contain only variable names that can be assigned to -- so either mutable variables, or declared and not defined variables. 

The right-hand side is expanded into a single sequence of expressions in the following way:
\begin{enumerate}
\item Say that $e_1 \commadots e_n$ are the original right-hand side expressions. 

\item For each $e_i$, where $1 \leq i \leq n$, if $e_i$ is prefixed with a sequence-splat operator, replace $e_i$ with a comma-separated expressions $e_{i,j}$, where $j$ is the index of the sub-expression contained in the original $e_i$, and move to the next expression $e_{i+1}$. 
\end{enumerate}

To match the left-hand side variable names with the expanded right-hand side expressions, match first the variables until the one prefixed with an asterisk, if any, and remove the matched expressions. Count variables that are following the one prefixed with an asterisk as $m$ and match them with the remaining expressions, starting from expression $n - m$ where $n$ is the count of the remaining expressions, or from the first expression, if $m \geq n$. If $m \leq n$, then collect the remaining expressions into a sequence and assign it to the variable prefixed with an asterisk. In any case, if there are less expressions available than variables to assign to, assign the extra variables with \code{nil}. If there are more expressions than variables to assign to and no variable is prefixed with an asterisk, then the extra expressions are discarded and released. 

The multiple assignment evaluates all expressions on the right-hand side of the assignment prior to the actual assignment. The expected type of each assigned expression is the expected type of the corresponding variable it assigns to, or if the corresponding variable is prefixed with an asterisk, then the expected type is the expected type of the elements of the sequence declared by that variable. 

If the name of the assigned variable is ``\lstinline!_!'', the assignment for that variable is not evaluated and is discarded. 

\example The following examples show how multiple assignment works. 
\begin{lstlisting}
// swap two variables
a, b := b, a

// `a` will be `e`
// `b` will be the first element of `f` (if `f` contains anything)
// `d` will be the last element of `f` (if `f` contains anything)
// `c` will be the remaining elements of `f` (if `f` contains anything)
// if `f` is an empty sequence, then `b` and `d` are assigned nil
//   and `c` is an empty sequence
// if `f` has one element, then `d` is assigned nil 
//   and `c` is assigned an empty sequence
// if `f` has two elements, then `c` is assigned an empty sequence
a, b, *c, d := e, *f
\end{lstlisting}





\section{Conditional Expressions}
\label{sec:conditional-expressions}

\syntax\begin{lstlisting}
Cond_Expr        ::= Cond_Block_Expr | Cond_Mod_Expr
Cond_Block_Expr  ::= Cond_Block_Expr1 | Cond_Block_Expr2
Cond_Block_Expr1 ::= 'if' Expr ('then' | semi) Cond_Block 
                     {[semi] 'elsif' Expr ('then' | semi) Cond_Block}
                     [[semi] 'else' Cond_Block] 'end' ['if']
Cond_Block_Expr2 ::= 'unless' Expr ('then' | semi) Cond_Block 
                     {[semi] 'elsif' Expr ('then' | semi) Cond_Block}
                     [[semi] 'else' Cond_Block] 'end' ['unless']
Cond_Mod_Expr    ::= Expr Cond_Modifier
Cond_Modifier    ::= Cond_Modifier1
                     ['else' Infix_Expr]
Cond_Modifier1   ::= ('if' | 'unless') Infix_Expr 
Cond_Block       ::= Expr | Block
\end{lstlisting}

The conditional expression ~\lstinline!if $e_1$ then $e_2$ else $e_3$!~ chooses one of the values of $e_2$ and $e_3$, depending on the value of $e_1$. The condition $e_1$ is expected to conform to type \code{Boolean}, but can be virtually any type -- if it is not a \code{Boolean}, then it is equal to \code{yes} if it implements the method ~\lstinline!to_boolean(): Boolean! and that implementation returns \code{yes}, or can be converted to \code{yes} (\sref{sec:typed-expressions}), and \code{no} otherwise. The \code{nil} object converts always to \code{no}. If the $e_1$ is the single instance ``\lstinline!()!'' of type \code{Unit}, it is an error. The \code{then}-part $e_2$ and the \code{else}-part $e_3$ are both expected to conform to the expected type of the conditional expression, but are not required to. The type of the conditional expression is the weak least upper bound (\sref{sec:weak-conformance}) of the types of $e_2$ and $e_3$. A semicolon preceding the \code{else} symbol of a conditional expression is ignored. 

The conditional expression is evaluated by evaluating first $e_1$. If this evaluates to \code{true}, the result of evaluating $e_2$ is returned, otherwise the result of evaluating $e_3$ is returned. 

The evaluation of $e_1$ utilizes the so-called {\em short-circuit evaluation}. The expression $e_1$ is split by binary boolean operators. Then every first argument is evaluated, but the second argument is evaluated only if the evaluation of the first argument does not suffice to determine the value of the expression. When the first argument of ``\lstinline!&&!'' evaluates to \code{no}, the overall value must be \code{no} and the result of evaluating the second argument does not change that. When the first argument of ``\lstinline!||!'' evaluates to \code{yes}, the overall value must be \code{yes}. These boolean operators are in fact short-circuited source-code-wide, not only as part of conditional expressions. Word equivalents of these operators are not short-circuited (``\code{and}'' and ``\code{or}'' respectively). 

\example The following examples show how short-circuit evaluation behaves. Let's mark the short-circuited ``\lstinline!&&!'' as ``\lstinline!sand!'' and the short-circuited ``\lstinline!||!'' as ``\lstinline!sor!''. On the right side are the equivalent conditional expressions. 
\begin{lstlisting}
$x$ sand $y$          if $x$ then $y$ else no
$x$ sor $y$           if $x$ then yes else $y$
\end{lstlisting}

A short form of the conditional expression eliminates the \code{else}-part. The conditional expression ~\lstinline!if $e_1$ then $e_2$!~ is evaluated as if it was ~\lstinline!if $e_1$ then $e_2$ else ()!, and is therefore expected to be the weak least upper bound of the type \code{Unit} and the type of $e_2$. 

The conditional expression 
\begin{lstlisting}
if $e_1$ then $e_2$ elsif $e_3$ then $e_4$ $\ldots$ elsif $e_n$ then $e_{n+1}$ else $e_{n+2}$
\end{lstlisting} 
is evaluated as if it was 
\begin{lstlisting}
if $e_1$ then $e_2$ else if $e_3$ then $e_4$ $\ldots$ else if $e_n$ then $e_{n+1}$ else $e_{n+2}$
\end{lstlisting}
Basically, \code{elsif} is a simple syntax sugar for the little longer \code{else if} keyword tokens sequence. 

The alternative conditional expression ~\lstinline!unless $e_1$ then $e_2$ else $e_3$!~ is evaluated as if it was ~\lstinline@if !$e_1$ then $e_2$ else $e_3$@. Unlike in Ruby, the \code{elsif}-part is allowed to appear with this conditional expression. However, there is no syntax sugar for the \code{else unless} keyword tokens sequence. 

The modifier-fashion conditional expression ~\lstinline!$e_1$ if $e_2$ else $e_3$!~ is interpreted as if it was ~\lstinline!if $e_2$ then $e_1$ else $e_3$!. Similarly with the \code{unless} version and the short form of the modifier conditional expression (without the explicit \code{else}-part). 

Unlike in some languages, conditional expressions do not require to place parentheses around the conditions -- but it is possible to do so, the result is equivalent. That might be useful when the condition is inevitably long and needs to span multiple lines -- so that boolean operators may be situated at the beginning of each new line, instead of being at the end of the previous line. 






\section{Loop Expressions}

Coral has an elaborate support for loop expressions. Not all structures known from other languages are supported though, e.g. the ~\lstinline[language=Java]!do $\ldots$ while!~ expression, which is expressed differently in Coral. 






\subsection{Loop Control Expressions}
\label{sec:loop-control-expressions}

\syntax\begin{lstlisting}
Loop_Ctrl_Expr ::= Break_Expr
                 | Skip_Expr
                 | Next_Expr
                 | Redo_Expr
                 | Exhausted_Expr
                 | Broken_Expr
Break_Expr     ::= 'break' [label_name] [Cond_Modifier1]
Skip_Expr      ::= 'skip' [integer_literal] [Cond_Modifier1]
Next_Expr      ::= 'next' [label_name] [Cond_Modifier1]
Redo_Expr      ::= 'redo' [label_name] [Cond_Modifier1]
Exhausted_Expr ::= 'exhausted' Block_Expr
Broken_Expr    ::= 'broken' Block_Expr
\end{lstlisting}

Loop control expressions are made available inside of loop expressions to allow control of the enclosing loops.

In the following paragraphs, a {\em loop identified by the label $l$} is a loop expression preceded in its syntax with the syntax element \code{Label_Dcl} (\sref{sec:local-jump-expressions}). All annotations (\sref{sec:annotated-exprs}) that precede the label declaration are applied to the following loop expression, never to the label. 

The ~\lstinline!break $l$!~ expression stops the loop labeled with $l$, and omitting the $l$ label stops the directly enclosing loop. 

The ~\lstinline!skip $i$!~ expression skips $i$ loop iterations, or with the $i$ omitted, skips $1$ loop iteration (the current iteration). 

The ~\lstinline!next $l$!~ expression skips the current loop iteration and every other enclosing iteration until the loop identified by the given label $l$ is found, and continues with its next iteration. If the label $l$ is omitted, then its behavior is equal to ~\lstinline!skip 1!. 

The ~\lstinline!redo $l$!~ restarts the loop identified by the label $l$ (and stops all loops in between), or if $l$ is omitted, restarts the directly enclosing loop. 

The ~\lstinline!exhausted $e$!~ expression evaluates the expression $e$ only if the directly enclosing loop {\em was not broken} with the \code{break} keyword. 

The ~\lstinline!broken $e$!~ expression evaluates the expression $e$ only if the directly enclosing loop {\em was broken} with the \code{break} keyword. 

The standard library provides loop-like methods, where these loop control structures are not available as keywords, but as methods instead (either imported or available on some given loop-control object) -- they might be implemented e.g. using the \code{throw} expressions (\sref{sec:throw-catch-expressions}), that the enclosing loop-like method catches and resolves as appropriate. Only the \code{exhausted} and \code{broken} constructs need to be simulated, possibly by optional parameters or additional parameter sections.\footnote{In fact, all loop expressions may be interpreted as syntax sugar to such methods. How exactly -- that may get into this specification as soon as it is clearly defined.} 





\subsection{Iterable For Expressions}
\label{sec:iterable-expressions}

\syntax\begin{lstlisting}
Loop_Expr       ::= [Label_Dcl] 'for' Val_Dcls 'in' ['reverse'] Expr 
                    ['step' Expr] For_Loop
For_Loop        ::= 'loop' Loop_Block_Expr 'end' ['loop']
                  | '{' Loop_Block_Expr '}'
Loop_Block_Expr ::= {Block_Stat | Loop_Ctrl_Expr}
Val_Dcls        ::= Val_Dcl
                  | Pattern1
\end{lstlisting}

The {\em iterable expression} is typed as \code{Unit}, so there is no point in using its value. 

In an expression ~\lstinline!for $e_1$ in $e_2$ loop $e_3$ end!, the type of $e_2$ is expected to conform to ~\lstinline!Iterable_Like[$E$]!. The type of $e_1$ is expected to conform to the type $E$. The type of $e_3$ is evaluated to ``\lstinline!()!'' anyway. The scope of variables defined in $e_1$ extends to the $e_3$ expression. 

In expression ~\lstinline!for $e_1$ in reverse $e_2$ loop $e_3$ end!, the type of $e_2$ is expected to conform to \code{Reverse_Iterable_Like}. 

Iterable expressions make use only of the two mentioned traits and the methods defined by them, and therefore advanced iterating mechanisms, such as parallel computations, are not performed -- they are simply too complex to be generalized by a simple language construct. 

Iterable expression repeats evaluation of the expression $e_3$ for every value that comes from the \code{Iterable_Like}'s \code{Iterator}, unless the loop controls alter this flow (\sref{sec:loop-control-expressions}).

Iterable expressions are simple comprehensions over iterating a single iterable value. For more complex iterating expressions, see generators (\sref{sec:generator-expressions}).

An expression 
\begin{lstlisting}
for $e_1$ in $e_2$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}
$e_2$.each { when $e_1$ then $e_3$ }
\end{lstlisting} 

An expression 
\begin{lstlisting}
<<$l$>> for $e_1$ in $e_2$ loop $e_3$ end
\end{lstlisting} 
where $l$ is a label name, is translated to the invocation
\begin{lstlisting}[deletekeywords={label}]
$e_2$.each({ when $e_1$ then $e_3$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

An expression 
\begin{lstlisting}
for $e_1$ in reverse $e_2$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}[deletekeywords={reverse}]
$e_2$.reverse.each { when $e_1$ then $e_3$ }
\end{lstlisting} 

An expression 
\begin{lstlisting}
<<$l$>> for $e_1$ in reverse $e_2$ loop $e_3$ end
\end{lstlisting} 
where $l$ is a label name, is translated to the invocation
\begin{lstlisting}[deletekeywords={label,reverse}]
$e_2$.reverse.each({ when $e_1$ then $e_3$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

An expression 
\begin{lstlisting}
for $e_1$ in $e_2$ step $i$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}[deletekeywords={step}]
$e_2$.each({ when $e_1$ then $e_3$ }, step: $i$)
\end{lstlisting} 

Analogously, other combinations of \code{reverse}, \code{skip} and labeled loops are translated. If the $e_3$ expression contains a \code{exhausted} expression, then it's block is passed to the \code{each} method as an argument named \lstinline[deletekeywords={exhausted}]{exhausted}, and analogously, if the $e_3$ expression contains a \code{broken} expression, then it's block is passed to the \code{each} method as an argument named \lstinline[deletekeywords={broken}]{broken}.







\subsection{While \& Until Loop Expressions}

\syntax\begin{lstlisting}
Loop_Expr     ::= [Label_Dcl] ('while' | 'until') Expr For_Loop
                | Loop_Mod_Expr
Loop_Mod_Expr ::= Expr Loop_Modifier
Loop_Modifier ::= ('while' | 'until') Expr
\end{lstlisting}

The {\em while loop expression} ~\lstinline!while $e_1$ loop $e_2$ end!~ is typed as \code{Unit}, so there is no point in using its value. 

In an expression ~\lstinline!while $e_1$ loop $e_2$ end!, the expression $e_1$ is treated the same way as the condition part in conditional expressions (\sref{sec:conditional-expressions}). The type of $e_2$ is evaluated to ``\lstinline!()!'' anyway.

The while loop expression ~\lstinline!while $e_1$ loop $e_2$ end!~ is alone typed and evaluated as if it was an application of a hypothetical function ~\lstinline!while_loop ($e_1$) ($e_2$)!, where the function \code{while_loop} would be defined as follows, with the $e_1$ and $e_2$ would be passed by-name: 
\begin{lstlisting}
def while_loop (condition: => Boolean)(body: => Unit): Unit := {
<<repeat>>
  if (condition) { body; goto repeat } else {}
}
\end{lstlisting}
The real implementation has to handle loop control expressions (\sref{sec:loop-control-expressions}) around the evaluation of \code{body} and also handle a label, if one is given; so it is not this simple. 

A while loop expression repeats evaluation of the expression $e_2$ as long as $e_1$ evaluates to \code{yes}, unless the loop controls alter this flow (\sref{sec:loop-control-expressions}).





\subsection{Pure Loops}
\label{sec:pure-loops}

\syntax\begin{lstlisting}
Loop_Expr  ::= [Label_Dcl] 'loop'
               (semi Loop_Block_Expr 'end' ['loop'] | 
               '{' Loop_Block_Expr '}')
\end{lstlisting}

The {\em pure loop expression} ~\lstinline!loop $e$ end!~ is typed as \code{Unit}, so there is no point in using its value. 

A pure loop expression repeats evaluation of the expression $e$ as long as the loop controls don't alter this flow (\sref{sec:loop-control-expressions}). It is basically equivalent to an iterable expression (\sref{sec:iterable-expressions}) that iterates over an endless iterator. 

This expression may also be used to replace the ~\lstinline[language=Java]!do { $e_1$ } while ($e_2$)!~ expression, known from other languages, using the following structure: 
\begin{lstlisting}
loop
  $e_1$
  break if $e_2$
end loop
\end{lstlisting}

A pure loop expression is the only expression that is not translated into a method call, but rather into another expression. The following constructs are practically the same: 
\begin{lstlisting}
// construct with loop
loop
  $\ldots$
end loop

// construct with goto
label loop_begin
  $\ldots$
  goto loop_begin
\end{lstlisting}
However, the loop construct has built-in support for loop control expressions. 





\section{Generator Expressions}
\label{sec:generator-expressions}

\syntax\begin{lstlisting}
Loop_Expr      ::= 'for' (Generator_Iter | Generator_Expr)
Generator_Iter ::= '(' Enumerators ')' {nl} (Expr | For_Loop)
Generator_Expr ::= '{' Enumerators '}' {nl} 'yield' Expr
Enumerators    ::= Generator {semi Enumerator}
Enumerator     ::= Generator
                 | Guard
                 | Pattern1 ':=' Expr
Generator      ::= [Label_Dcl] Pattern1 '<-' Expr [Guard]
Guard          ::= Cond_Modifier1
\end{lstlisting}

A {\em generator iteration} ~\lstinline!for ($\enums$) $e$!~ executes expression $e$ for each binding generated by the enumerators $\enums$ and as an expression, it is typed as \code{Unit}. A {\em generator expression} ~\lstinline!for {$\enums$} yield $e$!~ evaluates expression $e$ for each binding generated by the enumerators $\enums$ and collects the results.

An enumerator sequence always starts with a generator; this can be followed by further generators, value definitions or guards. A {\em generator} ~\lstinline!$p$ <- $e$!~ produces bindings from an expression $e$, which are matched in some way against pattern $p$ (\sref{sec:pattern-matching}). A {\em value definition} ~\lstinline!$p$ := $e$!~ binds the value name $p$ (or several names in a pattern $p$) to the result of evaluating the expression $e$. A {\em guard} ~\lstinline!if $e$!~ (or ~\lstinline!unless $e$!) contains a boolean expression $e$, which restricts enumerated bindings. The precise meaning of generators and guards is defined by translation to invocations of four methods: \code{map}, \code{with_filter}, \code{flat_map} and \code{each}. These methods can be implemented in different ways for different carrier types.

The translation scheme is defined as follows. In a first step, every generator ~\lstinline!$p$ <- $e$!, where $p$ is not irrefutable (\sref{sec:irrefutable-patterns}) for the type of $e$, is replaced by 
\begin{lstlisting}
$p$ <- $e$.with_filter { when $p$ then yes else no }
\end{lstlisting}

Then, the following rules are applied repeatedly, until all comprehensions are eliminated. 
\begin{itemize}

\item A comprehensioin 
\begin{lstlisting}
for {$p$ <- $e$} yield $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.map { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension
\begin{lstlisting}
for {<<$l$>> $p$ <- $e$} yield $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.map({ when $p$ then $e'$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehension 
\begin{lstlisting}
for ($p$ <- $e$) $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.each { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for (<<$l$>> $p$ <- $e$) $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.each({ when $p$ then $e'$ }, label: $l$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehension 
\begin{lstlisting}
for {$p$ <- $e$; $p'$ <- $e'\ \ldots$} yield $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}
$e$.flat_map { when $p$ then for {$p'$ <- $e'\ \ldots$ } yield $e''$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for {<<$l$>> $p$ <- $e$; $p'$ <- $e'\ \ldots$} yield $e''$
\end{lstlisting}
where $l$ is a label name, and where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.flat_map(
  { when $p$ then for {$p'$ <- $e'\ \ldots$ } yield $e''$ },
  label: $l$
)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehension 
\begin{lstlisting}
for ($p$ <- $e$; $p'$ <- $e'\ \ldots$) $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}
$e$.each { when $p$ then for ($p'$ <- $e'\ \ldots$) $e''$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for (<<$l$>> $p$ <- $e$; $p'$ <- $e'\ \ldots$) $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.each(
  { when $p$ then for ($p'$ <- $e'\ \ldots$) $e''$ },
  label: $l$
)
\end{lstlisting}

\item A generator ~\lstinline!$p$ <- $e$!~ followed by a guard ~\lstinline!if $g$!~ is translated to a single generator
\begin{lstlisting}
$p$ <- $e$.with_filter(($x_1 \commadots x_n$) -> { $g$ })
\end{lstlisting}
where $x_1 \commadots x_n$ are the free variables of the pattern $p$. 

\item A generator ~\lstinline!$p$ <- $e$!~ followed by a guard ~\lstinline!unless $g$!~ is translated to a single generator
\begin{lstlisting}
$p$ <- $e$.with_filter(($x_1 \commadots x_n$) -> { !($g$) })
\end{lstlisting}
where $x_1 \commadots x_n$ are the free variables of the pattern $p$. 

\item A generator ~\lstinline!$p$ <- $e$!~ followed by a definition ~\lstinline!$p'$ := $e'$!~ is translated to the following generator of pairs of values, where $x$ and $x'$ are fresh names:
\begin{lstlisting}
($p$, $p'$) <- for {$x$ @ $p$ <- $e$} yield { val $x'$ @ $p'$ := $e'$; ($x$, $x'$) }
\end{lstlisting}

\end{itemize}

Generators in generator expression can optionally have a label $l$ assigned, so that expressions like ~\lstinline!break $l$!~ could work.\footnote{It is up to the concrete method how it handles the invocation, which uses \code{throw}-\code{catch} expressions -- however, ignoring it may result in an uncaught \code{Throwable} killing the thread.} Like with other loop expressions, if an \code{exhausted} or a \code{broken} loop control expression is given in the generator iteration expression $e$, it is passed to the outermost \code{each} method as a named argument, possibly along the \code{label} argument. 

\example The following code produces all pairs of numbers between $1$ and $n - 1$, whose sums are prime numbers. 
\begin{lstlisting}
for { i <- 1 .. n
      j <- 1 .. i
      if is_prime? i + j
} yield (i, j)
\end{lstlisting}
The comprehension is translated to:
\begin{lstlisting}
(1..n).flat_map {
  when i then (1 .. i).
    with_filter { (j) -> { is_prime? i + j } }.
    map { when j then (i, j) }
}
\end{lstlisting}

\example Generator expressions can be used to express vector and matrix algorithms concisely.
\begin{lstlisting}[mathescape=false]
def transpose[$A](xss: List[List[$A]]): List[List[$A]] :=
  for {i <- 0 .. xss(0).length} yield {
    for (xs <- xss) yield xs(i)
  }
\end{lstlisting} 
The comprehension is translated to: 
\begin{lstlisting}[mathescape=false]
def transpose[$A](xss: List[List[$A]]): List[List[$A]] := 
  (0 .. xss(0).length).
    map { 
      when i then xss.
        map { when xs then xs(i) }
    }
\end{lstlisting}






\section{Collection Comprehensions}
\label{sec:collection-comprehensions}

\syntax\begin{lstlisting}
List_Literal       ::= '%' Collection_Flags '[' 'for' Generator_Expr ']'
Dictionary_Literal ::= '%' Collection_Flags '{' 'for' Generator_Expr '}'
Bag_Literal        ::= '%' Collection_Flags '(' 'for' Generator_Expr ')'
\end{lstlisting}

Collection comprehensions extend the syntax of collection ``literals''\footnote{Pure literals are terminal symbols in the language, but collection literals are wrappers around virtually any expression.}, so that collections may be defined by not their explicit values, but by a function that generates them -- and that function is a generator. Only tuple literals don't have collection comprehension, due to their special nature within the language. 

Note that the generator expression for dictionary literal comprehension has to generate values of type ~\lstinline!($K$, $E$)!, where $K$ is the type of the keys and $E$ is the type of mapped values. 






\section{Pattern Matching \& Case Expressions}

\syntax\begin{lstlisting}
Match_Expr     ::= Pat_Match_Expr | Case_Expr
Pat_Match_Expr ::= 'match' Simple_Expr1 Match_Body
Match_Body     ::= semi When_Clauses 'end' ['match']
                 | '{' When_Clauses '}'
When_Clauses   ::= When_Clause {['next'] semi When_Clause} 
                   [['next'] 'else' Cond_Block]
When_Clause    ::= 'when' Pattern [Guard] ('then' | semi) Cond_Block
Case_Expr      ::= 'case' Simple_Expr1 Case_Body
Case_Body      ::= semi Case_Clauses 'end' ['case']
                 | '{' Case_Clauses '}'
Case_Clauses   ::= Case_Clause {['next'] semi Case_Clause}
                   [['next'] 'else' Cond_Block]
Case_Clause    ::= 'when' Case_Patterns ('then' | semi) Cond_Block
Case_Patterns  ::= Case_Pattern {',' Case_Pattern}
Case_Pattern   ::= Stable_Id
                 | literal [('..' | '...') literal]
                 | id
                 | Infix_Expr
\end{lstlisting}

Pattern matching is described in (\sref{sec:pattern-matching}). Here, the syntax of expressions that make use of pattern matching is given. 

Case expressions 
\begin{lstlisting}
case $e$ { when $c_1$ then $b_1\ \ldots$ when $c_n$ then $b_n$ else $b_{n+1}$ }
\end{lstlisting}
are simplified pattern matching expressions, though they do not use pattern matching at all, but {\em case equality} instead, defined with the method ``\lstinline!===!''. Thus, case expressions do not aim at matching the selector expression $e$, thus decomposing the selector $e$, but rather tests if it falls into a particular set of values, defined using the case equality method, by:
\begin{itemize}
\item a type of values ~\lstinline!$c$.`===`($e$)!,
\item a range of values ~\lstinline!($e_1$ .. $e_2$).`===`($e$)!, 
\item a set of values defined by another value ~\lstinline!$e_1$.`===`($e$)!.
\end{itemize}

Let $T$ be the type of the selector expression $e$. The parameter $p_i$ of each invocation of the method ``\lstinline!===!'' is typed with $T$ as its expected type and \code{Boolean} as the return type. It is an error if $T$ does not conform to the actual type of the parameter, as the invocation would not be applicable (\sref{sec:function-applications}). The method ``\lstinline!===!'' may be overloaded for multiple parameter types, then overloading resolution (\sref{sec:overloading-resolution}) applies as usual. 

The method ``\lstinline!===!'' is defined basically as follows:
\begin{lstlisting}
operator === ($x$: $T$): Boolean
  $\ldots$
end
\end{lstlisting}
where $x$ is the parameter name and $T$ is the expected type of the parameter, and the type of the selector expression $e$. 

The expected type of every block $b_i$ is the expected type of the whole pattern matching expression. The type of the pattern matching expression is then the weak least upper bound (\sref{sec:conformance}) of the types of all blocks $b_i$.

Multiple values can define a case pattern, for convenience. Note that no variables are bound from the case pattern to the corresponding block.





\section{Unconditional Expressions}

Unconditional expressions change the flow of programs without a condition. 

\subsection{Return Expressions}
\label{sec:return-expressions}

\paragraph{Implicit return expressions}
Implicit return expression is always the value of the last expression in a code execution path. 

\syntax\begin{lstlisting}
Result_Expr ::= Anon_Params '->' Block 
              | ['memoize'] Expr
\end{lstlisting}

\paragraph{Explicit return expressions}
Explicit return expressions unconditionally change the flow of programs by making the enclosing function definition return a value early (or return no value). 

\syntax\begin{lstlisting}
Return_Expr ::= ['memoize'] 'return' [Expr] [Cond_Modifier1]
\end{lstlisting}

A return expression ~\lstinline!return $e$!~ must occur inside the body of some enclosing method, or inside a block nested in the body of the innermost enclosing method. Unlike in Scala, the innermost enclosing method in a source program, $f$, does not need to have an explicitly declared result type, as the result type can be inferred as the weak least upper bound of all return paths, including the explicit return path. The return expression evaluates the expression $e$ and returns its value as the result of $f$. The evaluation of any statements or expressions following the return expression is omitted.The type of a return expression is \code{Nothing}.

The expression $e$ may be omitted, then the return expression \code{return} is type-checked and evaluated as if it was ~\lstinline!return ()!, typed as \code{Unit}. 

Returning from a nested block is implemented by throwing and catching a specialized exception, which may be seen by \code{throw}-\code{catch} expressions (\sref{sec:throw-catch-expressions}) between the point of return and the enclosing method. If such a block is captured and run later, at the point where the original call stack frame is long gone, the exception might propagate up the call stack that ran the captured block. Returning from anonymous functions does not affect the enclosing method. 

\paragraph{Memoized return expressions}
A returned expression may optionally be memoized, by using the keyword \code{memoize} right before the returned expression $e$ or ~\lstinline!return $e$!. In that case, arguments and reference to \code{self} are captured and stored along the returned value, so that further calls to the same method with the same arguments may be sped up significantly (\sref{sec:memoization}). Memoization is not available from within anonymous functions and blocks. 






\subsection{Structured Return Expressions}

\syntax\begin{lstlisting}
Return_Expr ::= ['memoize'] 'return' Var_Def 'do' 
                Block_Stat {semi Block_Stat} 
                'end' ['return']
\end{lstlisting}

A structured return expression is practically the same as explicit return expression. The variable defined in it has its scope extended to the following block statements, which are evaluated, and then the variable is returned. 






\subsection{Local Jump Expressions}
\label{sec:local-jump-expressions}

\syntax\begin{lstlisting}
Jump_Expr  ::= Goto_Expr | Label_Dcl
Goto_Expr  ::= 'goto' label_name [Cond_Modifier1]
Label_Dcl  ::= 'label' label_name 
             | '<<' label_name '>>'
label_name ::= plain_id
\end{lstlisting}

Local jumps transfer control from the points of \code{goto} statements to the statements following a \code{label}. Such a jump may only occur inside of the same function, i.e. it is not possible to jump from one method to another. Also, the jump can't happen to be from outside of a loop into a loop, but the other way around is possible. The only loop expressions that may be jumped out of are the pure loop (\sref{sec:pure-loops}) and a \code{while} loop, which are not transformed as comprehensions into method calls. 






\subsection{Continuations}
\label{sec:continuations}






\subsubsection{Unlimited continuations}

Unlimited continuations are defined by the whole program, as the unlimited continuation allows almost arbitrary non-local jumps. The unlimited continuation is captured with \code{call/cc} function. 

\paragraph{Definitions}
The following code shows how a function that create unlimited continuations might be defined. 
\begin{lstlisting}
protocol Continuation [-A, +B] extends Function_1[A, B] {$\ldots$}
protocol Unlimited_Continuation [-A] extends Continuation[A, Unit] {$\ldots$}
def call/cc [A, B <: A] (&ctx: Unlimited_Continuation[A] -> B?): A end
\end{lstlisting}

A continuation, while internally holding a copy of the call stack that it was created in, is basically a function from the value that is passed into it to some other type. Unlimited continuations are restricted in the means that the input and output type has to be the same, as an unlimited continuation directly changes its result value based on that without any further modification -- the modification is to be actually performed by the code that invokes the unlimited continuation. Delimited continuations do not have this restriction, as the captured continuation is well defined and delimited to a particular scope. 

To vindicate the signature of \code{Unlimited_Continuation[A]}, it extends \code{Continuation[A, Unit]} because when invoked, it does not return any value and instead the given argument is what its \code{call/cc} application returns -- and therefore \code{call/cc} has to return a value of the same type that the unlimited continuation accepts as argument. This is unlike a delimited continuation, where invocation of the continuation does not continue from \code{reset}. 

\example The following shows how to invoke a continuation. 
\begin{lstlisting}
call/cc {|cont| cont () }
call/cc {|cont| cont 1 }
call/cc {|cont| cont 1, 2, 3 }
\end{lstlisting}
In this example, each line captures the current continuation, with unlimited scope -- the whole call stack is duplicated for that to be possible. Once a continuation is invoked, the code that follows the corresponding \code{call/cc} is resumed, with the passed arguments being the result value. On the first line, the continuation is immediately invoked with no arguments, therefore the \code{call/cc} returns the unit value ``\code{()}''. On the second line, the continuation is immediately invoked with argument \code{1}, therefore the \code{call/cc} returns the value \code{1}. On the third line, the continuation is immediately invoked with arguments \code{1, 2, 3}, therefore the \code{call/cc} returns the value \code{Sequence(1, 2, 3)}. 

Since invoking the continuation changes history and the return value of \code{call/cc}, the values passed as arguments to its invocation are limited to the expected type of the original application of \code{call/cc}. It is an error if a continuation is invoked with a value of an incompatible type. A similar restriction applies to delimited continuations as well. 

There is no requirement for functions that use unlimited continuations to define their return type with any special annotations regarding continuation passing style -- there would not be any result type available, since the whole remaining program is the result. 

The initial application of \code{call/cc} returns whatever the given block returns, and such value has to be compatible with the expected type of the \code{call/cc} application. If the block itself invokes the continuation, then its return value is discarded and replaced with the arguments of the continuation invocation. 







\subsubsection{Delimited continuations}

Delimited continuations are defined with \code{reset} and \code{shift} functions. Reset and shift expressions are actually not language constructs, but rather regular functions that have a native implementation capable of unconditionally changing the standard control flow of a program. Moreover, the first \code{shift} expression (which captures the delimited continuation) controls the return value of the \code{reset} expression, which overrides the implicit return expression (\sref{sec:return-expressions}).

The difference between unlimited and delimited continuations is in the scope where the call stack is captured. With delimited continuations, that is defined by the scope of \code{reset} -- once \code{reset} is applied, there is no changing of its value, unlike with unlimited continuations, where the \code{call/cc} is similar to delimited continuation's \code{shift}. 

If the delimited continuation is stored to be used outside of \code{reset}'s bounds, then it can possibly return a value, but never modify the value of the original \code{reset} application.

A \code{reset} application is typed with its expected type and its result type is derived from the statically known contents of its passed block. If at any point there is a \code{Any} type occurring, it might propagate down into the result type. 

\paragraph{Definitions}
The following code shows how functions that create delimited continuations might be defined. 
\begin{lstlisting}
class Shift [+A, -B, +C] (val cont: Continuation[A, B] -> C) {
  def map [A1] (f: A -> A1): Shift[A1, B, C] := {
    Shift.new (k: Continuation[A1, B]) -> { cont((x: A) -> k(f(x))) }
  }
  def flat_map [A1, B1, C1 <: B] (f: A -> Shift[A1, B1, C1]): 
      Shift[A1, B1, C] := {
    Shift.new (k: Continuation[A1, B1]) -> { f(x).cont(k) }
  }
}
def reset [A, C] (ctx: => @[CPS_Param[A, C]] A): C end
def shift [A, B, C] (cont: Continuation[A, B] -> C): @[CPS_Param[B, C] A
annotation CPS_Param [-B, +C] {$\ldots$}
type CPS_Type [A] := CPS_Param[A, A]
type Suspendable := CPS_Param[Unit, Unit]
\end{lstlisting}

Here, the \code{ctx} parameter represents the block that is passed to \code{reset}. For typing, each \code{shift} block is virtually converted to a \code{for}-comprehension:
\begin{lstlisting}
val ctx := for {
  $x$ <- Shift.new($y$)
} yield ($b$)
\end{lstlisting}
where $x$ is a name representing the value that is assigned with the value of the \code{shift} application, $y$ is the block passed to \code{shift}, and $b$ is the code continuation that follows the application of \code{shift} (and which may possibly include more \code{shift} applications). 

\paragraph{Note}
Here, the \code{ctx} parameter is causing the passed block to be used as a positional argument. But for the type system, the annotation \code{@[CPS_Param[A, C]]} makes the type of the argument convert to a \code{for}-comprehension as specified, similar to what workflows (\sref{sec:workflows}) do with their passed blocks. Both conversions may happen dynamically at runtime. Therefore, the passed block is eventually a regular positional argument anyway. 

\example An example of a delimited continuation in use. 
\begin{lstlisting}
reset do
  shift {|cont: Integer -> Integer|
    cont(5)
  } + 1
end
\end{lstlisting}
For the type system, it looks as if it was the following code:
\begin{lstlisting}
val ctx := for {
  x <- Shift.new {|cont: Integer -> Integer|
    cont(5)
  }
} yield (x + 1)
reset(ctx)
\end{lstlisting}

\paragraph{Note}
Coral uses stack slice/copy mechanisms instead of code conversions to actually implement both continuations. Due to this, the continuations are technically less limited, but the typing of its expressions may get complicated easily, as the control flow is manipulated on VM level.

% TBD: add the example from http://dcsobral.blogspot.cz/2009/07/delimited-continuations-explained-in.html and explain it step-by-step, incl. the double flat_map





\section{Throw, Catch \& Ensure Expressions}
\label{sec:throw-catch-expressions}

\syntax\begin{lstlisting}
Catch_Expr  ::= Catch_Expr1 | Catch_Expr2
Catch_Expr1 ::= 'begin' Block 
                'catch' semi When_Clauses
                ['ensure' semi Block_Stat {semi Block_Stat}] 'end'
                'end'
Catch_Expr2 ::= '{' Block '}'
                'catch' '{' When_Clauses '}'
                ['ensure' '{' Block_Stat {semi Block_Stat} '}']
Throw_Expr  ::= 'throw' Expr
\end{lstlisting}

A throw expression ~\lstinline!throw $e$!~ evaluates the expression $e$. The type of this expression must conform to \code{Throwable}. It is an error if $e$ evaluates to \code{nil} or ~\lstinline!()!. If there is an active \code{begin}-\code{catch} expression that handles the thrown value, evaluation is resumed with the handler, otherwise a thread executing the \code{throw} is aborted. The type of a \code{throw} expression is \code{Nothing}. 

A \code{begin}-\code{catch} expression is of the form ~\lstinline!{ $b$ } catch $h$!, where $h$ is a handler pattern matching anonymous function (\sref{sec:pattern-matching-anon-fun})
\begin{lstlisting}
{ when $p_1$ then $b_1$ $\ldots$ when $p_k$ then $b_k$ else $b_{k+1}$ } .
\end{lstlisting}

This expression is evaluated by evaluating the block $b$ -- if evaluation of $b$ does not throw any value, the result of $b$ is returned, otherwise the handler $h$ is applied to the thrown value. If the handler $h$ contains a \code{when} clause matching the thrown value, the first such clause is invoked (and may throw another value, or the same value). If the handler contains no such clause, the value is re-thrown. 

Let $T$ be the expected type of the \code{begin}-\code{catch} expression. The block $b$ is expected to conform to $T$. The handler $h$ is expected to conform to type ~\lstinline!Partial_Function[Throwable, $T$]!. The type of the \code{begin}-\code{catch} expression is the weak least upper bound (\sref{sec:conformance}) of the type of $b$ and the result type of $h$. 

A \code{begin}-\code{ensure} expression ~\lstinline!{ $b$ } ensure { $e$ }!~ evaluates the block $b$. If evaluation of $b$ does not cause any value to be thrown, the block $e$ is evaluated. If any value is thrown during evaluation of $e$, the evaluation of the whole expression is aborted with the thrown value. If no value is thrown during evaluation of $e$, the result of $b$ is returned as the result of the whole expression, unless $e$ contains an explicit \code{return} (\sref{sec:return-expressions}) -- in that case, the value returned from $e$ replaces the value returned from $b$, even if $b$ returns a value explicitly. 

If a value is thrown during evaluation of $b$, the \code{ensure} block $e$ is also evaluated. If another value is thrown during evaluation of $e$, evaluation of the whole expression is aborted with the new thrown value and the previous is discarded. If no value is thrown during evaluation of $e$, the original value thrown from $b$ is re-thrown once evaluation of $e$ has completed, unless $e$ again contains an explicit \code{return} (\sref{sec:return-expressions}) -- in that case, the value thrown from $b$ is discarded, and the value returned from $e$ is returned. 


The block $b$ is expected to conform to the expected type of the whole expression and the \code{ensure} block $e$ is expected to conform to type \code{Unit}. 

An expression ~\lstinline!{ $b$ } catch $e_1$ ensure { $e_2$ }!~ is a shorthand for ~\lstinline!{{ $b$ } catch $e_1$ } ensure { $e_2$ }!. 





\subsection{Raise Expressions}

\syntax\begin{lstlisting}
Raise_Expr ::= 'raise' Raiseable
Raiseable  ::= string_literal
             | Path [',' string_literal]
             | Expr
\end{lstlisting}

A raise expression ~\lstinline!raise $e$!~ is similar to ~\lstinline!throw $e$! (\sref{sec:throw-catch-expressions}), it throws a value (raises an error) that is expected to be of type \code{Raiseable}. It has three variants: 
\begin{itemize}
\item[] \lstinline!raise $s$!, where $s$ is a string provided to constructor of the type \code{Runtime_Error}. 
\item[] \lstinline!raise $T$, $s$!, where $s$ is a string provided to constructor of the type $T$. 
\item[] \lstinline!raise $e$!, where $e$ is an expression, whose type is expected to conform to \code{Raiseable}, and whose result value will be raised after its evaluation. 
\item[] \lstinline!raise!, which raises a value of type \code{Runtime_Error} without any message. Such errors should not propagate outside of the method that raises them. 
\end{itemize}

\code{Raiseable} is a subtype of \code{Throwable}. 







\subsection{Rescue Expressions}

\syntax\begin{lstlisting}
Rescue_Expr  ::= [Label_Dcl] (Rescue_Expr1 | Rescue_Expr2)
Rescue_Expr1 ::= 'begin' Block 
                 'rescue' [Pattern [Guard]] semi Rescue_Block
                 {'rescue' [Pattern [Guard]] semi Rescue_Block }
                 ['ensure' semi Block_Stat {semi Block_Stat}] 'end'
Rescue_Expr2 ::= '{' Block '}' 
                 'rescue' [Pattern [Guard]] '{' Rescue_Block '}'
                 {'rescue' [Pattern [Guard]] '{' Rescue_Block '}'}
                 ['ensure' '{' Block_Stat {semi Block_Stat} '}']
Fun_Stats    ::= Block
                 {'rescue' [Pattern [Guard]] semi Rescue_Block }
                 ['ensure' semi Block_Stat {semi Block_Stat}]
Rescue_Block ::= {Rescue_Stat semi} [Result_Expr]
Rescue_Stat  ::= Block_Stat | Retry_Expr
Retry_Expr   ::= 'retry' [label_name] [Cond_Modifier1]
\end{lstlisting}

Rescue expression ~\lstinline!rescue $h$!~ is similar to catch expression (\sref{sec:throw-catch-expressions}), with two major differences: First, each \code{rescue} is followed by \code{when} clause; second, all \code{rescue} expressions in the same scope form together a handler $h$, where rules from catch expressions apply, only that $h$ is expected to conform to type ~\lstinline!Partial_Function[Raiseable, $T$]!, where $T$ is the expected type of the whole \code{begin}-\code{rescue} expression. 

The syntactic overlap with \code{ensure} expression signifies that the same expression with the exact same behavior may be used with \code{rescue} expressions as well. 

Optionally, the \code{rescue} may appear before any \code{begin} keyword, being connected to the function body instead as the expression protected agains raiseables (this does not apply to \code{catch}), where the \code{begin} is implied to be at the very start of the function's body. 

The ~\lstinline!retry $l$!~ expression is available inside of each raiseable handler block, and evaluating it restarts evaluation of the whole expression since \code{begin} of the labeled rescue expression, or if no label is given, then of the innermost (if nested) rescue expression. Again, it is not available in catch handler block. 

The keyword ~\lstinline[language=Java]!try!~ is not available in Coral -- in Coral, there is no trying, there is doing or not doing.  





\section{Anonymous Functions}
\label{sec:anonymous-functions}

\syntax\begin{lstlisting}
Anon_Fun        ::= Anon_Params '->' '{' Block '}'
Result_Expr     ::= Anon_Params '->' Block 
Anon_Params     ::= Bindings {'->' Bindings}
                  | Param_Clause
                  | '(' ['implicit'] id ')'
                  | '(' [Nameless_Param] ')'
Bindings        ::= '(' Binding {',' Binding} ')'
Binding         ::= (id | '_') [':' Type]
Nameless_Params ::= Nameless_Param {',' Nameless_Param}
Nameless_Param  ::= '_' [':' Type]
\end{lstlisting}

The anonymous function ~\lstinline!($x_1$: $T_1 \commadots x_n$: $T_n$) -> { $b$ }!~ maps parameters $x_i$ of types $T_i$ to a result value given by evaluation of block $b$. The scope of each formal parameter $x_i$ is $e$. Formal parameters must have pairwise distinct names.\footnote{In future versions of Coral, a syntax where curly brackets are not required to be surrounding an anonymous function's body may be allowed.}

If the expected type of an anonymous function is of the form ~\lstinline!Function_$n$[$S_1 \commadots S_n$, $R$]!, the expected type of $b$ is $R$ and the type $T_i$ of any of the parameters $x_i$ can be omitted, in which case $T_i = S_i$ is assumed. If there is no expected type of the anonymous function, then for each parameter $x_i$ which has no explicit type $T_i$, $T_i$ is assumed to be \code{Object}, and the type of the result value is also assumed to be \code{Object}. 

Note that anonymous functions explicitly specify all of their parameters, unlike anonymous pattern matching functions (\sref{sec:pattern-matching-anon-fun}), where the parameters are inferred from the expected type. 

The anonymous function is evaluated as the following expression:
\begin{lstlisting}
(Function_$n$[$S_1 \commadots S_n$, $T$] with {
  def apply ($x_1$: $T_1 \commadots x_n$: $T_n$): $T$ := { $b$ }
}).new
\end{lstlisting}

In the case of a single untyped formal parameter, ~\lstinline!($x$) -> { $b$ }!~ can be abbreviated to ~\lstinline!$x$ -> { $b$ }!. If an anonymous function ~\lstinline!($x$: $T$) -> { $b$ }!~ with a single typed parameter appears as the result of expression of a block, it can be abbreviated to ~\lstinline!$x$: $T$ -> { $b$ }!.

A formal parameter may also be a wildcard represented by an underscore ``\lstinline!_!''. In that case, a fresh name for the parameter is chosen arbitrarily. 

A parameter of an anonymous function may optionally be preceded by an \code{implicit} modifier. In that case the parameter is labeled \code{implicit} (\sref{sec:implicit-params-views}); however the parameter section itself does not count as an implicit parameter section in the sense of (\sref{sec:implicit-parameters}). Such a parameter ~\lstinline!implicit $x_i$!~ is then added transparently to the block $b$ as ~\lstinline!implicit val $y_i$ := $x_i$!, where $y_i$ is a fresh name. Also, therefore arguments to anonymous functions always have to be given explicitly. 
% TBD: decide whether to add placeholder syntax: _.map(_ + 1)

\example Examples of anonymous functions:
\begin{lstlisting}
// identity function
x -> { x }

// curried function composition
f -> g -> x -> { f(g(x)) }

// a summation function
(x: Integer, y: Integer) -> { x + y }

// a function which takes an empty parameter list,
// increments a non-local variable (via closure)
// and returns the new value
() -> { count += 1; count }

// a function that ignores its argument and returns 5
_ -> { 5 }
\end{lstlisting}







\subsection{Method Values}
\label{sec:method-values}

\syntax\begin{lstlisting}
Simple_Expr ::= '&' Simple_Expr1
              | '&' '(' Simple_Expr1 ')'
\end{lstlisting}

The expression ~\lstinline!&$e$!~ (or alternatively ~\lstinline!&($e$)!) is well-formed if $e$ is of method type or if $e$ is a call-by-name parameter. If $e$ is a method with parameters, ~\lstinline!&$e$!~ represents $e$ converted to a function type by eta expansion (\sref{sec:eta-expansion}). If $e$ is a parameterless method or call-by-name parameter of type ~\lstinline!=> $T$!, ~\lstinline!&$e$!~ represents the function of type ~\lstinline!() -> $T$!, which evaluates $e$ when it is applied to the empty parameter list ~\lstinline!()!. 

\example The method values in the left column are each equivalent to the anonymous functions (\sref{sec:anonymous-functions}) on their right. 
\begin{lstlisting}[deletekeywords={range}]
&(Math.sin)                (x)      -> { Math.sin(x) }
&(Array.range)             (x1, x2) -> { Array.range(x1, x2) }
&(List.map_2)              (x1, x2) -> (x3) -> { List.map_2(x1, x2)(x3) }
&(List.map_2(xs, ys))      (x)      -> { List.map_2(xs, xy)(x) }
&(42.`*`)                  (x)      -> { 42 * x }
\end{lstlisting}

Note that if $e$ resolves to a parameterless method of type ~\lstinline!() -> $T$!~ or if $e$ has a method type ~\lstinline!() $\mapsto\ T$!, it is evaluated to type $T$ (\sref{sec:method-conversions}) -- and the method value syntax provides a way to prevent this. 





\section{Anonymous Classes}
\label{sec:anonymous-classes}

\syntax\begin{lstlisting}
Anon_Class      ::= ['class' [Class_Param_Clauses] 'extends'] 
                    [Early_Defs] Anon_Class_Tmpl
Anon_Class_Tmpl ::= Class_Parents 'with' '{' [Template_Body] '}'
\end{lstlisting}

Anonymous classs are a mechanism to implement an abstract class or override a concrete class ``ad hoc'', in place where needed, without needing to create a new constant (although as an expression, the anonymous class definition can indeed be assigned to a constant and gain its name). Anonymous classes can't be type constructors (\sref{sec:type-constructors}). 

A minimal anonymous class expression is of the form ~\lstinline!$c$ with { $t$ }!, where $c$ is the class that the anonymous class inherits from (can be even \code{Object}), and $t$ is the template of the anonymous class. The anonymous class inherits all traits mixed into this parent class, and can itself include or prepend more traits (via the \code{Class_Parents} syntax element). 

Optionally, the anonymous class may define its own primary constructor parameters, in which case the form of the anonymous class is ~\lstinline!class ($\ps_1$)$\ldots$($\ps_n$) extends $c$ with { $t$ }!, where $\ps_1$ to $\ps_n$ are the primary constructor parameters. Superclass constructor arguments may be specified in any case. 






\section{Statements}
\label{sec:statements}

\syntax\begin{lstlisting}
Block_Stat    ::= Use
                | {Annotation} ['implicit'] Def
                | {Annotation} {Local_Modifier} Tmpl_Def
                | Expr
                | Alias_Expr
                | Capture_Usage
                | ()
Template_Stat ::= Use
                | {Annotation} {Modifier} Def
                | {Annotation} {Modifier} Dcl
                | Prop_Dcl
                | Prop_Def
                | 'include' Container_Path [Cond_Modifier]
                | 'prepend' Container_Path [Cond_Modifier]
                | Expr
                | Alias_Expr
                | ()
Fun_Stats     ::= [Fun_Stat {semi Fun_Stat}] Return_Expr
                | Block
                  {'rescue' [Pattern [Guard]] semi Block }
                  ['ensure' semi Block_Stat {semi Block_Stat}]
Fun_Stat      ::= Block_Stat
Fun_Dec_Expr  ::= {Annotation} Dcl
                | {Annotation} ['implicit'] Def
                | 'transparent'
                | 'opaque'
                | 'native' [Expr]
                | ()
Alias_Expr    ::= 'alias' symbol_literal 'is' symbol_literal
Capture_Usage ::= 'use' id {',' id} 'as' ('weak' | 'unowned' | 'soft')
\end{lstlisting}

Statements occur as parts of blocks and templates. Despite their name, they are actually generally expressions as well, except that for some statements, their value is not much of a use, i.e. use clauses, whose value is a \code{nil}, or the empty statement/expression, whose value is again \code{nil}. 

Function statements is an umbrella term for a series of statements and expressions, so their effective value is more complex. 

An expression that is used as a statement can have an arbitrary value type. An expression statement $e$ is evaluated by evaluating $e$ and discarding and releasing the result of the evaluation. 

Block statements may be definitions, which bind local names in the block. The only modifier allowed in all block-local definitions is \code{implicit}. When prefixing a class or object definition, modifiers \code{abstract}, \code{final} and \code{sealed} are also permitted (\sref{sec:modifiers}).

Evaluation of a statement sequence entails evaluation of the statements in the order they are written. This behavior can be overridden for statement sequences in workflows (\sref{sec:workflows}).

Statement can be an import via a use clause (\sref{sec:use-clauses}), a definition or an expression, or it can be empty. Statements used in the template of a class definition can also be declarations. 

A function that is declared with \code{transparent} in its \code{declare} block, is visible as referentially transparent, and therefore the compiler and possibly the runtime as well are given the possibility to replace function applications of this same function with its previously computed result with the same arguments on the same receiver instance. In that sense, it is similar to memoization (\sref{sec:memoization}), but skips one call stack frame and works better during compilation, unlike memoization, which is a runtime feature. On the other hand, a function that is declared with \code{opaque} in its \code{declare} block, is visible as referentially opaque and those optimizations are disabled for it, so the function is re-evaluated each time it is applied. 

A function that is declared with \code{native} in its \code{declare} block, has its body defined outside of Coral source files, possibly in other languages, native to the platform of the Coral VM. For now, some CSL functions are declared this way and a possibility to let users define their own native functions is upcoming in future versions of Coral. Note that the native implementation of the function would have to match the expected platform of the Coral VM, or maybe the expression would map platforms to the native implementations of the function. 

An alias to a function name creates a duplicate record in method table of a class or a duplicate variable pointing to the aliased function name. From that scope on, the functions are bound by name, and aliased function names are also inherited. It is an error if a subtype tries to override an aliased function name. 






\section{Implicit Conversions}
\label{sec:implicit-conversions}

Implicit conversions can be applied to expressions whose type does not match their expected type, to qualifiers in selections, and to unapplied methods. The available implicit conversions are given in the next two sub-sections.

We say that a type $T$ is {\em compatible} to a type $U$ if $T$ weakly conforms to $T$ after applying eta-expansion (\sref{sec:eta-expansion}) and view applications (\sref{sec:views}), if necessary.






\subsection{Value Conversions}
\label{sec:value-conversions}

The following implicit conversions can be applied to an expression $e$, which is of some value type $T$ and which is type-checked with some expected type $\exptype$. Some of these implicit conversions may be disabled with pragmas.

\paragraph{Overloading resolution}
If an expression denotes several possible members of a class, overloading resolution (\sref{sec:overloading-resolution}) is applied to pick a unique member. 

\paragraph{Type instantiation}
An expression $e$ of a polymorphic type
\begin{lstlisting}
[$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$] $\mapsto\ T$
\end{lstlisting}
which does not appear as the function part or a type application is converted to a type instance of $T$ by determining with local type inference (\sref{sec:local-type-inference}) instance types $T_1 \commadots T_n$ for the type variables $a_1 \commadots a_n$ and implicitly embedding $e$ in the type application ~\lstinline!$e$[$T_1 \commadots T_n$]! (\sref{sec:type-applications}). 

\paragraph{Numeric widening}
If $e$ is of a number type which weakly conforms (\sref{sec:conformance}) to the expected type, it is widened to the expected type. 

\paragraph{Numeric narrowing}
If the expected type has smaller range than the number type of $e$, but the value of $e$ fits into the expected type, it is narrowed to the expected type. 

\paragraph{Value discarding}
If $e$ is of some value type and the expected type is \code{Unit}, $e$ is converted to the expected type by embedding it in the block ~\lstinline!{ $e$; () }!. 

\paragraph{View application}
If none of the previous conversions applies, view applications are not disallowed by pragmas (implicitly they are allowed), and $e$'s type does not conform to the expected type $\exptype$, an attempt is made to convert $e$ to the expected type with a view application (\sref{sec:views}). This can happen in compile time only if all necessary type information is available, otherwise, runtime handles it by using specialized instructions (and those instructions are disabled from compilation when view applications are disabled). 

\paragraph{Dynamic member selection}
If none of the previous conversions applies, and $e$ is a prefix of a selection ~\lstinline!$e$.$x$!, then if $e$'s type conforms to \code{Dynamic_Member_Selecting}, the selection is rewritten according to rules for dynamic member selection (\sref{sec:dynamic-member-selection}). Otherwise, \code{member_not_found} is invoked on the receiver, whose implementation in \code{Object} is to raise an error. 

% TBD: explain in a CFR how dynamic member selecting actually works on the Coral VM level - registering a method fallback chain if a member is not found, here it is like %[:apply_dynamic, :member_not_found], and determine what happens when this is not done (no-op maybe? error maybe? language config error maybe?)





\subsection{Method Conversions}
\label{sec:method-conversions}

The following implicit conversions can be applied to methods which are not applied to some argument list. 

\paragraph{Evaluation}
A parameterless method $m$ of type ~\lstinline!() -> $T$!~ is always converted to type $T$ by evaluating the expression to which $m$ is bound. 

\paragraph{Implicit application}
If the method takes only implicit parameters, implicit arguments are passed following the rules of (\sref{sec:implicit-parameters}).

\paragraph{Eta expansion}
Otherwise, if the expected type $\exptype$ is a function type ~\lstinline!($\Ts'$) -> $T'$!, eta-expansion (\sref{sec:eta-expansion}) is performed on the expression $e$. 

\paragraph{Empty application}
Otherwise, if $e$ is of a method type ~\lstinline!() $\mapsto\ T$!, it is implicitly applied to the empty argument list, yielding ~\lstinline!$e$()!. 






\subsection{Overloading Resolution}
\label{sec:overloading-resolution}

If an identifier or selection $e$ references several members of a class, the context of the reference is used to identify a unique member, if possible. The way this is done depends on whether or not $e$ is used as a function. Note that even if overloaded resolution picks up a unique member, that member still may not be applied in regard of the actual expected types of the function application. Let $\mathcal{A}$ be the set of members referenced by $e$. 

\subsubsection{Function in an application}

Assume first that $e$ appears as a function in an application, as in ~\lstinline!$e$($e_1 \commadots e_m$)!.

\paragraph{Shape-based overloading resolution}
One first determines the set of functions that is potentially applicable based on the {\em shape} of the arguments. 

The shape of an argument expression $e$, written ~\lstinline!$\shape$($e$)!, is a type that is defined as follows:
\begin{itemize}
\item For a function expression ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$) -> $b$!, the shape is ~\lstinline!(Any$\commadots\,$Any) -> $\shape$($b$)!, where \code{Any} occurs $n$ times in the argument type. 
\item For a named argument ~\lstinline!$n$: $e$!, the shape is ~\lstinline!@[named_arg :$n$] $\shape$($e$)!, which is an annotated type.\footnote{This is different from e.g. Scala, since Coral supports captured named arguments, which make the definition of applicable functions different.} % TBD: fix the name of the annotation as it will be chosen over time. 
\item For all other expressions, the shape is \code{Nothing}. 
\end{itemize}

Let $\mathcal{B}$ be the set of alternatives in $\mathcal{A}$ that are {\em applicable} (\sref{sec:function-applications}) to expressions ~\lstinline!($e_1 \commadots e_n$)!~ of types ~\lstinline!($\shape$($e_1$)$\commadots \shape$($e_n$))!. If there is precisely one alternative in $\mathcal{B}$, that alternative is chosen. It is an error if that alternative is not applicable to the expected types of the argument expressions -- the method is unapplied (\sref{sec:value-conversions}). 

\paragraph{Argument counts based overloading resolution}
Otherwise, let $S_1 \commadots S_m$ be the vector of types obtained by typing each argument with an undefined expected type (kind of equivalent to typing it with \code{Any}), keeping the annotations of named arguments attached (from the previous step with the shape of arguments). For every member $m$ in $\mathcal{B}$, one determines whether it is applicable to expressions ~\lstinline!($e_1 \commadots e_m$)!~ of types $S_1 \commadots S_m$, which drops requirements set up by ~\lstinline!$\shape$($e$)!, namely those for function expressions, and therefore members in $\mathcal{B}$ are more likely to be selected. It is an error if none of the members in $\mathcal{B}$ are applicable -- the method is unapplied. If there is one single applicable alternative, that alternative is chosen. 

\paragraph{Applicability based overloading resolution}
Otherwise, let $\mathcal{C}$ be the set of applicable alternatives in the application to $e_1 \commadots e_m$. It is again an error if $\mathcal{C}$ is empty. Otherwise, one chooses the {\em most specific} alternative among the alternatives in $\mathcal{C}$, according to the following definition of being  ``more specific than''.

\begin{definition}
The {\em relative weight} of an alternative $A$ over an alternative $B$ is defined as the sum of relative weights of each argument $e_i$ in the application to $e_1 \commadots e_m$. In the following equation, $A_i$ is the type of the parameter corresponding to $e_i$ in the alternative $A$, and $B_i$ is the type of the parameter corresponding to $e_i$ in the alternative $B$. 

\[\begin{array}{l l}
\weight(A, B) &= \sum_{i=1}^{m} \pweight(A_i, B_i) \\
\pweight(t, u) &= \cweight(t, u) + \rweight(t)
\end{array}
\]

\[\begin{array}{l l}
\cweight(t, u) &= \left\{ 
  \begin{array}{l l}
    1 & \textrm{if $t \conforms u$}\\
    0 & \textrm{otherwise}
  \end{array} \right. \\
\rweight(t) &= \left\{ 
  \begin{array}{l l}
    1 & \textrm{unless $t$ is a repeated or a capturing parameter}\\
    0 & \textrm{otherwise}
  \end{array} \right.
\end{array}\]
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the relative weight of $A$ over $B$ is greater than the relative weight of $B$ over $A$. 

If there are more alternatives in $\mathcal{C}$ that are equally most specific, one chooses one of them as in overloading resolution without any application (\sref{sec:overloading-resolution-no-app}), where $\mathcal{A}$ is the same as $\mathcal{C}$ here, and the expected type is the expected type of the function application. 

\paragraph{Note}
As overloading on return type is possible, note that overloading based on arguments takes precedence over overloading on return type, even if overloading on return type would make different alternative to be chosen. 

\example Assume the following overloaded function definitions:
\begin{lstlisting}
def f (*x: Integer) end             // 1.
def f (x: Integer) end              // 2.
def f (x: Integer, y: Integer) end  // 3.
\end{lstlisting}

In the application \code{f(1)}, there are two applicable alternatives in regard to both shape and argument counts -- the first two. Applicability test gives relative weight to $(1)$ over $(2)$ of $1$, since it has a repeated parameter, and relative weight to $(2)$ over $(1)$ of 2, therefore the second is chosen. 

In the application \code{f(1, 2)}, there are again two applicable alternatives -- the first and the last. Applicability test gives relative weight to $(1)$ over $(3)$ of $2$, since it has a repeated parameter matching both arguments, and relative weight to $(3)$ over $(1)$ of $4$, therefore the second is chosen. 

In the application \code{f(1, 2, 3)}, there is only one applicable alternative (the first), which can be detected (as soon as) based on the shape of its argument expressions. 

\subsubsection{Function in a type application}

Assume next that $e$ appears as a function in a type application, as in ~\lstinline!$e$[$\targs$]!. Then let $\mathcal{B}$ be the set of all alternatives in $\mathcal{A}$ which take the same number of type parameters as there are type arguments in $\targs$ are chosen. It is an error if no such alternative exists -- the type application is unapplied. If there is one such alternative, that one is chosen. 

Otherwise, let $\mathcal{C}$ be the set of those alternatives in $\mathcal{B}$ that are applicable to the type arguments, so that the bounds defined by the alternative's type parameters are satisfied. It is an error if no such alternative exists, and it is also an error if there are several such alternatives, as there is (for now) no way to select a unique member. If there is one such alternative, that one is chosen. 

\subsubsection{Expression not in any application}
\label{sec:overloading-resolution-no-app}

Assume finally that $e$ does not appear as a function in either an application or a type application, (or that overloading resolution on a function in an application was left with several most specific alternatives). If an expected type is given, let $\mathcal{B}$ be the set of those alternatives in $\mathcal{A}$ which are compatible (\sref{sec:implicit-conversions}) to it. Otherwise, let $\mathcal{B}$ be the same as $\mathcal{A}$. It is an error if there is no such alternative. If there is one such alternative, that one is chosen. 

Otherwise, one chooses the {\em most specific} alternative among the alternatives in $\mathcal{B}$, according to the following definition of being ``more specific than'':

\begin{definition}
The {\em relative weight} of an alternative $A$ over an alternative $B$ is defined as a number from $0$ to $1$, defined as:
\begin{itemize}
\item $1$ if $A \conforms B$, $0$ otherwise.
\end{itemize}
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the relative weight of $A$ over $B$ is greater than the relative weight of $B$ over $A$. 

It is an error if there is no alternative in $\mathcal{B}$ which is more specific than all other alternatives in $\mathcal{B}$ -- the method is unapplied.\footnote{This can be fixed e.g. by using typed expressions (\sref{sec:typed-expressions}).}

\paragraph{Note}
This resolution is not applied in case of nested function applications, even though the containing application could possibly provide an expected type for the nested application to successfully select a unique member, based on overloading on result type. This prevents creation of possibly very large matrices of all possible combinations of argument types, which would not only be the product of the simple types of each argument, but also of all supertypes (including traits separate!), which is {\em not feasible}. But argument types have to be know prior to overloading resolution, as if they were to be applied before the containing application, which they probably will be. One way to overcome this limitation is to use dynamic types and type the expression (\sref{sec:typed-expressions}) with a dynamically selected expected type, which has to be {\em specific enough} to make overloading of the nested application possible. After argument types are known, value conversions may be applied to them in order to turn the types from {\em compatible} to {\em conforming}. Therefore, a single function application may still dynamically overload into different unique member being selected with each application. 

\paragraph{Note}
An important note is that when an identifier $e$ references several members of a class, it also references only those members that are visible (\sref{sec:modifiers}) from the scope where $e$ appears. 

% TBD: maybe add more examples? including named arguments, optional arguments...







\subsection{Local Type Inference}
\label{sec:local-type-inference}

Local type inference infers type arguments to be passed to expressions of polymorphic type. Say $e$ is of a type ~\lstinline![$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$] $\mapsto\ T$!~ and no explicit type arguments are given. 

Local type inference converts this expression to a type application ~\lstinline!$e$[$T_1 \commadots T_n$]!. The choice of the type arguments $T_1 \commadots T_n$ depends on the context in which the expression appears and on the expected type $\exptype$. 

Local type inference is not always able to infer all type arguments, and sometimes may even infer useless ones -- in that cases, explicit type arguments are to be used to solve the problems. 

\paragraph{Case 1: Selections}
If the expression appears as a prefix of a selection (or is a function application with empty arguments list) with a name $x$, then type inference is {\em deferred} to the whole expression \code{$e$.$x$}. That is, if \code{$e$.$x$} has type $S$, it is now treated as having type ~\lstinline![$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$] $\mapsto\ S$!, and local type inference is applied in turn to infer type arguments for $a_1 \commadots a_n$, using the context in which \code{$e$.$x$} appears. 

\paragraph{Case 2: Values}
If the expression $e$ appears as a value without being applied to some value arguments in a function application, the type arguments are inferred by solving a constraint system which relates the expression's type $T$ with the expected type $\exptype$. Without loss of generality we can assume that $T$ is a value type; if it is a method type, we apply eta-expansion (\sref{sec:eta-expansion}) to convert it to a function type (which is a value type and we're home again). Solving means finding a substitution $\sigma$ of types $T_i$ for the type parameters $a_i$, such that all of the following conditions hold:
\begin{itemize}
\item None of inferred types $T_i$ is a singleton type (\sref{sec:singleton-types}). % TBD: decide whether this restriction can be removed
\item All type parameter bounds are satisfied, i.e. $\sigma L_i \conforms \sigma a_i$ and also $\sigma a_i \conforms \sigma U_i$ for $i = 1 \commadots n$. 
\item The expression's type conforms to the expected type, i.e. $\sigma T \conforms \sigma \exptype$. 
\end{itemize}

It is an error if no such substitution exists. If several substitutions exist, local type inference will choose for each type variable $a_i$ a minimal or a maximal type $T_i$ of the solution space (where a maximal type is closer to \code{Object} and minimal is closer to \code{Nothing}). A {\em maximal} type $T_i$ will be chosen if the type parameter $a_i$ appears contravariantly (\sref{sec:variance-of-type-parameters}) in the type $T$ of the expression. A {\em minimal} type $T_i$ will be chosen in all other situations, i.e. if the type variable appears covariantly, non-variantly or not at all\footnote{In fact, this particular case with the type not appearing at all might be changed in future versions of Coral to defer inference for it.} in the type $T$. We call such a substitution $\sigma$ an {\em optimal solution} of the given constraint system for the type $T$. 

\paragraph{Case 3: Methods}
This case applies if the expression $e$ appears in an application \code{$e$($d_1 \commadots d_m$)}. In that case $T$ is a method type ~\lstinline!($p_1$: $R_1 \commadots p_n$: $R_n$) $\mapsto\ T'$!. Without loss of generality we can assume that the result type $T'$ is a value type; if it is a method type, we apply eta-expansion (\sref{sec:eta-expansion}) to convert it to a function type (which is a value type and we're home, yet again). Once computes first the types $S_j$ of the argument expressions $d_j$, using two alternative schemes. Each argument expression $d_j$ is typed first with the expected type $R_j$, in which the type parameters $a_1 \commadots a_n$ are taken as type constants. If this fails the argument $d_j$ is typed instead with an expected type $R'_j$, which results from $R_j$ by replacing every type parameter in $a_1 \commadots a_n$ with $\udef$. 

In a second step, type arguments are inferred by solving a constraint system, which relates the method's type with the expected type $\exptype$ and the argument types $S_1 \commadots S_m$. Solving the constraint system means finding a substitution $\sigma$ of types $T_i$ for the type parameters $a_i$, such that all of the following conditions hold:
\begin{itemize}
\item None of inferred types $T_i$ is a singleton type (\sref{sec:singleton-types}). % TBD: decide whether this restriction can be removed
\item All type parameter bounds are satisfied, i.e. $\sigma L_i \conforms \sigma a_i$ and also $\sigma a_i \conforms \sigma U_i$ for $i = 1 \commadots n$. 
\item The method's result type $T'$ conforms to the expected type, i.e. $\sigma T' \conforms \sigma \exptype$. 
\item Each argument type weakly conforms (\sref{sec:conformance}) to the corresponding formal parameter type (\sref{sec:corresponding-parameters}), i.e. $\sigma S_j \conforms _w \sigma R_j$ for $j = 1 \commadots m$. 
\end{itemize}

If a type argument does not appear in the expected type and neither in the argument types, it stays defined with an inaccessible value $\udef$, and is possibly inferred in a future inference run, in case of curried functions. The type arguments that are inferred to be $\udef$ are deferred and preserve their order in a virtual implicit type parameter list of the following parameter lists.\footnote{This is different from Scala, where Scala will infer all type arguments of the first parameter list, even if it would infer not very helpful types.}

It is an error if no such substitution exists. If several solutions exists, an optimal one for the type $T'$ is chosen. 

All or parts of an expected type $\exptype$ may be undefined. The rules for conformance (\sref{sec:conformance}) are extended to this case by adding the rule that for any type $T$, the following two statements are always true:
\begin{itemize}
\item $\udef \conforms T$
\item $T \conforms \udef$
\end{itemize}

It is possible that no minimal or maximal solution for a type variable exists, which is an error. Because ``$\conforms$'' is a partial order, it is also possible that a solution set has several optimal solutions for a type. In that case, Coral is free to pick any one of them. 

\example Consider the two methods, where \code{List} is covariant in its type parameter:
\begin{lstlisting}
def cons [A] (x: A, xs: List[A]): List[A] := x ~> xs
def list_nil [B]: List[B] := List.Nil
\end{lstlisting}
and the definition
\begin{lstlisting}
val xs := cons(1, list_nil)  .
\end{lstlisting}

The application of \code{cons} is typed with an undefined expected type. This application is completed by local type inference to \code{cons[Integer](1, list_nil)}. Here, one uses the following reasoning to infer the type argument \code{Integer} for the type parameter \code{A}:

First, the argument expressions are typed. The first argument \code{1} has type \code{Integer}, whereas the second argument \code{list_nil} is itself polymorphic. One tries to type \code{list_nil} with an expected type \code{List[A]}. This leads to the constraint system
\begin{lstlisting}
List[?B] <: List[A]  ,
\end{lstlisting}
where we have labeled \code{?B} with a question mark to indicate that it is a variable in the constraint system. Because class \code{List} is covariant, the optimal solution of this constraint is a minimal type, 
\begin{lstlisting}
B := Nothing  .
\end{lstlisting}

In the second step, one solves the following constraint system for the type parameter \code{A} of \code{cons}:
\begin{lstlisting}
Integer <: ?A              // for the parameter x
List[Nothing] <: List[?A]  // for the parameter xs
List[?A] <: $\udef$        // for the result type
\end{lstlisting}

The optimal solution of this constraint system is 
\begin{lstlisting}
A := Integer  ,
\end{lstlisting}
so \code{Integer} is the type inferred for \code{A}. 

The optimal solution is found based on the following reasoning: 
\begin{enumerate}
\item Solutions for the first constraint are types \code{Integer} and its supertypes.
\item Solutions for the second constraint are \code{Nothing} and all supertypes of \code{Nothing}, basically any type. Together with the first constraint, only those types from the solution of the first constraint are possible. 
\item Solutions for the third constraint are all types. Together with the first two constraint, only those types from the solution of the first constraint are possible. 
\item Therefore, the minimal type is chosen from the solution space, as \code{A} appears covariantly (\sref{sec:variance-of-type-parameters}) in the type $T$ of the expression (which is \code{List[A]}), which is in turn \code{Integer}. 
\end{enumerate}

\example Consider now the definition
\begin{lstlisting}
val ys := cons("abc", xs)  ,
\end{lstlisting}
where \code{xs} is defined as type \code{List[Integer]} as before. In this case local type inference proceeds as follows.

First, the argument expressions are typed. The first argument \code{"abc"} is of type \code{String}. The second argument \code{xs} is first tried to be typed with expected type \code{List[A]}. This leads to the constraint system
\begin{lstlisting}
List[Integer] <: List[?A]
\end{lstlisting}

In a second step, one solves the following constraint system for the type parameter \code{A} of \code{cons}:
\begin{lstlisting}
String <: ?A
List[Integer] <: List[?A]
List[?A] <: $\udef$
\end{lstlisting}

The optimal solution of this constraint system is
\begin{lstlisting}
A := Object  ,
\end{lstlisting}
so \code{Object} is the type inferred for \code{A}. 

\example Consider now an unrelated definition
\begin{lstlisting}
def test_fun [A, B] (a: A)(b: A, c: B)(d: B) := $\ldots$
\end{lstlisting}

In the function application
\begin{lstlisting}
test_fun(1)(2, "hello")("world")  ,
\end{lstlisting}
the type argument $A$ is inferred to be \code{Integer} and $B$ is inferred to be \code{String} in the following type inference. Note that if the type inference for $B$ was not deferred, it would be inferred to \code{Object}, which would not be really helpful. 

With the same definition, in the following function application
\begin{lstlisting}
val fun := &test_fun(1)  ,
\end{lstlisting}
the value of \code{fun} is of a type \code{[B]((Integer, B) -> B -> Object)}.

Still with the same definition, in the following function application
\begin{lstlisting}
val fun := &test_fun(1)(2, "hello")  ,
\end{lstlisting}
the value of \code{fun} is of a type \code{String -> Object}.





\subsection{Eta-Expansion}
\label{sec:eta-expansion}

{\em Eta-expansion} converts an expression of a method type (not a function application) to an equivalent expression of a function type. It is especially useful to prevent re-evaluation of the expression's subexpressions, if the expression is passed using a by-name strategy. It proceeds in two steps. 

First, one identifies the maximal subexpressions of $e$, let's say these are $e_1 \commadots e_m$. For each of these, one creates a fresh name $x_i$. Let $e'$ be the expression resulting from replacing every maximal subexpression $e_i$ in $e$ by the corresponding fresh name $x_i$. Second, one creates a fresh name $y_i$ for every argument type $T_i$ of the method, for $i = 1 \commadots n$, using named arguments and parameters as defined by the method. The result of eta-conversion is then: 
\begin{lstlisting}
val $x_1$ := $e_1$
$\ldots$
val $x_m$ := $e_m$
($y_1$: $T_1 \commadots y_n$: $T_n$) -> $e'$($y_1 \commadots y_n$)
\end{lstlisting}







\subsection{Dynamic Member Selection}
\label{sec:dynamic-member-selection}

Coral defines a marker trait \code{Dynamic_Member_Selecting} that enables dynamic invocations rewriting without resorting to use error handling mechanisms to implement dynamic dispatch. 

Instances $x$ of this trait allow method invocations ~\lstinline[deletekeywords={method}]!$x$.method(args)! for arbitrary method ~\lstinline[deletekeywords={method}]!method!~ and argument lists \code{args}, as well as property accesses ~\lstinline[deletekeywords={property}]!$x$.property! for arbitrary property names ~\lstinline[deletekeywords={property}]!property!. 

If an invocation is not implemented by $x$ (i.e. if type checking fails and no other implicit conversion provides a way to proceed with the invocation), it is virtually rewritten according to the following rules:

\begin{lstlisting}[deletekeywords={property,method}]
foo.method("blah")      foo.apply_dynamic(:method)("blah")
foo.method(x: "blah")   foo.apply_dynamic_named(:method)((:x, "blah"))
foo.method(1, x: 2)     foo.apply_dynamic_named(:method)(
                            (nil, 1), (:x, "blah"))
foo.property            foo.select_dynamic(:property)
foo.property := 10      foo.update_dynamic(:property)(10)
foo.array(10)           foo.apply_dynamic(:array)(10)
foo.array(10) := 11     foo.select_dynamic(:array).update(10)(11)
\end{lstlisting}






\section{Workflows}
\label{sec:workflows}

Workflows are basically a syntax sugar for a block expression that is passed as an argument to a workflow builder (an object that conforms to \code{Workflow_Builder}). In the following translation table, the left column presents the constructs, and the right column its de-sugared form, where $b$ is the workflow builder. Note that it has to be statically known at compile time that an object is an instance of \code{Workflow_Builder} for this language feature to work properly.

\begin{lstlisting}
b do cexpr end              b.delay(() -> { cexpr })
let pat := expr; cexpr      let pat := expr; cexpr
let! pat := expr; cexpr     b.bind(expr, (pat) -> { cexpr })
return expr                 b.return(expr)
return! expr                b.return_from(expr)
yield expr                  b.yield(expr)
yield! expr                 b.yield_from(expr)
for pat in expr             b.for(expr, (pat) -> { cexpr })
  loop cexpr end 
while expr loop cexpr end   b.while(
                                () -> { expr }, 
                                b.delay(() -> { cexpr }))
if expr then cexpr1         if expr then cexpr1 else cexpr2 end
  else cexpr2 end
if expr then cexpr          if expr then cexpr else b.zero
cexpr1; cexpr2              b.combine(cexpr1, b.delay(() -> { cexpr2 }))
begin cexpr1                b.catch(expr, (v) -> { match v { cexpr2 } })
  catch cexpr2 end
begin cexpr1                b.ensure(cexpr1, () -> { cexpr2 })
  ensure cexpr2 end
\end{lstlisting}






\section{Syntactic Forms}
\label{sec:syntactic-forms}

\subsection{Quasi-quotation}
\label{sec:quasi-quotation}

\syntax\begin{lstlisting}
Quasiquote_Expr ::= '`(' Any_Expr ')'
Any_Expr        ::= Expr
                  | Block_Stat {semi Block_Stat}
                  | Template_Stat {semi Template_Stat}
                  | Alias_Expr
                  | Compilation_Unit
                  | Top_Stat_Seq
Expr            ::= '#{' Expr '}'
\end{lstlisting}

Quasi-quote expression ~\lstinline!`( $e$ )!~ is basically a well-formed piece of Coral source code, wrapped in parentheses preceded by a backtick. The expression represents the compiled expression $e$ in means of an AST node. Alternative way to define a quasi-quoted expression is with the annotation \code{@[quasiquote]}.

Quasi-quote expressions may optionally be interpolated, so that values or other nodes may be injected into the represented AST. There are the following ways to interpolate the AST:
\begin{itemize}
\item Interpolating expression ~\lstinline!#{ $e$ }!, where $e$'s value is expanded into the AST as is. If the expression would require parentheses around it in the source, then parentheses have to be around the interpolating expression.\footnote{Note that the same delimiters are used to interpolate string literals.}
\item The \code{@[unquote]} annotation, which puts parentheses around the annotated expression. 
\item The \code{@[splice]} annotation, where the annotated expression is expanded into the AST as is. 
\end{itemize}

A quasi-quote without any interpolation is equivalent to a quote (\sref{sec:quotation}). 

Quasi-quotes are useful in combination with macros (\sref{sec:macros}). 






\subsection{Quotation}
\label{sec:quotation}

A quote expression is basically a quasi-quote, but without any interpolation. The annotation that marks an expression for quotation is \code{@[quote]}. 















