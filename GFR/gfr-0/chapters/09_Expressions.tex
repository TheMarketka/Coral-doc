%!TEX TS-program = xelatex
%!TEX encoding = UTF-8 Unicode

\chapter{Expressions}

\minitoc

\newpage

% TBD: update this chapter and the syntax gradually as the CLS evolves

\syntax\begin{lstlisting}
Expr        ::= Value_Expr
              | Loop_Expr
              | Rescue_Expr
              | Raise_Expr 
              | Throw_Expr
              | Catch_Expr
              | Return_Expr
              | Assign_Expr
              | Update_Expr
              | Yield_Expr
              | Infix_Expr
              | Annot_Expr
              | Cast_Expr
              | Use_Expr
              | Delayed_Expr
              | Ref_Expr
              | Jump_Expr
              | Anon_Fun
              | Anon_Class
              | Expr semi Expr
Value_Expr  ::= Simple_Expr
              | Cond_Expr
              | Match_Expr
              | New_Expr
              | Def
              | {Local_Modifier} Tmpl_Def
              | '(' Expr ')'
              | 'begin' Expr 'end'
              | Quasiquote_Expr
              | Quote_Expr
              | Metaclass_Access
              | Workflow_Expr
              | Type_Expr
Type_Expr   ::= '(' Type ')'
              | Annot_Type - Nullable_Mod
Simple_Expr ::= Block_Expr
              | Simple_Expr1
              | Method_Expr
              | TT_Expr
Result_Expr ::= ['memoize'] Expr
              | ['memoize'] 'tailcall' Argument_Exprs
Exprs       ::= Expr {',' Expr}
\end{lstlisting}

Expressions are composed of various keywords, operators and operands. Expression forms are discussed subsequently. 







\section{Expression Typing}
\label{sec:expression-typing}

The typing of expressions is often relative to some {\em expected type} (which might be undefined). When we write ``expression $e$ is expected to conform to type $T$'', we mean:
\begin{enumerate}
\item The expected type of $e$ is $T$.
\item The type of expression $e$ must conform to $T$. 
\end{enumerate}

Usually, the type of the expression is defined by the last element of an execution branch, as discussed subsequently with each expression kind. 

What we call ``statement'', in context of Gear is in fact yet another kind of an expression, and those expressions themselves always have a type and a value. 





\section{Data Expressions}





\subsection{Simple Constant Expressions}
\label{sec:literal-expr}

\syntax\begin{lstlisting}
Simple_Expr1 ::= integer_literal
               | floating_point_literal
               | complex_literal
               | rational_literal
               | character_literal
               | boolean_literal
               | string_literal
               | symbol_literal
               | regular_expression_literal
\end{lstlisting}

Typing of literals is as described in (\sref{sec:literals}); their evaluation is immediate. 

Gear guarantees that methods of numeric literals (the class \code{Number}) always terminate, are idempotent, and do not have any observable side effects. 







\subsection{The Nil and Undefined Values}

\syntax\begin{lstlisting}
Simple_Expr1 ::= 'nil'
               | 'undefined'
\end{lstlisting}

The \code{nil} value is of type \code{Nothing}, and is thus compatible with every type that is nullable (\sref{sec:nullable-types}).

The \code{undefined} value is of type \code{Undefined}, a subtype of \code{Nothing}, and is thus also compatible with every type that is nullable (\sref{sec:nullable-types}). 

The \code{nil} represents a ``no object'', and is itself represented by an object. 

A reference to any member of the \code{nil} object causes \code{Member_Not_Found} to be raised, unless the member in fact exists. The \code{nil} object is also frozen by default. 

The \code{undefined} represents also ``no object'', being itself represented by an object, but also represents ``undefined value'', which could be any of the following:
\begin{itemize}
  \item Undefined dynamically accessed instance variable or class object variable. This is a common case. 
  \item Undefined values for keys in implementations of \code{Map}. This is also a common case, if the \code{nil} object is to be considered a legit value. 
  \item Undefined type argument.
  \item Rarely, undefined value or variable. Could happen if there is an extreme error in a macro, or basically a bug in the language. 
\end{itemize}

Defined values and variables may not be undefined by assigning them with the \code{undefined} object directly by user code, but it is important to note that this may happen on special occasions indirectly, most notably during hot code loading, e.g. if the definition of an instance variable goes missing from the new code version. 

See (\sref{sec:emptiness}) for more details on ``nothing'' values. 






\subsection{Tuple Expressions}
\label{sec:tuples}

\syntax\begin{lstlisting}
Simple_Expr1 ::= '(' [Named_Exprs] ')'
Named_Exprs  ::= Named_Expr {',' Named_Expr}
Named_Expr   ::= [['~'] id ':'] Expr
\end{lstlisting}

A tuple expression ~\lstinline!($e_1 \commadots e_n$)!~ is an alias for the class instance creation ~\lstinline!Tuple_$n$($e_1 \commadots e_n$)!, where $n \geq 2$. The empty tuple ~\lstinline!()!~ is the unique value of type \code{Unit}. A tuple with only one value is only the value itself, without being wrapped in a tuple. Also ~\lstinline!Tuple_1!~ is a special type (pretty much like \code{Any} or \code{Auto}), which helps to make this possible even in dynamic use cases. 

Sub-expressions in a tuple expression that are prepended with an id (in form of ~\lstinline!~$x_i$: $e_i$!) are named $x_i$ -- this adds annotation ~\lstinline!@[named :$x_i$]!~ to the type of the sub-expression. If the annotation is explicitly added, the behaviour is the same. Named sub-expressions, either in the syntax sugar or explicit form, can only appear at the end of the sequence of sub-expressions, thus no unnamed sub-expressions can appear after a named sub-expression. 

Tuple expressions have the runtime type of ~\lstinline!Gear/Language.Tuple_$n$[$T_1 \commadots T_n$]!, where each $T_i$ is the known type of each $e_i$, including the annotations that name sub-expressions. 

Tuple expressions might be automatically converted into full argument expressions, as defined in (\sref{sec:function-applications}).





\subsection{List Expressions}
\label{sec:list-expressions}

\syntax\begin{lstlisting}
Words        ::= Word {{? Unicode whitespace ?}+ Word}
Word         ::= {id_char}+
Simple_Expr1 ::= List_Expr
List_Expr    ::= '%' List_Flags '[' [Expr {semi Expr}] ']'
               | '%w' List_Flags '[' [Words] ']'
List_Flags   ::= [['i' | (* immutable *)
                   'm']  (* mutable *)
                  ['l']] (* double linked *)]
\end{lstlisting}

An expression of the form ~\lstinline!%[$e_1$; $\ldots$; $e_n$]! is a list expression. 

% TBD: elaborate on the forms and types




\subsection{Array Expressions}
\label{sec:array-expressions}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Array_Expr
Array_Expr   ::= '%' Array_Flags '[|' [Expr {semi Expr}] '|]'
               | '%w' Array_Flags '[|' Words '|]'
Array_Flags  ::= [['i' | (* immutable *)
                   'm']] (* mutable *)
\end{lstlisting}

An expression of the form ~\lstinline!%[|$e_1$; $\ldots$; $e_n$|]! is an array expression. 





\subsection{Dictionary Expressions}
\label{sec:dict-expressions}

\syntax\begin{lstlisting}
Simple_Expr1    ::= Dictionary_Expr
Dictionary_Expr ::= '%' Dict_Flags '{' [Dict_Mapping1 {semi Dict_Mapping1}] '}'
                  | '%' Dict_Flags '{' [Dict_Mapping2 {semi Dict_Mapping2}] '}'
Dict_Mapping1   ::= Simple_Expr1 '=>' Expr
Dict_Mapping2   ::= ['~'] id ':' Expr
Dict_Flags      ::= [['i' | (* immutable *)
                      'm']  (* mutable *)
                     ['l']] (* linked *)
\end{lstlisting}

An expression of the form ~\lstinline!%{$e_1$; $\ldots$; $e_n$}! is a dictionary expression. 




\subsection{Multimap Expressions}
\label{sec:multimap-expressions}

\syntax\begin{lstlisting}
Simple_Expr1  ::= Multimap_Expr
Multimap_Expr ::= '%' Dict_Flags '{{' [Dict_Mapping1 {semi Dict_Mapping1}] '}}'
                | '%' Dict_Flags '{{' [Dict_Mapping2 {semi Dict_Mapping2}] '}}'
\end{lstlisting}

An expression of the form ~\lstinline!%{{$e_1$; $\ldots$; $e_n$}}! is a multimap expression. 






\subsection{Bag Expressions}
\label{sec:bag-expressions}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Bag_Expr
Bag_Expr     ::= '%' Bag_Flags '(' [Expr {semi Expr}] ')'
               | '%' Bag_Flags '(' [Expr {semi Expr}] ')'
Bag_Flags    ::= [['i' | (* immutable *)
                   'm']  (* mutable *)
                  ['l']  (* linked *)
                  ['s']] (* set instead of bag (tally-less bag) *)
\end{lstlisting}

An expression of the form ~\lstinline!%($e_1$; $\ldots$; $e_n$)! is a bag expression. 





\subsection{Record Expressions}
\label{sec:record-expressions}

\syntax\begin{lstlisting}
Simple_Expr1       ::= Record_Expr
Record_Expr        ::= 'record' [nl] '{' [nl] Record_Fields_Init [nl] '}'
Record_Fields_Init ::= Record_Field_Init {semi Record_Field_Init}
Record_Field_Init  ::= Stable_Id '=>' Expr
\end{lstlisting}

An expression of the form
\begin{lstlisting}
record { $i_1$ => $e_1$; $\ldots$; $i_n$ => $e_n$ }
\end{lstlisting}
is a record expression. 






\subsection{Record Clone Expressions}
\label{sec:record-clone-expressions}

\syntax\begin{lstlisting}
Simple_Expr1       ::= Record_Clone_Expr
Record_Clone_Expr  ::= 'record' [nl] 
                       '{' [nl] Expr 'with' Record_Fields_Init [nl] '}'
Record_Fields_Init ::= Record_Field_Init {semi Record_Field_Init}
Record_Field_Init  ::= Stable_Id '=>' Expr
\end{lstlisting}

An expression of the form
\begin{lstlisting}
record { $e$ with $i_1$ => $e_1$; $\ldots$; $i_n$ => $e_n$ }
\end{lstlisting}
is a record clone expression. 





\subsection{Object Clone Expressions}
\label{sec:object-clone-expressions}

\syntax\begin{lstlisting}
Simple_Expr1      ::= Object_Clone_Expr
Object_Clone_Expr ::= '{<' Object_Ivars_Init '>}'
Object_Ivars_Init ::= Object_Ivar_Init {semi Object_Ivar_Init}
Object_Ivar_Init  ::= id '=>' Expr
\end{lstlisting}

An expression of the form
\begin{lstlisting}
{< $i_1$ => $e_1$; $\ldots$; $i_n$ => $e_n$ >}
\end{lstlisting}
is an object clone expression. 





\subsection{Delayed Expressions}
\label{sec:delayed-expressions}

\syntax\begin{lstlisting}
Delayed_Expr ::= 'lazy' [nl] Expr
\end{lstlisting}

Delayed expressions of the form ~\lstinline!lazy $e$!~ are a syntax sugar for:
\begin{lstlisting}[deletekeywords={new}]
Gear/Language.Lazy.new(() -> { $e$ })
\end{lstlisting}

The \code{Gear/Language.Lazy} instance is not automatically unboxed, unlike lazy value or variable definitions. It is an error to define a lazy value or variable with a delayed expression, as that would be only redundant. The delayed expression is evaluated by sending the instance a ``\code{value}'' message\footnote{This is the behaviour of call-by-need parameters.}, or by using the prefix operator ``\lstinline@!@''. The delayed expression is force re-evaluated by sending the instance a ``\code{value!}'' message, overwriting any previous value\footnote{This is the behaviour of call-by-name parameters.}, or by using the prefix operator ``\lstinline@!!@'', with the same side-effect. 






\subsection{Ref Expressions}
\label{sec:ref-expressions}

\syntax\begin{lstlisting}
Ref_Expr ::= 'ref' [nl] Expr
\end{lstlisting}

Ref expressions of the form ~\lstinline!ref $e$!~ are a syntax sugar for:
\begin{lstlisting}[deletekeywords={new}]
Gear/Language.Reference_Cell.new($e$)
\end{lstlisting}

The \code{Gear/Language.Reference_Cell} instance is not automatically unboxed. The contained value can be retrieved from a reference cell using the prefix operator ``\lstinline@!@'', or by sending the instance a ``\code{value}'' message. The contained value can be overwritten by using the infix operator ``\lstinline!<-!'', or by sending the instance a ``\code{value_=}'' message. 

Reference cells are lightweight instances that can be used to simulate output parameters at low costs, in both CPU cycles and the language design.

\example An example of how to manipulate reference cells. 
\begin{lstlisting}
(* initialize a reference cell *)
let a := ref 42
let b := Gear/Language.Reference_Cell.new(42)
let c := new Gear/Language.Reference_Cell(42)

(* retrieve contained value from reference cell *)
let d := !a
let e := a.value

(* change the value the reference cell contains *)
a <- 64
a.value := 128
\end{lstlisting}





\subsection{Workflows}
\label{sec:workflows}

\syntax\begin{lstlisting}
Workflow_Expr          ::= Expr ['do'] '{' Workflow_or_Range_Expr '}'
Workflow_or_Range_Expr ::= Workflow | Short_Workflow | Range_Expr

Workflow ::= 'let!' (Pattern2 | var_dcl) ':=' Expr semi Workflow
           | Val_Def semi Workflow
           | Var_Def semi Workflow
           | 'def' Fun_Def semi Workflow
           | 'type' Type_Def 'end' ['type'] semi Workflow
           | Tmpl_Def semi Workflow
           | 'yield!' Expr
           | Yield_Expr
           | 'return!' Expr
           | Return_Expr
           | 'if' Condition ('then' | semi) Workflow 'end' ['if']
           | 'if' Condition ('then' | semi) Cond_Block 
             {[semi] 'elsif' Condition ('then' | semi) Cond_Block}
             Else Workflow 'end' ['if']
           | 'match' Simple_Expr1 semi Wf_When {semi Wf_When}
             [semi Else Workflow] {semi ('rescue' | 'catch') Wf_When} 
             'end' ['match']
           | 'match' Simple_Expr1 '{' Wf_When {semi Wf_When}
             [semi Else Workflow] {semi ('rescue' | 'catch') Wf_When} '}'
           | 'case' Simple_Expr1 semi Wf_Case {semi Wf_Case}
             [semi Else Workflow] {semi ('rescue' | 'catch') Wf_Case} 'end' ['case']
           | 'case' Simple_Expr1 '{' Wf_Case {semi Wf_Case}
             [semi Else Workflow] {semi ('rescue' | 'catch') Wf_Case} '}'
           | 'switch' Simple_Expr semi Wf_Switch {semi Wf_Switch}
             [semi Else Workflow] 'end' ['switch']
           | 'switch' Simple_Expr '{' Wf_Switch {semi Wf_Switch}
             [semi Else Workflow] '}'
           | 'begin' Workflow 
             'catch' [nl] Wf_When {semi Wf_When} [semi Else Workflow]
             ['ensure' semi Block_Stat {semi Block_Stat}] 'end'
           | '{' Workflow '}' 'catch' 
             '{' Wf_When {semi Wf_When} [semi Else Workflow] '}'
             'ensure' '{' Block_Stat {semi Block_Stat} '}'
           | 'begin' Workflow 
             'rescue' [Pattern [Guard]] semi Workflow
             {'rescue' [Pattern [Guard]] semi Workflow }
             ['ensure' semi Block_Stat {semi Block_Stat}] 'end'
           | '{' Workflow '}' 'rescue' 
             'rescue' [Pattern [Guard]] '{' Workflow '}'
             {'rescue' [Pattern [Guard]] '{' Workflow '}' }
             'ensure' '{' Block_Stat {semi Block_Stat} '}'
           | Rethrow_Expr (* only between 'catch' .. 'end' *)
           | Reraise_Expr (* only between 'rescue' .. 'end' *)
           | ('while' | 'until') Condition 
             'loop' Workflow 'end' ['loop']
           | ('while' | 'until') Condition 
             '{' Workflow '}'
           | Workflow ('while' | 'until') Condition
           | 'for' Val_Dcls 'in' ['reverse'] Expr
             ['step' Expr] 'loop' Workflow 'end' ['loop']
           | 'for' Val_Dcls 'in' ['reverse'] Expr
             ['step' Expr] '{' Workflow '}'
           | Workflow semi Workflow
           | Expr
           
Short_Workflow ::= 'for' Generator_Expr
                 | [Label_Dcl] 'for' Val_Dcls 'in' ['reverse'] Expr 
                   ['step' Expr] Wf_For_Loop
           
Wf_When       ::= 'when' Pattern [Guard] ('then' | semi) Workflow
Wf_Case       ::= 'when' Case_Patterns ('then' | semi) Workflow
Wf_Switch     ::= 'when' Switches ('then' | semi) Workflow
Wf_For_Loop   ::= 'loop' Wf_Loop_Block 'end' ['loop']
                | '{' Wf_Loop_Block '}'
Wf_Loop_Block ::= {Wf_Yield | Block_Stat | Loop_Ctrl_Expr}
Wf_Yield      ::= Yield Expr
\end{lstlisting}

% TODO: finish Workflow, continue with loop, while, for
% TODO: finish the definitions




\subsection{Collection Comprehensions}
\label{sec:collection-comprehensions}

\syntax\begin{lstlisting}
List_Literal       ::= '%' [CF] '['  Collection_Gen  ']'
Array_Literal      ::= '%' [CF] '[|' Collection_Gen '|]'
Dictionary_Literal ::= '%' [CF] '{'  Collection_Gen  '}'
Bag_Literal        ::= '%' [CF] '('  Collection_Gen  ')'
Collection_Gen     ::= (Workflow_Expr | Expr) ['in' Range_Expr]
                     | Short_Workflow
                     | Range_Expr
\end{lstlisting}

Collection comprehensions extend the syntax of collection ``literals''\footnote{Pure literals are terminal symbols in the language, but collection literals are wrappers around virtually any expression.}, so that collections may be defined not by their explicit values, but by a function that generates them -- and that function is a generator. Only tuple literals don't have collection comprehension, due to their special nature within the language. 

Note that the generator expression for dictionary literal comprehension has to generate values of type ~\lstinline!($K$, $E$)!, where $K$ is the type of the keys and $E$ is the type of mapped values, or, if the actual dictionary type defines its own entry type, values that are members of the entry type. 

If the \code{Workflow_Expr} inside the collection literal uses \code{Seq_Literal} or similar on-demand computations, the collection literal value is also a cache for its results. 

If the expression that generates values would create an infinite collection, the \code{in Range_Expr} specification can be used to constrain the generated values to the given range. 

% TBD: define traits/annotations like "literal-convertible", "collection-literal" and "collection-literal-builder", so that generators may produce different values and those will be inserted into the collection from the literal without the extra allocation for system-defined literal type; convert either from the system-defined literal type, or use update() for dictionaries and add() for lists, arrays, bags/sets. Also add a trait/annotation that will define that this is not needed for when the type is a system-provided type. 





\subsection{Sequence Comprehensions}
\label{sec:sequence-comprehensions}

\syntax\begin{lstlisting}
Collection_Literal ::= Seq_Literal
Eagerness          ::= ['eager' | 'lazy']
Seq                ::= Eagerness 'seq'
Seq_Literal        ::= Seq '{' Collection_Gen '}'
Collection_Literal ::= Seq_Literal
\end{lstlisting}

Apart from collection comprehensions (\sref{sec:collection-comprehensions}), Gear offers also sequence comprehensions. The crucial difference is in evaluation: collection comprehension trigger eager evaluation, unless indeed the used source collection does not employ lazy evaluation of some kind by itself. Sequence comprehension, on the other hand, is super-lazy. 

A sequence generated by the form ~\lstinline!seq { $e$ }!~ works like a forgetting enumerator -- it computes values using the expression $e$ only when they are required. This is most useful for very large sequences, and/or when the computation is expensive in some way. 

The expression $e$ may be of a few different kinds:
\begin{itemize}
  \item A \code{Range_Expr}, in which case the sequence is based on a given range, optionally including a \code{delta}, which then defines the increment between each value (and which can indeed be \code{1} or more, not limited to fractions of \code{1}). Such a sequence is {\em linear}, and its size is determinable without computing all the values. At most one bound can be infinity, in which case the size of the sequence is infinite. 
  \item A \code{Method_Expr}, in which case a function that accepts a key (or an index, if you wish) and computes the corresponding value. Such a sequence is {\em indexed}, but its size is undefined. 
  \item A workflow using \code{yield} and \code{yield!} to feed the sequence with a next value. Such a sequence is again {\em linear}, and its size is defined when all values are computed. 
\end{itemize}

In every case, a range may be optionally given to constrain the generated sequence. 

The Gear Standard Runtime Library offers more functions to manipulate and create sequences. 

A sequence comprehension expression ~\lstinline!seq { $e$ }!~ is equivalent to ~\lstinline!lazy seq { $e$ }!, whereas ~\lstinline!eager seq { $e$ }!~ is implicitly cached, but eagerly evaluated -- and thus can't use \code{Method_Expr}, because there is no known range of keys or indexes.\footnote{The GSRL offers functions to overcome this issue.}





\subsection{Literal Conversions \& Collection Builders}
\label{sec:literal-conversions}

Literal convertible implementations can be seen as a higher-priority views from a literal to the expected type -- these are automatically attempted before any view applications (\sref{sec:implicit-conversions}), and are not affected by implicit conversions being disabled in the scope.





\subsubsection{Nil \& Undefined Literal Convertible}

\begin{lstlisting}
protocol Nil_Literal_Convertible 
    [T <: Nil_Literal_Convertible[T]] 
    extends Object
  message self.new (nil_literal: Nothing): T end
end protocol
\end{lstlisting}

A not-nullable or strictly not-nullable value type may implement the protocol \code{Gear/Language.Nil_Literal_Convertible}, and then it accepts both \code{nil} and \code{undefined} values without error -- the expression that assigns these values to a variable of such a type $T$ is converted into application of \code{$T$.new(nil)}. The conversion is applied also dynamically, and also before any attempts of view applications. 

In GSRL, the \code{Gear/Language.Option[T]} type implements this protocol. 

% \subsubsection{String Literal Convertible}
% TBD: finish this after API is ready
% \subsubsection{Tuple Literal Convertible}
% TBD: is this needed?

\subsubsection{List Literal Convertible}

\begin{lstlisting}
protocol List_Literal_Convertible 
    [T <: List_Literal_Convertible[T]] 
    extends Object
  type Acceptable_Element_Type end type
  message self.new (list_literal: List[Acceptable_Element_Type]): T end
end protocol
\end{lstlisting}

Any type may implement the protocol \code{Gear/Language.List_Literal_Convertible}, and then list literals may be converted to the type. 





\subsection{Generator Expressions}
\label{sec:generator-expressions}

\syntax\begin{lstlisting}
Loop_Expr      ::= 'for' (Generator_Expr | Generator_Iter)
Generator_Iter ::= '(' Enumerators ')' {nl} (Expr | For_Loop)
Yield          ::= 'yield' | 'yield!'
Generator_Expr ::= '{' Enumerators '}' {nl} Yield Expr
Enumerators    ::= Generator {semi Enumerator}
Enumerator     ::= Generator
                 | Guard
                 | Pattern1 ':=' Expr
Generator      ::= [Label_Dcl] Pattern1 'in' Expr [Guard]
Guard          ::= Cond_Modifier1
\end{lstlisting}

A {\em generator iteration} ~\lstinline!for ($\enums$) $e$!~ executes expression $e$ for each binding generated by the enumerators $\enums$ and as an expression, it is typed as \code{Unit}. A {\em generator expression} ~\lstinline!for {$\enums$} yield $e$!~ evaluates expression $e$ for each binding generated by the enumerators $\enums$ and collects the results.

An enumerator sequence always starts with a generator; this can be followed by further generators, value definitions or guards. A {\em generator} ~\lstinline!$p$ in $e$!~ produces bindings from an expression $e$, which are matched in some way against pattern $p$ (\sref{sec:pattern-matching}). A {\em value definition} ~\lstinline!$p$ := $e$!~ binds the value name $p$ (or several names in a pattern $p$) to the result of evaluating the expression $e$. A {\em guard} ~\lstinline!if $e$!~ (or ~\lstinline!unless $e$!) contains a boolean expression $e$, which restricts enumerated bindings. The precise meaning of generators and guards is defined by translation to invocations of four methods: \code{map}, \code{with_filter}, \code{flat_map} and \code{each}. These methods can be implemented in different ways for different carrier types.

The translation scheme is defined as follows. In a first step, every generator ~\lstinline!$p$ in $e$!, where $p$ is not irrefutable (\sref{sec:irrefutable-patterns}) for the type of $e$, is replaced by 
\begin{lstlisting}
$p$ in $e$.with_filter { when $p$ then yes otherwise no }
\end{lstlisting}

Then, the following rules are applied repeatedly, until all comprehensions are eliminated. 
\begin{itemize}

\item A comprehensioin 
\begin{lstlisting}
for {$p$ in $e$} yield $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.map { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension
\begin{lstlisting}
for {<<$l$>> $p$ in $e$} yield $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.map({ when $p$ then $e'$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehensioin 
\begin{lstlisting}
for {$p$ in $e$} yield! $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.flat_map { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension
\begin{lstlisting}
for {<<$l$>> $p$ in $e$} yield! $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.flat_map({ when $p$ then $e'$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 


\item A comprehension 
\begin{lstlisting}
for ($p$ in $e$) $e'$
\end{lstlisting}
is translated to
\begin{lstlisting}
$e$.each { when $p$ then $e'$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for (<<$l$>> $p$ in $e$) $e'$
\end{lstlisting}
where $l$ is a label name, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.each({ when $p$ then $e'$ }, label: $l$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

\item A comprehension 
\begin{lstlisting}
for {$p$ in $e$; $p'$ in $e'\ \ldots$} yield $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}
$e$.flat_map { when $p$ then for {$p'$ in $e'\ \ldots$ } yield $e''$ }
\end{lstlisting}
If there was \code{yield!} instead of \code{yield}, then \code{yield!} is also in the translated code. 

\item A comprehension 
\begin{lstlisting}
for {<<$l$>> $p$ in $e$; $p'$ in $e'\ \ldots$} yield $e''$
\end{lstlisting}
where $l$ is a label name, and where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.flat_map(
  { when $p$ then for {$p'$ in $e'\ \ldots$ } yield $e''$ },
  label: $l$
)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. If there was \code{yield!} instead of \code{yield}, then \code{yield!} is also in the translated code. 

\item A comprehension 
\begin{lstlisting}
for ($p$ in $e$; $p'$ in $e'\ \ldots$) $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}
$e$.each { when $p$ then for ($p'$ in $e'\ \ldots$) $e''$ }
\end{lstlisting}

\item A comprehension 
\begin{lstlisting}
for (<<$l$>> $p$ in $e$; $p'$ in $e'\ \ldots$) $e''$
\end{lstlisting}
where $\ldots$ is a (possibly empty) sequence of generators, value definitions, or guards, is translated to
\begin{lstlisting}[deletekeywords={label}]
$e$.each(
  { when $p$ then for ($p'$ in $e'\ \ldots$) $e''$ },
  label: $l$
)
\end{lstlisting}

\item A generator ~\lstinline!$p$ in $e$!~ followed by a guard ~\lstinline!if $g$!~ is translated to a single generator
\begin{lstlisting}
$p$ in $e$.with_filter(($x_1 \commadots x_n$) -> { $g$ })
\end{lstlisting}
where $x_1 \commadots x_n$ are the free variables of the pattern $p$. 

\item A generator ~\lstinline!$p$ in $e$!~ followed by a guard ~\lstinline!unless $g$!~ is translated to a single generator
\begin{lstlisting}
$p$ in $e$.with_filter(($x_1 \commadots x_n$) -> { not $g$ })
\end{lstlisting}
where $x_1 \commadots x_n$ are the free variables of the pattern $p$. 

\item A generator ~\lstinline!$p$ in $e$!~ followed by a definition ~\lstinline!$p'$ := $e'$!~ is translated to the following generator of pairs of values, where $x$ and $x'$ are fresh names:
\begin{lstlisting}
($p$, $p'$) in for {$x$ @ $p$ in $e$} yield { val $x'$ @ $p'$ := $e'$; ($x$, $x'$) }
\end{lstlisting}

\end{itemize}

Generators in generator expression can optionally have a label $l$ assigned, so that expressions like ~\lstinline!break $l$!~ could work.\footnote{It is up to the concrete method how it handles the invocation, which uses \code{throw}-\code{catch} expressions -- however, ignoring it may result in an uncaught \code{Throwable} killing the thread.} Like with other loop expressions, if an \code{exhausted} or a \code{broken} loop control expression is given in the generator iteration expression $e$, it is passed to the outermost \code{each} method as a named argument, possibly along the \code{label} argument. 

\example The following code produces all pairs of numbers between $1$ and $n - 1$, whose sums are prime numbers. 
\begin{lstlisting}
for { i in 1 .. n
      j in 1 .. i
      if is_prime? i + j
} yield (i, j)
\end{lstlisting}
The comprehension is translated to:
\begin{lstlisting}
(1 .. n).flat_map {
  when i then (1 .. i)
    .with_filter { j -> { is_prime? i + j } }
    .map { when j then (i, j) }
}
\end{lstlisting}

\example Generator expressions can be used to express vector and matrix algorithms concisely.
\begin{lstlisting}
def transpose[A](xss: List[List[A]]): List[List[A]] :=
  for {i in 0 .. xss(0).length} yield {
    for (xs in xss) yield xs(i)
  }
\end{lstlisting} 
The comprehension is translated to: 
\begin{lstlisting}
def transpose[A](xss: List[List[A]]): List[List[A]] := 
  (0 .. xss(0).length)
    .map { 
      when i 
        xss.map { when xs then xs(i) }
    }
\end{lstlisting}






\subsection{Anonymous Functions}
\label{sec:anonymous-functions}

\syntax\begin{lstlisting}
Anon_Fun        ::= Anon_Params '->' '{' Block '}'
                  | 'def' Anon_Params '->' Expr
                  | 'def' Params2 '->' Expr
                  | 'function' When_Clauses 'end' ['function']
                  | 'function' '{' When_Clauses '}'
Result_Expr     ::= Anon_Params '->' Block 
Anon_Params     ::= Bindings {'->' Bindings}
                  | Param_Clause
                  | id [':' Type]
                  | '(' ['implicit'] id ')'
                  | '(' [Nameless_Params] ')'
                  | Nameless_Param
Bindings        ::= '(' Binding {',' Binding} ')'
Binding         ::= (id | '_') [':' Type]
Nameless_Params ::= Nameless_Param {',' Nameless_Param}
Nameless_Param  ::= '_' [':' Type]
\end{lstlisting}

The anonymous function ~\lstinline!($x_1$: $T_1 \commadots x_n$: $T_n$) -> { $b$ }!~ maps parameters $x_i$ of types $T_i$ to a result value given by evaluation of block $b$. The scope of each formal parameter $x_i$ is $e$. Formal parameters must have pairwise distinct names.\footnote{In future versions of Gear, a syntax where curly brackets are not required to be surrounding an anonymous function's body may be allowed.}

If the expected type of an anonymous function is of the form ~\lstinline!Function_$n$[$S_1 \commadots S_n$, $R$]!, the expected type of $b$ is $R$ and the type $T_i$ of any of the parameters $x_i$ can be omitted, in which case $T_i = S_i$ is assumed. If there is no expected type of the anonymous function, then for each parameter $x_i$ which has no explicit type $T_i$, $T_i$ is assumed to be \code{Object}, and the type of the result value is also assumed to be \code{Object}. 

Note that anonymous functions explicitly specify all of their parameters, unlike anonymous pattern matching functions (\sref{sec:pattern-matching-anon-fun}), where the parameters are inferred from the expected type. 

The anonymous function is evaluated as the following expression:
\begin{lstlisting}
(Function_$n$[$S_1 \commadots S_n$, $T$] with {
  def apply ($x_1$: $T_1 \commadots x_n$: $T_n$): $T$ := { $b$ }
}).new
\end{lstlisting}

In the case of a single untyped formal parameter, ~\lstinline!($x$) -> { $b$ }!~ can be abbreviated to ~\lstinline!$x$ -> { $b$ }!. If an anonymous function ~\lstinline!($x$: $T$) -> { $b$ }!~ with a single typed parameter appears as the result of expression of a block, it can be abbreviated to ~\lstinline!$x$: $T$ -> { $b$ }!.

A formal parameter may also be a wildcard represented by an underscore ``\lstinline!_!''. In that case, a fresh name for the parameter is chosen arbitrarily. 

A parameter of an anonymous function may optionally be preceded by an \code{implicit} modifier. In that case the parameter is labeled \code{implicit} (\sref{sec:implicit-params-views}); however the parameter section itself does not count as an implicit parameter section in the sense of (\sref{sec:implicit-parameters}). Such a parameter ~\lstinline!implicit $x_i$!~ is then added transparently to the block $b$ as ~\lstinline!implicit val $y_i$ := $x_i$!, where $y_i$ is a fresh name. Also, therefore arguments to anonymous functions always have to be given explicitly. 

\example Examples of anonymous functions:
\begin{lstlisting}
(* identity function *)
x -> { x }

(* curried function composition *)
f -> g -> x -> { f(g(x)) }

(* a summation function *)
(x: Integer, y: Integer) -> { x + y }

(* a function which takes an empty parameter list,
   increments a non-local variable (via closure)
   and returns the new value *)
() -> { count += 1; count }

(* a function that ignores its argument and returns 5 *)
_ -> { 5 }
\end{lstlisting}





\subsubsection{Placeholder Syntax for Anonymous Functions}
\label{sec:placeholder-functions}

\syntax\begin{lstlisting}
Simple_Expr1 ::= '%' digit {digit}
\end{lstlisting}

An expression (\code{Expr}) may contain embedded percent symbols ``\lstinline!%!'' followed by a number at places where identifiers are legal. Such an expression represents an anonymous function, where each numbered percent symbol denotes the corresponding positional parameter, and the zero-numbered symbol denotes the anonymous function itself.\footnote{This is different from Scala where the parameters are referenced with an underscore and not numbered -- they are successive.}

Define an {\em anonymous section} to be an expression of the form ~\lstinline!%$n$ as $T$!, where $T$ is a type, or else of the form ~\lstinline!%$n$!, provided that the percent symbol does not appear as the expression part of a typed expression. 

An expression $e$ of syntactic category \code{Expr} {\em binds} an anonymous section $u$, if the following conditions hold:
\begin{enumerate}
  \item $e$ properly contains $u$
  \item there is no other expression of syntactic category \code{Expr} which is properly contained in $e$ and which itself properly contains $u$
\end{enumerate}

If an expression $e$ binds anonymous sections $u_1 \commadots u_n$, in order specified by the numbering (and with blanks in between filled by a fresh $u_i$), it is equivalent to the anonymous ~\lstinline!($u'_1 \commadots u'_n$) -> { $e'$ }!, where each $u'_i$ results from $u_i$ by replacing the percent symbol with a fresh identifier and $e'$ results from $e$ by replacing each $u_i$ with $u'_i$. If $u_i$ was a part of a typed expression, the corresponding parameter is typed the same and the $u'_i$ in $e$ does not need to be typed anymore. 

\example The anonymous functions in the left column use placeholder syntax. Each of these is equivalent to the anonymous function to its right. 
\begin{lstlisting}
%1                    x -> { x }
%1 + 1                x -> { x + 1 }
%1 * %2               (x, y) -> { x * y }
(%1 as Integer) * 2   (x: Integer) -> { x * 2 }
if %1 then x else y   z -> { if z then x else y }
%1.map(f)             x -> { x.map(f) }
%1.map(%1 + 1)        x -> { x.map(y -> { y + 1 }) }
if %1 <= 1 then 1     x -> { if x <= 1 then 1 
else %1 * %0(%1 - 1)         else x * Function.self(x - 1) }     
\end{lstlisting}
Note that \code{Function.self} in the last example refers to the anonymous function itself. 





\subsubsection{Method Values \& Partial Applications}
\label{sec:method-values}

\syntax\begin{lstlisting}
Method_Expr       ::= '&' Simple_Expr2
                    | '&(' Simple_Expr3 ')'
                    | '&(' op_id ')' [Papply_Poetry1 | Papply_Parens1]
                    | '&(' nary_op_id ')' [Papply_Poetry1 | Papply_Parens1]
Simple_Expr2      ::= (Simple_Expr1 - Poetry_Args) [Papply_Parens]
Simple_Expr3      ::= (Simple_Expr1 - Poetry_Args) 
                      [Papply_Poetry | Papply_Parens]
Papply_Parens     ::= Papply_Parens1 [Block_Arg | '&_' ['as' Type]]
                    | Block_Arg 
                    | '&_' ['as' Type]
Papply_Parens1    ::= {'(' [Papply_Args_Expr] ')'}+ 
Papply_Poetry     ::= Papply_Poetry1 
                      [Block_Expr2 | ',' '&_' ['as' Type]]
Papply_Poetry1    ::= Papply_Args_Expr
Papply_Args_Expr  ::= (Papply_Pos_Args [',' Papply_Named_Args])
                    | Papply_Named_Args
Papply_Pos_Args   ::= Papply_Pos_Arg {',' Papply_Pos_Arg}
Papply_Pos_Arg    ::= Pos_Arg | '_' ['as' Type]
Papply_Named_Args ::= Papply_Named_Arg {',' Papply_Named_Arg}
                      {',' '**' Expr}
                    | '**' Expr {',' '**' Expr}
Papply_Named_Arg  ::= Named_Arg
                    | ['~'] id ':' '_' ['as' Type]
\end{lstlisting}

The expression ~\lstinline!&$e$!~ (or alternatively ~\lstinline!&($e$)!) is well-formed if $e$ is of method type or if $e$ is a call-by-name parameter. If $e$ is a method with parameters, ~\lstinline!&$e$!~ represents $e$ converted to a function type by eta expansion (\sref{sec:eta-expansion}). If $e$ is a parameterless method or call-by-name parameter of type ~\lstinline!=> $T$!, ~\lstinline!&$e$!~ represents the function of type ~\lstinline!() -> $T$!, which evaluates $e$ when it is applied to the empty parameter list ~\lstinline!()!. 

\example The method values in the left column are each equivalent to the anonymous functions (\sref{sec:anonymous-functions}) on their right. 
\begin{lstlisting}[deletekeywords={range}]
&(Math.sin)             x -> { Math.sin(x) }
&(Array.range)          (x1, x2) -> { Array.range(x1, x2) }
&(List.map_2)           (x1, x2) -> x3 -> { List.map_2(x1, x2)(x3) }
&(List.map_2(xs, ys))   x -> { List.map_2(xs, xy)(x) }
&(42.`*`)               x -> { 42 * x }
val vs := 1 .. 9; &(vs.fold)
                        x1 -> x2 -> { vs.fold(x1)(x2) }
&((1 .. 9).fold(z))     { val eta1 := z 
                          val eta2 := (1 .. 9)
                          x -> eta2.fold(eta1)(x) }
&(Some(1).fold(`???`))  { val eta1 := () -> { `???` }
                          val eta2 := Some(1)
                          x -> { eta2.fold(eta1())(x) } }
\end{lstlisting}

Note that if $e$ resolves to a parameterless method of type ~\lstinline!() -> $T$!~ or if $e$ has a method type ~\lstinline!() $\mapsto\ T$!, it is evaluated to type $T$ (\sref{sec:method-conversions}) -- and the method value syntax provides a way to prevent this. 

If $e$ resolves to an overloaded member, then the type of the expression is a type projection to that member, constrained to the matching alternatives. 

If $e$ contains sub-expressions of the forms ``\lstinline!_!'' or ``\lstinline!_ as $T$!'', called {\em argument placeholders}, then the method value contains only those overloaded alternatives that are applicable to the given sub-expressions, including the argument placeholders. Such an expression is then partially applied and resolves to an anonymous function, where the argument placeholders become parameters of the anonymous function. 

\paragraph{Joined parameters}

A partial application generates an anonymous function, in which all skipped parameters are joined into a single fresh parameter list, containing all the skipped parameters, with preserved order and typing. Such an anonymous function may again be a subject to further partial application, if so desired.\footnote{A proper IDE should show all the possible fresh parameter lists per each overloaded alternative.} 

Parameters appearing in parameter lists that were not provided any arguments are not considered skipped, and due to the behaviour of automatic currying, are only a regular part of the result value of the anonymous function. 

Parameters that are optional, variadic, or purely named with default values, are never considered as skipped, and thus do not make it into the fresh new parameter list. 

\paragraph{Implicit partial application}

A function application (\sref{sec:function-applications}) using poetry-style argument passing is implicitly partially applied per each argument given. 

The runtime is allowed to optimize such serial partial applications to fit as many arguments given as possible into a single argument list of any overloaded alternative. If the following conditions are all met, then the partial application is also fully applied:
\begin{enumerate}
  \item Function application has all arguments needed for a single overloaded alternative, so that it can be applied to the arguments. 
  \item An implicit parameter list can be provided automatically with arguments, if any is present in the alternative. This is different from regular function applications, in the sense that regular function application signals an error if the implicit arguments can't be assembled. 
  \item The result type is compatible to the expected type. If the expected type is \code{Gear/Language.Auto}, then it is always compatible. 
  \item It is not in a method value, which prevents full application not just in case of implicit partial applications.
\end{enumerate}

This rule practically means that methods with more parameters in a single parameter list are preferred to methods with fewer parameters in a single parameter list, when it comes to poetry-style argument passing. However, it is possible to split poetry-style argument passing with parentheses, to delimit separate applications in consecutive function applications. 

If poetry-style arguments include {\em named arguments}, and any overloaded alternative or non-overloaded member has the same external parameter name across multiple parameter lists, then their order of appearance in those parameter lists is preserved in the order of named arguments. Moreover, it is possible to create a partial application that skips not just parameters, but even whole parameter lists, and the order and typing of missing arguments is preserved in parameters of the generated anonymous function. 

% TBD: write a GFR that shows examples of this in further details

\example Basic examples of implicit partial applications using poetry-style arguments passing. 
\begin{lstlisting}
def papplied (a, b, c): Number := a + b + c

(* resolves to partially applied `papplied`, 
   `a` reified to `1` *)
let papplied_1 (b, c) := papplied 1

(* resolves to partially applied `papplied_1`, 
   `b` reified to `2` *)
let papplied_2 (c) := papplied_1 2

(* finally applies `papplied`, 
   resolves to evaluated `1 + 2 + 3` *)
let fully_applied := papplied_2 3

(* resolves to partially applied `papplied`, 
   `a` reified to `1` and `b` reified to `2` *)
let papplied_3 (c) := papplied 1, 2
\end{lstlisting}

\example Examples of implicit partial applications in face of overloaded members. 
\begin{lstlisting}
def papplied (a, b, c): Number := a + b + c
def papplied (a): Number := a + 3

(* resolves to partially applied `papplied`, 
   `a` reified to `1` *)
let papplied_1 (b, c) := papplied 1

(* resolves to partially applied `papplied`, 
   `a` reified to `1` *)
let papplied_2 () := papplied 1
(* full application *)
let papplied_full := papplied_2() 

(* finally applies `papplied`, 
   resolves to evaluated `1 + 3` *)
let papplied_3 := papplied 1

(* finally applies `papplied`, 
   resolves to evaluated `1 + 2 + 3` *)
let papplied_4 := papplied 1, 2, 3
\end{lstlisting}

\example Example of skipping parameters and parameter lists. 
\begin{lstlisting}
def papplied (a, b)(c): Number := a + b + c

(* resolves to partially applied `papplied`, 
   skipping first parameter list *)
let papplied_1 (a, b) := papplied ~c: 3

(* resolves to partially applied `papplied`, 
   skipping `a` in its first parameter list *)
let papplied_2 (a)(c) := papplied ~b: 2
\end{lstlisting}






\subsection{Anonymous Classes}
\label{sec:anonymous-classes}

\syntax\begin{lstlisting}
Anon_Class      ::= ['class' [Class_Param_Clauses] 'extends'] 
                    [Early_Defs] Anon_Class_Tmpl
Anon_Class_Tmpl ::= Class_Parents 'with' '{' [Template_Body] '}'
\end{lstlisting}

Anonymous classs are a mechanism to implement an abstract class or override a concrete class ``ad hoc'', in place where needed, without needing to create a new constant (although as an expression, the anonymous class definition can indeed be assigned to a constant and gain its name). Anonymous classes can't be type constructors (\sref{sec:type-constructors}). 

A minimal anonymous class expression is of the form ~\lstinline!$c$ with { $t$ }!, where $c$ is the class that the anonymous class inherits from (can be even \code{Object}), and $t$ is the template of the anonymous class. The anonymous class inherits all traits mixed into this parent class, and can itself include or prepend more traits (via the \code{Class_Parents} syntax element). 

Optionally, the anonymous class may define its own primary constructor parameters, in which case the form of the anonymous class is ~\lstinline!class ($\ps_1$)$\ldots$($\ps_n$) extends $c$ with { $t$ }!, where $\ps_1$ to $\ps_n$ are the primary constructor parameters. Superclass constructor arguments may be specified in any case. 






\section{Application Expressions}







\subsection{Designator Expressions}
\label{sec:designators}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Path
               | '(' Anon_Class ')' '.' Selection
               | Value_Expr '.' Selection
Selection    ::= ['?'] (id | digit {digit})
\end{lstlisting}

A designator refers to a named term. It can be a {\em simple name} or a {\em selection}.

A simple name $x$ refers to a value as specified in (\sref{sec:identifiers-names-scopes}). If $x$ is bound by a definition or a declaration in an enclosing class or object $C$, it is taken to be equivalent (at the resolution time) to the selection ~\lstinline!$C$.self.$x$!, where $C$ is taken to refer to the class or object containing $x$, even if the type name $C$ is shadowed at the occurrence of $x$. 

If $r$ is a stable identifier (\sref{sec:type-paths}) of type $T$, the selection ~\lstinline!$r$.$x$!~ refers to a member $m$ of $r$ that is identified in $T$ by the name $x$. 

For other expressions $e$, ~\lstinline!$e$.$x$!~ is typed as if it was ~\lstinline!{ val $y$ := $e$; $y$.$x$ }!, for some fresh name $y$. 

The selection ~\lstinline!$e$.?$x$!~ is typed as if it was 
\begin{lstlisting}
{ val $y$ := $e$; if Nothing !=== $y$ then $y$.$x$ else nil }
\end{lstlisting}
for some fresh name $y$; also called {\em safe navigation} or {\em safe selection}; \code{!===} is the negated result of \code{===} used in (\sref{sec:case-exprs}).

The expected type of a designator's prefix is undefined. The type of a designator is the type $T$ of the entity it refers to. 

The selection ~\lstinline!$e$.$x$!~ is evaluated by first evaluating the qualifier expression $e$, which yields an object $r$. The selection's result is then the member $m$ of $r$ that is either defined by $m$ or defined by a definition overriding $m$. 

A selection ~\lstinline!$e$.$x$!, where $x$ is formed by decimal digits, is useful for selecting members whose name is a decimal number. Tuple types have such members, and other types may define such members by enclosing their names in backticks, e.g. ~\lstinline!def `1` () := 1!. The expression $e$ must not be a number literal. 





\subsection{Attribute Selection Expressions}
\label{sec:attribute-selection}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Simple_Expr ''' Selection
\end{lstlisting}

An attribute is a special function that has at least one parameter list with a single parameter, and optionally more regular parameter lists following the first one. 

An attribute selection ~\lstinline!$x$'$a$!~ is then viewed as function application ~\lstinline!$a$($x$)!. An attribute selection ~\lstinline!$x$'$a$($\args$)!~ is then viewed as function application ~\lstinline!$a$($x$)($\args$)!~ etc. (\sref{sec:function-applications}).





\subsection{Self, This, Super, Outer \& Module}
\label{sec:self-this-super}

\syntax\begin{lstlisting}
Simple_Expr1 ::= [id '.'] 'self' ['[' ('cloned' | 'origin') ']']
                 ['.' Selection]
               | [id '.'] 'this' ['[' ('cloned' | 'origin') ']']
                 '.' Selection
               | [id '.'] 'super' ['[' ('cloned' | 'origin') ']']
                 [Class_Qualifier] 
                 ['.' Selection]
               | 'outer' Class_Qualifier 
                 ['.' 'super' [Class_Qualifier]] 
                 ['.' Selection]
               | 'outer' Class_Qualifier
                 '.' 'this' '.' Selection
               | 'module' [Class_Qualifier] '.' Selection
\end{lstlisting}

The expression \code{self} stands always for the current instance in the context (and in function resolution searches in the actual class of the instance) in the innermost template containing the reference (thus excluding blocks and anonymous functions). 

The expression \code{this} is the same as \code{self}, except that function resolution searches from the class that this expression appears in, possibly skipping overrides in subtypes of the actual class of \code{self}, and continues as usual up the inheritance chain. The \code{this} expression is interchangeable with \code{self} in the following paragraphs, although use of \code{self} is preferred. 

The expression ~\lstinline!$C$.self!~ refers to the current instance in the context of the enclosing (or even directly enclosing) type $C$. It is an error if $C$ is not an enclosing type. The type of the expression is the same as ~\lstinline!$C$.self.type!. 

A reference ~\lstinline!super.$m$!~ refers to a method or type $m$ in the least proper supertype of the innermost template containing the reference. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

A reference ~\lstinline!$C$.super.$m$!~ refers to a method or type $m$ in the least proper supertype of the innermost class or object definition named $C$, which encloses the reference. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

The \code{super} prefix may be followed by a qualifier ~\lstinline![$T$]!, as in ~\lstinline!$C$.super[$T$].$m$!. In this case, the reference is to the type or method $m$ in the parent class or trait of $C$, whose simple name is $T$. It evaluates to the member $m'$ in the actual supertype of that template, which is equal to $m$ or which overrides $m$. If $m$ refers to a method, then the method must be either concrete, or the template containing the reference must have a member $m'$, which overrides $m$ and which is labeled \code{abstract override}. 

The expression ~\lstinline!outer[$T$]!~ refers to the current instance in the context of enclosing (or even directly enclosing) type $T$. It is an error if $T$ is not an enclosing type. The type of the expression is the same as ~\lstinline!outer[$T$].type!. 

Class qualifier may be a simple name referring to name of an enclosing type or supertype (depending on the preceding keyword: \code{outer} or \code{super}), or---if there is no type of such name or the qualifier is not a simple name---a stable id referring to the enclosing type or supertype. The latter case is useful in cases when there are multiple enclosing types or supertypes of the same simple name. Class qualifiers are evaluated at compile time, but, when the slow path of stable id is taken, it may refer to a lazily imported type name. It is obviously an error if the slow path is taken, no name is found during compilation and there are no lazy imports in the scope, or no name is found using the lazy import. 





\subsection{Use Expressions}
\label{sec:use-expressions}

\syntax\begin{lstlisting}
Use_Expr       ::= Use_Expr_As 
                 | Use_Aspect
                 | Use_Refinement
Use_Expr_As    ::= 'use' Simple_Expr ('as' | 'as!' | 'as?')
                   [id ':'] Type [Block_Expr]
Use_Aspect     ::= 'use' 'aspect' Stable_Id [Block_Expr]
Use_Refinement ::= 'use' 'refinement' Stable_Id [Block_Expr]
\end{lstlisting}

Use expressions of the form ~\lstinline!use $e$ as $a$: $T$!~ are similar to typed expressions (\sref{sec:typed-expressions}). Their intention is to rebind an expression to a specific type (changing its expected type), and then either have this type to be effective in the same scope from that point onward, or, if a \code{Block_Expr} is syntactically given, only in the scope of that block expression. If a block is given, then the return value of the block is the value of this expression, otherwise, the value retrieved by evaluation of \code{Simple_Expr} is the value of this expression. Conversions described in typed expressions (\sref{sec:typed-expressions}) apply in these expressions as well, including the differences between \code{as} and ~\lstinline@as!@. 

Use expressions of the form ~\lstinline!use aspect $T$!~ enable the specified aspect, either in the scope defined by the given block, or if no block is given, then from that point onward, up to the scope end. If the expression is used as a template statement, then the aspect is enabled for the whole template anywhere, unless it has the block part. 

Use expressions of the form ~\lstinline!use refinement $T$!~ enable the specified refinement, either in the scope defined by the given block, or if no block is given, then from that point onward, up to the scope end. If the expression is used as a template statement, then the refinement is enabled for the whole template anywhere, unless it has the block part. 








\subsection{Function Applications}
\label{sec:function-applications}

\syntax\begin{lstlisting}[mathescape=false]
Simple_Expr1   ::= (Simple_Expr1 - Poetry_Args) Argument_Exprs 
Argument_Exprs ::= ['.'] Parens_Args {Parens_Args} [Block_Arg] 
                 | Poetry_Args [Block_Expr2]
                 | Block_Arg

Parens_Args ::= '(' [Args_Expr] ')'
Poetry_Args ::= Args_Expr
Args_Expr   ::= (Pos_Args [',' Named_Args])
              | Named_Args
Pos_Args    ::= Pos_Arg {',' Pos_Arg}
Pos_Arg     ::= ['*'] Expr 
              | '$' 
              | TT_Expr
              | Slice_Expr
Named_Args  ::= Named_Arg {',' Named_Arg} {',' '**' Expr}
              | '**' Expr {',' '**' Expr}
Named_Arg   ::= ['~'] id ':' (Expr | TT_Expr | Slice_Expr)
              | ['~'] id ':' '$'
              | '~' id
Block_Arg   ::= Block_Expr 
              | Method_Expr
\end{lstlisting}

% TODO: describe last block arg
% TODO: describe arg prefixed with a dot (e.g. .Red)

A function application ~\lstinline!$f$($e_1 \commadots e_m$) $b$!~ applies the function $f$ to the argument expressions $e_1 \commadots e_m$ and passes the block expression $b$ (\sref{sec:blocks}) into it. If $f$ has a method type ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$) $\mapsto\ U$!, the type of each argument expression $e_i$ is typed with the corresponding parameter type $T_i$ (\sref{sec:corresponding-parameters}) as expected type. Let $S_i$ be type of argument $e_i$ (for $i = 1 \commadots m$). If $f$ is a polymorphic method, local type inference (\sref{sec:local-type-inference}) is used to determine type arguments for $f$. If $f$ is of a value type, the application is taken to be equivalent to ~\lstinline!$f$.apply($e_1 \commadots e_m$)!, i.e. the application of an \code{apply} method defined by $f$. 

If none of $e_i$ is purely a named argument, and $f$ accepts a single parameter of \code{Any}, \code{Object} or \code{Tuple_$n$} type (where $n = m$), then the function application is taken as ~\lstinline!$f$(($e_1 \commadots e_m$))!. With respect to overloading resolution (\sref{sec:overloading-resolution}), a member that requires argument expressions to tuple conversion is always less specific than a member that does not require such conversion. 

\paragraph{Distinctions}
Function applications using the \code{Poetry_Args} syntactic category are automatically partially applied, see (\sref{sec:method-values}).

\paragraph{Note}
Target type expression (\sref{sec:target-type-expressions}) can't be the first argument in a function application that uses poetry-style arguments passing, due to resulting ambiguity between an argument expression and a chained function application or selection.





\subsubsection{Argument Evaluation Strategies}
\label{sec:arg-eval-strategies}

Gear defers evaluation of arguments up to the point of function application, and happens then as specified in parameter evaluation strategies (\sref{sec:param-eval-strategies}). The type that each argument is type-checked against the corresponding parameter type (defined as follows) is the expected type of the argument expression, i.e. not its actual concrete type, which is known only after its evaluation. If the expected type is undefined, then \code{Any} is assumed. Typed expressions (\sref{sec:typed-expressions}) may be used to give the argument expression a concrete expected type. When the argument expression is evaluated, it is evaluated as if it were in the scope of the function application (which it is), so that visibility rules from that scope apply. 






\subsubsection{Corresponding Parameters}
\label{sec:corresponding-parameters}

The argument expressions $a_1 \commadots a_n$ are said to be corresponding to parameters $p_1 \commadots p_n$ based on the following mapping definition. 

\begin{enumerate}
  \item Argument unpacking is applied. 
    \begin{enumerate}
      \item {\em Sequence arguments} are prefixed with an asterisk ``\code{*}'', and are evaluated to a \code{Sequence[_]}-compatible type. The values are unpacked and injected in place of the sequence argument in order defined by the sequence. This triggers early evaluation of the argument, which is only done once in face of overloading resolution and/or the following function application. Sequence arguments may only appear among positional arguments. 
      \item {\em Mapping arguments} are prefixed with a double asterisk ``\code{**}'', and are evaluated to a \code{Sequence[(Symbol, _)]}-compatible type; \code{Map[Symbol, _]} is one such an acceptable type which does not require further conversion to a sequence. The key and value pairs (tuples) are unpacked from the sequence and appended to the sequence of other named arguments. 
    \end{enumerate}
    
  \item Condition check: if there are named arguments, each argument name must be unique per argument list. It is an error if there are duplicate argument names, either before or after argument unpacking.
    
  \item Positional arguments are mapped to their corresponding parameters, as defined by positional parameters (\sref{sec:positional-parameters}). Positional parameters will never map to purely named parameters. 
  
  \item Condition check: after the previous step, if there are any other unassigned arguments, the remaining arguments must be named, and optionally followed by a block argument. 
  
  \item The remaining named arguments are mapped based on their name to parameters of the same external name (\sref{sec:external-internal-parameter-names}). If the corresponding parameter is a variadic parameter, then rules for the parameter apply (\sref{sec:variadic-parameters}). Named arguments are never corresponding to positional parameters without an external name (\sref{sec:external-internal-parameter-names}). 
  
  \item If there are any extra named arguments, and a capturing named parameter is present, those extra named arguments are mapped to it. 
  
  \item If there is a {\em block argument} passed as positional and appearing last in the argument list, it is mapped to the captured block parameter, if that is present, and if not, then the argument is available for use with the \code{yield} keyword (\sref{sec:yield-expressions}). It not an error if the function member does not use \code{yield}, but that should be avoided. A block argument is either a block expression, or an argument prefixed with an ampersand ``\lstinline!&!''. In a consecutive function application, there may be only one block argument per each argument list as allowed by syntax, unlike with captured block parameter. 
  
  \item If there are any parameters without an assigned argument, those parameters must have a default value, which is evaluated prior to the function application (provided that the function was selected as unique in overloading resolution, if any). It is an error if there are any parameters left without a corresponding argument or default value. It is not an error if a variadic parameter is left with an empty sequence, as it is not an error if a capturing named parameter contains an empty mapping. 
  
\end{enumerate}

The type of each argument expression $a_i$ is typed with the corresponding parameter type $T_j$ as expected type, where the mapping from $i$ to $j$ is defined by corresponding parameters and is correct. 






\subsubsection{Applicable Function}

The function $f$ must be applicable to its arguments $a_1 \commadots a_n$ of types $S_1 \commadots S_n$. 

If $f$ has a method type ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$)$R$!, the function $f$ is applicable if all of the following conditions hold:
\begin{itemize}

  \item A mapping defined by corresponding parameters exists and is correct. 

  \item For every named argument ~\lstinline!$x_i$: $a'_i$!, the type $S_i$ is compatible (\sref{sec:implicit-conversions}) with the parameter type $T_j$, whose name $p_j$ matches $x_i$, or if $f$ defines a capturing named parameter and $x_i$ does not match name of any $p_j$, then the type $S_i$ is compatible with the parameter type $T_j$, whose name $p_j$ matches the name of the capturing named parameter.

  \item For every positional argument $a_i$, the type $S_i$ is compatible (\sref{sec:implicit-conversions}) with its corresponding $T_i$. 

  \item The given block or the last argument prefixed with ``\lstinline!&!'' is of a type compatible (\sref{sec:implicit-conversions}) with the type of the captured block parameter, if such parameter is defined. 

  \item If the expected type of the function application is defined, the result type $R$ is compatible (\sref{sec:implicit-conversions}) to it. 

  \item Every formal parameter $p_j$: $T_j$ which is not specified by either a positional or a named argument has a default value (\sref{sec:optional-parameters} \& \sref{sec:named-parameters}). 
  
\end{itemize}

If $f$ is a polymorphic method, it is applicable if local type inference (\sref{sec:local-type-inference}) can determine type arguments, so that the instantiated method is applicable. If $f$ is of a value type, it is applicable if it has a method member named \code{apply}, which is applicable. Note that if explicit type parameters are given to the polymorphic method, type application (\sref{sec:type-applications}) happens prior to function application. 

If a function application appears to be an argument to another function application (let's call it a nested function application), the expected type of the nested function application is used to determine, whether the outer function is applicable, but the nested function application is not evaluated until time specified by argument evaluation strategy (\sref{sec:arg-eval-strategies}) corresponding to the argument. Local type inference may indeed occur for the nested function application, if it involves a polymorphic method, but again, only using the available expected types. 

If a corresponding parameter $p_j$ to an argument expression $e_i$ is of a constrained type (\sref{sec:constrained-types}), the argument expression is early evaluated, so that it can be determined whether the argument's type conforms to the constrained type, but only if the expected type of $e_i$ does conform to the type of $p_j$ (otherwise, it is clear that it won't conform, thus there is no need to evaluate the expression). 

\example Assume the following function, which computes the sum of variable number of arguments:
\begin{lstlisting}
def sum (*xs: Integer) := (0 /: xs) ((x, y) -> { x + y })
\end{lstlisting}
Then 
\begin{lstlisting}
sum 1, 2, 3, 4
sum (1, 2, 3, 4)
sum *%[1; 2; 3; 4]
sum (*%[1; 2; 3; 4])
sum 1, 2, *%[3; 4]
sum (1, 2, *%[3; 4])
sum 1, *%[2; 3], 4
sum (1, *%[2; 3], 4)
\end{lstlisting}
all yield $10$ as result. On the other hand,
\begin{lstlisting}
sum %[1; 2; 3; 4]
\end{lstlisting}
would not be applicable. Moreover, (note the extra space before the sequence-splat operator),
\begin{lstlisting}
sum * %[1; 2; 3; 4]
\end{lstlisting}
would be interpreted as 
\begin{lstlisting}
sum.`*`(%[1; 2; 3; 4])
\end{lstlisting}
which is an infix expression rather than a function application. On the other hand, a space may appear between the function name and the arguments list.





\subsubsection{Tail-call optimization}

A function application usually allocates a new stack frame on the program's runtime stack for the current thread. However, if at least one of the following conditions holds and function calls itself as its last action, the application is executed using the stack frame of the caller, replacing arguments and rewinding stack pointer to the first instruction, called {\em tail-call optimization}:
\begin{itemize}
\item The function is local and not overloaded. 
\item The function is \code{final}. 
\item The function is \code{private} or ~\lstinline!private[self]!. 
\item The function is annotated so that tail-call optimization is explicitly allowed. 
\item A pragma allowing tail-call optimizations is effective in the scope of the tail call. 
\end{itemize}
The optimization will not happen if the application results in a different (possibly overloaded or overridden) variant of the caller function being applied, and a warning is issued if the tail-call optimization was explicitly expected (either via an annotation or a pragma). 





\subsubsection{Named \& Optional Arguments}
\label{sec:named-optional-arguments}

If an application uses named arguments ~\lstinline!$p_i$: $e_i$!~ or default arguments, the following conditions must hold:
\begin{itemize}
\item No named argument appears left of a positional argument in the argument list. 
\item No positional argument appears right of a named argument. A bit of an exception is the captured block argument, which appears to be positional, but is treated specially. 
\item The names $p_i$ of all named arguments are pairwise distinct per argument list.
\item Every formal parameter ~\lstinline!$p_j$: $T_j$!, which is not specified by a positional argument, has a default argument. 
\item Every formal parameter ~\lstinline!~$p_j$: $T_j$!, which is not specified by a named argument, has a default argument. 
\item If there are more named arguments than named parameters (excluding the capturing named parameter), a capturing named parameter is defined. (If it is not, the function is not applicable.)
\end{itemize}

No transformation is applied to convert a function application into an application without named or default arguments -- the runtime handles the application itself. 






\subsubsection{By-Name, By-Need \& By-Future Arguments}
\label{sec:by-name-arguments}
\label{sec:by-need-arguments}
\label{sec:by-future-arguments}

None of these argument types require any syntactically special treatment. The user of a function that uses these types should however consider the implications of their types on their evaluation. 





\subsubsection{Curried Functions \& Partial Applications}
\label{sec:curried-functions}
\label{sec:partial-applications}

A curried function can appear in two distinct forms:
\begin{itemize}
  \item[] {\em Implicitly curried form}, which is defined by using multiple parameters lists. 
  \item[] {\em Explicitly curried form}, which is defined by using function types as result types of functions, or simply by returning a function from within a function. Those have no special treatment, e.g. in regard of overloading resolution. 
\end{itemize}

Each form has some implications on function applications. 

Let's define {\em consecutive function applications}. Such function applications are a continuous sequence of function applications, where each following function application is directly applied to the result of the previous function application, without storing the intermediate values anyhow. 

\example The following are examples of consecutive function applications:
\begin{lstlisting}
f(a, b)(c, d)
f(a, b).apply(c, d)
f(a, b).(c, d) (* short form of the previous *)
\end{lstlisting}
The following are not consecutive function applications:
\begin{lstlisting}
val e := f(a, b)
e(c, d)
\end{lstlisting}

An implicitly curried function requires a consecutive function application for all of its parameters lists, excluding the implicit parameters list. If the implicitly curried function is intended to be {\em partially applied} (not providing all the parameters lists with arguments lists), then a method value (\sref{sec:method-values}) can be used. This also applies to the implicit parameters list -- if providing it is to be deferred, a method value that encloses arguments lists up to the implicit parameters list can be used, but then the implicit arguments list has to be provided later in order to evaluate the curried function. 

On the other hand, explicitly curried functions do not care about consecutive function applications. 

The consecutive function applications meta-construct is also a solution to providing explicitly the implicit parameters list an arguments list. Without it, the function application would handle the implicits from it and the consecutive application would be applied to the result of the whole function. Therefore, if a consecutive function application is present, the evaluation of implicit parameters list is deferred to this consecutive function application, so that arguments for it can be specified. If there is no consecutive function application, then the implicit parameters list is evaluated as usual. 





\subsubsection{Function Compositions \& Pipelines}
\label{sec:function-compositions}
\label{sec:function-pipelines}

These expressions are not in fact syntax features, but rather an implementation on functions and their traits. 

A {\em function composition} is a way to compose two functions and return a function. A {\em function pipeline} is a way to pass a value to a function and return a value, which can be again passed to another function in a pipeline. 

Function composition is usually defined by operators such as ``\lstinline!|>>!'' for unary functions, ``\lstinline!||>>!'' for binary functions and so on, and ``\lstinline!<<|!'' for unary functions, ``\lstinline!<<||!'' for binary functions, in reverse order. 

Function pipeline is usually defined by operators such as ``\lstinline!|>!'' for unary functions, ``\lstinline!||>!'' for binary functions and so on, and ``\lstinline!<|!'' for unary functions, ``\lstinline!<||!'' for binary functions, in reverse order. 

These operators for unary functions can be defined as follows, e.g.:
\begin{lstlisting}
trait Function_1 [-T, +R]
begin

  (* right-binding *)
  operator |>> [T1] (g: T1 -> T): T1 -> R := 
    (a: T1) -> { self(g(a)) }

  (* left-binding *)
  operator <<| [T1] (g: T1 -> T): T1 -> R :=
    (a: T1) -> { self(g(a)) }

  (* right-binding *)
  operator |> (a: T): R :=
    self(a)

  (* left-binding *)
  operator <| (a: T): R := 
    self(a)
    
end trait
\end{lstlisting}

Function composition and pipelining makes more sense with the use of positional parameters rather than with named parameters, although with some more verbose syntax, it can be achieved as well, e.g. by assuming that the composed functions or pipelines share the same names of their named parameters. 





\subsubsection{Memoization}
\label{sec:memoization}

How to memoize a function's result is described in (\sref{sec:return-expressions}).

A memoized function's body is not evaluated, if it was once called with the same arguments (based on equality, not identity), and if that result value is still memoized. If so, the memoized result value is immediately returned without evaluation of the function's body, which can speed up execution of some functions significantly. Such functions should however be referentially transparent in best-case scenario (\sref{sec:function-decls-defs} \& \sref{sec:statements}) or at least tolerant to being memoized. 

Memoization is better with small parameter numbers, so that searching the result values cache would not actually take longer than evaluation of the function's body. Functions that are defined with the \code{function} keyword (\sref{sec:function-decls-defs}) may opt-in to implicit memoization\footnote{E.g., based on the computed complexity of the function. If the function is decided to be simple, then memoization could actually worsen performance.}, as well as functions declared as \code{transparent} (\sref{sec:statements}). Functions declared as \code{opaque} (\sref{sec:statements}) should not be memoized. 

Parameters of memoization\footnote{Parameters include things like: cache policy, ttl, cache size and so on.} may be controlled, even on per-function basis, with use of specialized annotations and pragmas. 




\subsubsection{Application Shortcut}
\label{sec:function-application-shortcut}

A function application ~\lstinline!$f$.($e_1 \commadots e_m$) $b$!~ is a syntax sugar for a function application ~\lstinline!($f$())($e_1 \commadots e_m$) $b$!, which in turn is a shortcut for function application ~\lstinline!$f$().apply($e_1 \commadots e_m$) $b$!, as appropriate.\footnote{E.g. curried functions do not need any explicit \code{.apply()} applications, as these are implied, but would work anyway, therefore the second expanded form is equivalent to the first expanded form.}

This is especially useful for situations where a prefix appears to the function application and $f$ denotes a member that evaluates to a function, or maybe to a collection, but does not itself accept any arguments. 

A function application ~\lstinline!$p$.$f$.($e_1 \commadots e_m$) $b$!~ is a syntax sugar for a function application ~\lstinline!($p$.$f$)($e_1 \commadots e_m$) $b$!, which in turn is a shortcut for function application ~\lstinline!$p$.$f$().apply($e_1 \commadots e_m$) $b$!, where $p$ is some prefix expression. 





\subsubsection{Receiver Universal Shortcut}
\label{sec:receiver-universal-shortcut}

A function application ~\lstinline!$r$.$f$($e_1 \commadots e_m$)!, where at least one of $e_i$ is literally ~\lstinline[mathescape=false]!$!~ or contains it as a sub-expression, is a syntax sugar for function application, where each ~\lstinline[mathescape=false]!$!~ is replaced with ~\lstinline[mathescape=false]!r.`$`()!. 

A function application ~\lstinline!$r$($e_1 \commadots e_m$)!, where at least one of $e_i$ is literally ~\lstinline[mathescape=false]!$!, is a syntax sugar for function application, where each ~\lstinline[mathescape=false]!$!~ is replaced with ~\lstinline[mathescape=false]!r.`$`()!~ and \code{r} is a variable reference. 

In case of nested function applications, this shortcut is applied absolutely only to the outermost application, to prevent any confusion. It can be combined with application shortcut.

\example Combining receiver universal shortcut with application shortcut.
\begin{lstlisting}[mathescape=false]
(* the expression *)
prefix.receiver.($)
(* is equivalent to the expression *)
prefix.receiver.(prefix.receiver.`$`())
(* which is in turn equivalent to *)
prefix.receiver().apply(prefix.receiver().`$`())
\end{lstlisting}

\paragraph{Note}
The receiver universal shortcut is defined for Gear's collection types as an alias to \code{size} -- to be used in slicing, primarily.
% TBD: decide whether more shortcuts should be allowed, numbered e.g., probably not 





\subsection{Type Applications}
\label{sec:type-applications}

\syntax\begin{lstlisting}
Simple_Expr1 ::= Simple_Expr Type_Args
\end{lstlisting}

A type application ~\lstinline!$e$[$T_1 \commadots T_n$]!~ instantiates a polymorphic value $e$ of type ~\lstinline![$a_1$ >: $L_1$ <: $U_1$ $\commadots$ $a_n$ >: $L_n$ <: $U_n$] $\mapsto\ S$!~ with argument types $T_1 \commadots T_n$. Every argument type $T_i$ must obey the corresponding bounds $L_i$ and $U_i$. That is, for each $i = 1 \commadots n$, we must have $\sigma L_i <: T_i <: \sigma U_i$, where $\sigma$ is the substitution $[a_1 := T_1 \commadots a_n := T_n]$. The type of the application is $\sigma S$. 

If the function part $e$ is of some value type, the type application is taken to be equivalent to ~\lstinline!$e$.apply[$T_1 \commadots T_n$]!, i.e. the application of an \code{apply} method defined by $e$. 

Type applications can be omitted if local type inference (\sref{sec:local-type-inference}) can infer best type arguments for a polymorphic function from the types of the actual function arguments and the expected result type. If any of the type arguments is specified as an underscore ``\code{_}'', it is locally inferred, therefore allowing for partial type application, where the provided type arguments are taken as constant types. 





\subsection{Instance Creation Expressions}
\label{sec:instance-creation-exprs}

\syntax\begin{lstlisting}
New_Expr ::= 'new' [Early_Defs] Class_Parents 
             ['begin' [Template_Body] 'end']
           | 'new' [Early_Defs] Class_Parents 
             ['{' Template_Body '}']
           | 'new' '{' Template_Body '}'
\end{lstlisting}

Unlike languages like Java, Scala, C\# and similar, Gear does not have dedicated language construct for creating new instances of classes. Instead, all such attempts are made through the ~\lstinline[deletekeywords={new}]!Class#new!~ method (not to be confused with ``static'' ~\lstinline[deletekeywords={new}]@Class.new@, which is for dynamic creation of ad-hoc classes), which passes all the arguments to the appropriate constructor (and is defined using \code{Variadic_Arguments}). 

It is indeed possible to write custom ~\lstinline[deletekeywords={new}]!$T$#new! implementations, where $T$ is the class---or even trait!---for which the custom implementation is, and that implementation may decide to use ~\lstinline[deletekeywords={new}]!Class#new!~ or not (typical use case: a factory method without the usual corporate factory names).

There is one more way to create an instance of a class, and that is to use a syntax construct of the \code{New_Expr} syntax category. This construct has multiple forms for different use cases. Note that there is also a syntax construct for anonymous classes (\sref{sec:anonymous-classes}), which is related, but has slightly different semantics -- most notably, anonymous classes can be reused and bound to a name, because they do not create any new instance (just yet), and can define class parameters, including type parameters. 

A simple instance creation expression is of the form ~\lstinline!new $c$!, where $c$ is a constructor invocation (\sref{sec:constructor-invocations}). Let $T$ be the type of $c$, then $T$ must denote a type instance of a non-abstract subtype of \code{Any}. $T$ must also conform to the {\em self type} of the class denoted by $T$. The expression is evaluated by invoking ~\lstinline[deletekeywords={new}]!Class#new!, where the method is invoked with \code{self} being $T$, thus skipping any custom overrides of the method. Note that $c$ might be an instantiated type variable, in which case it might not be entirely possible to guarantee that the expression will be evaluated successfully -- no matching and accessible constructor might be available in the instantiated type. 

A general instance creation expression is of the form ~\lstinline!new $t$!~ for some class template $t$. Such an expression is equivalent to the following block:
\begin{lstlisting}
{ class $a$ extends $t$; new $a$ }  ,
\end{lstlisting}
where $a$ is a fresh name of an {\em anonymous class} (\sref{sec:anonymous-classes}) bound to the name $a$ within the block (and unbound when the block exits).

A shorthand instance creation expression is of the form ~\lstinline!new { $S$ }!, where ~\lstinline!{ $S$ }! is a class body, which is equivalent to the general instance creation expression ~\lstinline!new Object { $S$ }!. This is for creating structural types, ad-hoc. 

\example Consider the following shorthand instance creation expression:
\begin{lstlisting}
new { def name() := "Dagny Taggart" }
\end{lstlisting}
This is a shorthand for the general instance creation expression
\begin{lstlisting}
new Object { def name() := "Dagny Taggart" }
\end{lstlisting}
Which is in turn a shorthand for the block
\begin{lstlisting}
{ class $a$ extends Object { def name() := "Dagny Taggart" }; new $a$ }
\end{lstlisting}
where $a$ is a freshly created name. 




\subsection{Blocks}
\label{sec:blocks}

\syntax\begin{lstlisting}
Block_Expr      ::= Block_Expr1 | Block_Expr2
Block_Expr1     ::= '{' [Block_Args] Block '}'
Block_Expr2     ::= 'do' [Block_Args] Block ('end' | 'done')
Block_Args      ::= '|' [Params] [Block_Shadowing] '|' 
                    [':' Type [semi]]
Block_Shadowing ::= ';' [nl] [Shad_Val_Dcl {',' Shad_Val_Dcl}]
Shad_Val_Dcl    ::= Val_Dcl | Var_Dcl
Block           ::= {Block_Stat semi} [Result_Expr]
\end{lstlisting}

A block expression ~\lstinline!{ $s_1$; $\ldots$; $s_n$; $e$ }!~ is constructed from a sequence of block statements $s_1 \commadots s_n$ and a final expression $e$. The statement sequence may not contain two definitions or declarations that bind the same name in the same namespace, except for local function definitions, which then create overloaded local function definitions (behaving pretty much like regular overloaded functions). The final expression may be omitted, in which case the unit value ~\lstinline!()!~ is assumed. 

The expected type of the final expression $e$ is the expected type of the block expression. The expected type of all preceding statements is undefined. 

The type of a block ~\lstinline!{ $s_1$; $\ldots$; $s_n$; $e$ }!~ is ~\lstinline!$T$ for-some { $Q$ }!, where $T$ is the type of $e$ and $Q$ contains existential clauses (\sref{sec:existential-types}) for every value or type name which is free in $T$ and which is defined locally in any of the statements $s_1 \commadots s_n$. We say that the existential clause {\em binds} the occurence of the value or type name. Specifically, 
\begin{itemize}

\item A locally defined type definition ~\lstinline!type $t$ := $T$!~ is bound by the existential clause ~\lstinline!type $t$ >: $T$ <: $T$!. It is an error if $t$ carries type parameters. 

\item A locally defined value definition ~\lstinline!val $x$: $T$ := $e$!~ is bound by the existential clause ~\lstinline!val $x$: $T$!. 

\item A locally defined class definition ~\lstinline!class $c$ extends $t$!~ is bound by the existential clause ~\lstinline!type $c$ <: $T$!, where $T$ is the least class type of refinement type which is a proper supertype of the type $c$. It is an error if $c$ carries type parameters. 

\item A locally defined object definition ~\lstinline!object $x$ extends $t$!~ is bound by the existential clause ~\lstinline!val $x$: $T$!, where $T$ is the least class type of refinement type which is a proper supertype of the type ~\lstinline!$x$.type!.
\end{itemize}

Evaluation of the block entails evaluation of its statement sequence, followed by an evaluation of the final expression $e$, which defines the implicit result of the block. 





\subsubsection{Block Expression as Argument}
\label{sec:block-arguments}

A block expression may be used as the very last argument in a function application (\sref{sec:function-applications}), being equivalent to an anonymous function. 

As such, the block parameters section is optional to be defined, and its parameters are, unlike with anonymous functions, tolerant to different shapes of given arguments. If parameters of the block are typed and arguments for the corresponding parameters are given, the types of the arguments must be compatible with the expected parameter types. 

If less arguments are provided, the remaining parameters have default values of their types, and it is an error if such parameter is typed with a non-nullable type. 

If more arguments are provided, the extra arguments are discarded and released. 

An explicit return expression (\sref{sec:return-expressions}) within the block is interconnected with the innermost function that defines the block, i.e. evaluating it returns from the function (as well as from the block expression). This does not apply to anonymous functions (\sref{sec:anonymous-functions}), where the return expression is interconnected with the anonymous function itself. 






\subsubsection{Variable Closure}
\label{sec:variable-closure}

Gear uses variable closure when defining a block expression. 

If a block expression is used just as a statement, it implicitly inherits access to all variables and methods defined in the scope in which it itself is defined. 

Variables are made available via inner hidden instance variables of the implicit function. This includes the \code{self} object of the outer scope, if any methods are to be executed from within the block. Those variables are referenced with a strong reference, and therefore may cause in some situations retain cycles -- this can be solved by using {\em capture lists}, which can override this default behavior and store the reference as either \code{weak}, \code{soft} or \code{unowned} reference, to break the retain cycle.\footnote{Quite useful with lazy definitions of instance variables, where the expression is wrapped in an implicit block.} 

If a block expression is used as an argument in a function application (\sref{sec:function-applications}), it is used as a functor, and is provided with read and write access to variables in the scope that the function application appears in, and with an access to the \code{self} reference, including any nested ~\lstinline!$C$.self!~ references (\sref{sec:self-this-super}). Write access to variables is provided in a manner equivalent to \code{out} arguments. 

Variable closure is applied to anonymous functions (\sref{sec:anonymous-functions}) as well. 

A block expression may opt-in to {\em shadow variables} that it would otherwise have access to from its scope, specified with the \code{Block_Shadowing} syntax element. Variables and methods with the same names as those of the shadowing variables will not be a part of the variable closure. 





\subsection{Yield Expressions}
\label{sec:yield-expressions}

\syntax\begin{lstlisting}
Yield_Expr ::= [id '.'] 'yield' [Parens_Args | Poetry_Args]
\end{lstlisting}

A yield expression ~\lstinline!yield $a_1 \commadots a_n$!~ is an universal \code{yield} operation:
\begin{enumerate}
  \item A way to invoke the block argument (\sref{sec:function-applications} \& \sref{sec:block-arguments}) and pass it arguments. It's expected type is the result type of the given block argument. The value of the expression is then whatever the block argument returned. 
  \item When no block argument was given and the invocation happens inside a fiber that is not the thread's main fiber, a way to return from a fiber without destroying it's stack. The value of the expression is then whatever value is passed to the method that resumes the fiber (so that it continues with that value in place of the \code{yield} expression). 
  \item A part of workflows (\sref{sec:workflows}).
  \item A part of generators (\sref{sec:generator-expressions}) and collection comprehensions (\sref{sec:collection-comprehensions}).
  \item In other cases, it is an error to use \code{yield}. 
\end{enumerate}

A yield expression ~\lstinline!$T$.yield $a_1 \commadots a_n$!~ is a specialized case of the previous definitions of \code{yield}, where $T$ may be one of:
\begin{itemize}
  \item \code{Block}, for invoking block argument. To test if a block argument is available, use \code{Yield.block_available?}, defined in Gear's \code{Language} module. 
  \item \code{Fiber}, for yielding from a fiber. To test if a yield from a fiber is available, use \code{Yield.fiber_available?}, defined in Gear's \code{Language} module. 
\end{itemize}





\subsection{Prefix \& Infix Operations}
\label{sec:prefix-infix-ops}

\syntax\begin{lstlisting}
nary_op_id   ::= '?' {op_char}
Infix_Expr   ::= Prefix_Expr
               | Infix_Expr [Infix_Op Infix_expr]
               | Infix_Expr nary_op_id Infix_Expr {':' Infix_Expr}
               | Range_Expr
Simple_Expr1 ::= '(' op_id ')' Poetry_Args
               | '(' nary_op_id ')' Poetry_Args
Infix_Op     ::= op_id | id
Prefix_Expr  ::= [op_id | 'not'] Simple_Expr1
Range_Expr   ::= Infix_Expr ('..' | '...' | '..<') Infix_Expr
                 [FP_Delta [FP_Digits]]
Slice_Expr   ::= Infix_Expr ('..' | '...' | '..<') [Infix_Expr]
               | ('..' | '...' | '..<') Infix_Expr
\end{lstlisting}

Expressions can be constructed from operands and operators. 





\subsubsection{Prefix Operations}

A prefix operation $\op\ e$ consists of a prefix operator $\op$, which may be any operator identifier, but must not be followed by any whitespace, only identifiers or parentheses (except for the special operator \code{not}, which has to be separated by a space from the expression that it prefixes). The expression $\op\ e$ is equivalent to the method application ~\lstinline!$e$.$\op$()!~ (i.e., prefix operators are right-binding). If such method does not exist, it is equivalent to the function application ~\lstinline!$\op$($e$)!, and if such function does not exist either, implicit conversions on $e$ are attempted. 

There is also a keyword prefix operator: \code{not}, which must be followed by a whitespace and is always prefix.

The precedence of prefix operators is higher than that of infix operators (\sref{sec:infix-operations}). For example, the source input sequence \code{-sin(x)} is read as \code{-(sin(x))}, which is in turn read as \code{sin.apply(x).`-`()}, whereas the function application \code{negate sin(x)} would be parsed as \code{negate(sin(x))}, using poetry-style arguments. To further emphasize the precedence of prefix operators, \code{-a + b} is read as \code{-(a) + b}, and \code{-(a + b)} as just that. 

Prefix operations may alternatively appear in the form $(\op)\ e$, which is equivalent to a function application form, but still searches for implementation of the operator in $e$ first. 





\subsubsection{Postfix Operations}

Apart from standard function applications (\sref{sec:function-applications}) that may be viewed as postfix, Gear does not include support for postfix operations. 





\subsubsection{Infix Operations}
\label{sec:infix-operations}

An infix operator can be an arbitrary identifier, usually an operator identifier. Infix operators have static {\em precedence}, {\em associativity} and {\em binding direction} defined as follows:

Infix operators have to be separated from both sides by whitespace from the expressions that they connect. If the following whitespace is a newline character, then precedence rules can not be followed (due to line-by-line parsing and evaluation) and usual behaviour described in (\sref{sec:newlinecharacters}) is followed. 

Infix operations and $n$-ary operations may alternatively appear in the form $(\op)\ e_1 \commadots e_n$, which is equivalent to a function application with poetry-style arguments passing (unless $e_1$ is a tuple expression with more than 1 elements, then it's regular-style arguments passing). 

The {\em precedence} of an infix operator is determined by the operator's first character. Characters are listed below in increasing order of precedence, with characters on the same line having the same precedence.

\begin{lstlisting}
$\mbox{\rm\sl(all alphanumeric characters)}$
|
&
< > ~
= !
:
$\mbox{\rm\sl(all other special characters)}$
+ -
* / %
^
\end{lstlisting}

That is, operators starting with ``\lstinline!|!'' have the lowest precedence, followed by operators starting with ``\lstinline!^!'', etc. 

There's one exception to this rule, which concerns {\em assignment operators} (\sref{sec:assignment-operations}). The precedence of an assignment operator is the same as the one of simple assignment (\lstinline!:=!). That is, it is lower than the precedence of any other operator. 

A number of left-associative alphanumeric operators with different precedence exist:
\begin{itemize}
  \item \code{and}, with precedence of ~\lstinline!&!. 
  \item \code{or}, with precedence of ~\lstinline!|!.  
  \item \code{xor}, with precedence of ~\lstinline!|!.  
  \item \code{rem}, with precedence of ~\lstinline!%!. 
  \item \code{mod}, with precedence of ~\lstinline!%!. 
  \item \code{div}, with precedence of ~\lstinline!/!. 
  \item \code{quot}, with precedence of ~\lstinline!/!.   
\end{itemize}

The {\em associativity} and {\em binding direction} of an operator is determined by the operator's last character. Operators ending in a colon ``\lstinline!:!'' are right-associative, unless they are $n$-ary (\sref{sec:nary-infix-expressions}); and operators ending in a greater-than sign ``\lstinline!>!'' are right-binding, if they both consist of more than one operator character. All other operators are left-associative and left-binding. No operator is right-associative and right-binding at the same time, as right-binding operators are in fact left-associative. 

Precedence, associativity and binding direction of operators determine the grouping of parts of an expression as follows.

\begin{itemize}
  \item If there are several infix operations in an expression, then operators with higher precedence bind more closely than operators with lower precedence. 

  \item If there are consecutive infix operations $e_0\ \op_1\ e_1\ \op_2 \ldots \op_n\ e_n$ with operators $\op_1 \ldots \op_n$ of the same precedence, then all those operators must have the same associativity (i.e. it is an error if they don't). If all operators are left-associative, then the sequence is interpreted as ~\lstinline!(($e_0\ \op_1\ e_1$) $\op_2 \ldots$) $\op_n\ e_n$!. Otherwise, if all operators are right-associative, the sequence is interpreted as ~\lstinline!$e_0\ \op_1$ ($e_1\ \op_2$ ($\ldots \op_n\ e_n$))!.

  \item A left-associative binary operation $e_1\ \op\ e_2$ is interpreted as ~\lstinline!$e_1$.`$\op$`($e_2$)!. If $\op$ is right-associative or right-binding, the same operation is interpreted as ~\lstinline!{ val x := $e_1$; $e_2$.`$\op$`($x$) }!, where $x$ is a fresh name. 

  \item The right-hand operand of a left-associative operator may consist of several arguments enclosed in parentheses, e.g. ~\lstinline!$e\ \op$ ($e_1 \commadots e_n$)!. This expression is then interpreted as ~\lstinline!$e$.`$\op$`($e_1 \commadots e_n$)!. 

  \item The left-hand operand of a right-associative or right-binding operator may consist of several arguments enclosed in parentheses, e.g. ~\lstinline!($e_1 \commadots e_n$) $\op\ e$!. This expression is then interpreted as ~\lstinline!$e$.`$\op$`($e_1 \commadots e_n$)!. 
  
  \item If $e_0$ in $e_0\ \op_1\ e_1$ does not implement the operator, then the infix operation is equivalent to function application $\op_1(e_0,\ e_1)$, and if such function does not exist either, then implicit conversions are attempted on $e_0$. This is also applied recursively to consecutive infix operations. 
\end{itemize}





\paragraph{Alphanumeric Infix Operators vs. Function Application}

Infix operations take precedence over function applications (\sref{sec:function-applications}) that use ``poetry''-style arguments passing.

\example Distinction between infix operations and function applications with ``poetry''-style arguments passing. 
\begin{lstlisting}
(* function application *)
file.open "hello_world.txt"
(* is equivalent to function application *)
file.open("hello_world.txt")

(* whereas expression *)
a shift-left b
(* is an infix expression equivalent to *)
a.shift-left(b)
(* or alternatively *)
shift-left(a, b)
(* and not to the less obvious *)
a(shift-left(b))
\end{lstlisting}

Infix operations can be grouped together. If there is an even number of expressions separated by whitespace (i.e., no right-hand side of an infix operation), the last one is an argument in ``poetry''-style function application, but such code is considered suspicious and a warning is issued during compilation. 




\paragraph{Standard Operators}

Always consult GFR-2 for complete reference. This is a short extract of the full set of standard operators. Not all classes implement these operators, e.g. \code{Object} implements none, not even \code{=}. 

Language-reserved operators:
\begin{lstlisting}
a == b       (* value identity *)
a /== b      (* not identical *)
not (a == b) (* quite the same as `not identical' *)
\end{lstlisting}

Standard arithmetic operators:
\begin{lstlisting}
a + b     (* addition *)
a +. b    (* real addition *)
a - b     (* subtraction *)
a -. b    (* real subtraction *)
a * b     (* multiplication *)
a *. b    (* real multiplication *)
a / b     (* any number division *)
a /. b    (* real division *)
a // b    (* rational division *)
a //. b   (* rational division with real numerator *)
a div b   (* integral division *)
a mod b   (* modulo *)
a quot b  (* quotient *)
a rem b   (* remainder *)
a ^ b     (* power *)
\end{lstlisting}

Standard comparison operators:
\begin{lstlisting}
a = b    (* equality *)
a /= b   (* non-equality *)
a < b    (* less than *)
a <= b   (* less than or equal *)
a > b    (* greater than *)
a >= b   (* greater than or equal *)
\end{lstlisting}

Extended comparison operators (arguments are a tuple on the right hand side of the operator):
\begin{lstlisting}
a = ($\ldots$)   (* `a` equal to all arguments *)
a /= ($\ldots$)  (* `a` not equal to all arguments,
            but arguments may be equal to each other *)
a < ($\ldots$)   (* `a` less than all arguments *)
a <= ($\ldots$)  (* `a` less than or equal all arguments *)
a > ($\ldots$)   (* `a` greater than all arguments *)
a >= ($\ldots$)  (* `a` greater than or equal all arguments *)
\end{lstlisting}

Standard bitwise operators: 
\begin{lstlisting}
a << b   (* arithmetic (& logical) shift left *)
a <<< b  (* shift left, preserving the least significant bit *)
a >> b   (* arithmetic shift right *)
a >>> b  (* logical shift right *)
a <<@ b  (* rotate left *)
a >>@ b  (* rotate right *)
a and b  (* bitwise and (when applied to numbers) *)
a &&& b  (* bitwise and *)
a or b   (* bitwise or (when applied to numbers) *)
a ||| b  (* bitwise or *)
a xor b  (* bitwise xor (when applied to numbers) *)
not a    (* bitwise not (prefix, unary; when applied to numbers) *)
\end{lstlisting}

Standard boolean (logical) operators:
\begin{lstlisting}
a && b   (* boolean and *)
a and b  (* boolean and *)
a || b   (* boolean or *)
a or b   (* boolean or *)
a xor b  (* boolean xor *)
not a    (* boolean not (prefix, unary; when applied to booleans) *)
\end{lstlisting}

% Standard fuzzy logic operators:
% \begin{lstlisting}
% \end{lstlisting}





\paragraph{Range Expressions}
A range expression (the \code{Range_Expr} syntax category) is a special case of an infix expression, which can optionally be followed by delta and digits specifications, so that a range that may result from it the expression can swap a floating point type with a fixed point type, and thus allowing more operations on the range, e.g. iteration (where the delta defines the ``step'' of each iteration). 

If the expression contains both delta and digits specifications, the expected type of both operands is a decimal fixed point type with corresponding specification of delta and digits. The range of the type is implementation-defined. 

If the expression contains only a delta specification, the expected type of both operands is an ordinary fixed point type with corresponding specification of delta. The range of the type is implementation-defined. 




\paragraph{Slice Expression}
A slice expression (the \code{Slice_Expr} syntax category) is a special case of an infix expression, which can only appear in function applications as an argument. 

The expression is a representation of a range that has optional bounds, and if the bound is missing, it is \code{None}. This has special meaning for functions that accept slices as arguments -- usually, missing left bound means ``from first'', missing right bound means ``to last inclusive''. 




\subsubsection{Assignment Operations}
\label{sec:assignment-operations}

An assignment operator is an operator symbol that ends in an ``equals'' character ``\lstinline!=!'', with the exception of operators for which one of the following conditions holds: 
\begin{enumerate}
\item the operator also starts with an equals character and has more than one character, or
\item the operator is one of ``\lstinline!<=!'', ``\lstinline!>=!'', ``\lstinline!/<=!'', ``\lstinline!/>=!'' or ``\lstinline!/=!''\footnote{This one effectively disqualifies ``\lstinline!$l$ /= $r$!'' from being treated as ``\lstinline!$l$ := $l$ / $r$!'', very intentionally: to prevent floating/fixed point division from being privileged to integral division, ``\code{div}''.}.
\end{enumerate}

Assignment operators are treated specially in that they can be expanded to assignments if no other interpretation is valid, as previously defined. Assignment operators can be defined as members of a type. 

Let's consider an assignment operator, such as ``\lstinline!+=!'', in an infix operation ~\lstinline!$l$ += $r$!, where $l$ \& $r$ are expressions. This operation can be re-interpreted as an assignment
\begin{lstlisting}
$l$ := $l$ + $r$
\end{lstlisting}
except that the operations's left-hand-side $l$ is evaluated only once. 

The re-interpretation is occurs if the following conditions are fulfilled:
\begin{enumerate}
  \item The left hand side $l$ does not have a member named ``\lstinline!+=!'', and also can not be converted by an implicit conversion (\sref{sec:implicit-conversions}) to a value with a member named ``\lstinline!+=!'', applicable to a value of type of $r$. 
  \item The assignment ~\lstinline!$l$ := $l$ + $r$! is type-correct. In particular, this implies that $l$ refers to an object that is convertible to a value with a member named ``\lstinline!+!'' (or itself has such a member without conversion, in the ideal case, indeed). 
  \item The variable $l$ is assignable, defined, not immutable. This implies that it is defined as a ~\lstinline!var $l$!. 
\end{enumerate}

The re-interpretation is built into the compiled bytecode in such a way that first tries the assignment operator, and then the re-interpretation only in case where the assignment operator approach failed.\footnote{No appropriate implicit conversion was found, or if implicit conversions are disabled for the expression, the value referred to by $l$ does not have the appropriate member.} It is indeed an error if none of the two approaches succeeded. 

Assignment operations are right-associative, despite any rules defined for other operators. The value of an assignment expression is the left-hand side argument after the assignment operation was evaluated. 

\example Right-associativity of assignment operations, using mutable variables as left-hand sides. 
\begin{lstlisting}
(* the assignment *)
a := b := c
(* is equivalent to *)
a := (b := c)

(* the assignment *)
(a := b) := c
(* is equivalent to *)
a := b; a := c

(* this also works *)
a := let b := c
(* as *)
a := (let b := c)
\end{lstlisting}




\subsubsection{$N$-ary Infix Expressions}
\label{sec:nary-infix-expressions}

\syntax\begin{lstlisting}
nary_op_id  ::= '?' {op_char}
Infix_Expr  ::= Infix_Expr nary_op_id Infix_Expr {':' Infix_Expr}
\end{lstlisting}

Operators that begin with a question mark ``\code{?}'' (and may as well consist only of that one character) have the special ability to create an $n$-ary infix expression. Those are recognized by the ``\code{:}'' symbol, which is otherwise not allowed as an operator. Here, it serves as a separator of arguments to the $n$-ary infix operation. The expression is viewed as if it were a regular infix expression, where the infix expressions following the $n$-ary operator are all right-hand side arguments to the operation. 

The following two infix expressions and the third function application are equivalent.
\begin{lstlisting}
a ? b : c : d
a ? (b, c, d)
a.`?`(b, c, d)
\end{lstlisting}

\example The most widely used $n$-ary operator is the ternary conditional operator ``\code{?}'', which could be defined on the \code{Boolean} type as follows:

\begin{lstlisting}
class Boolean extends Object
  operator ? [A, B <: A, C <: A] (if_true: => B, if_false: => C): A
    if self
      if_true
    else
      if_false
    end
  end
end
\end{lstlisting}

Such definition of the conditional operator includes lazy evaluation of the arguments. A shorthand version could use an object definition from which the operator name may be imported into scope:

\begin{lstlisting}
object Conditional
begin
  operator ?: [A, B] (if_true: => A, if_false: => B): A or B
    if if_true.to_boolean
      if_true
    else
      if_false
    end
  end
end

implicit def to_boolean_wrapper [W] (obj: W): Boolean_Wrapper[W]
  Boolean_Wrapper.new(obj)
end
\end{lstlisting}

Then, one may use these operators as follows: 

\begin{lstlisting}
val a := b ? c : d
val e := b ?: d (* which is equal to `b ? b : d` *)
\end{lstlisting}





\subsubsection{Operator Name Resolution}

In any operator-related expression (prefix, infix, $n$-ary), the operator name is first searched in the receiver. Then, if not found, the name scope in which the operator expression appears, is searched for an operator of the given name and arity of arguments count incremented with 1 (for the original receiver). After that, implicit conversions are applied to the receiver, to a type that contains operator with the given name. 





\subsection{Target Type Expressions}
\label{sec:target-type-expressions}

\syntax\begin{lstlisting}
TT_Expr ::= '.' Simple_Expr1
\end{lstlisting}

Target type expression $e$ with expected type $\exptype$ is a shorthand for the selection and/or application (either function, type or both) ~\lstinline!$\exptype$.$e$!. 

Target type expressions appear throughout the syntax in a few places. Each such place imposes a condition on what is a legal target type expression for it. Every target type expressions requires an expected type to be defined. Based on the expected type, the target type expression is a selection from the expected type. If a target type expression is used as an argument, its type is a refinement that contains the selected member (or members if chained), and optionally a requirement of type parameters and/or application parameters. The refinement is then as usual checked relative to the expected type, and not recursively on any nested members. Implicit conversions may not be applied on the resulting expression, because there would be no way to evaluate an original value, which depends on the expected type. 

\paragraph{Note}
Target type expressions are limited to a simple selection, or a chain of selections, optionally followed by a type application and/or a function application with arbitrary number of argument lists. 





\subsection{Assignments}

\syntax\begin{lstlisting}
Assign_Expr ::= [Simple_Expr '.'] id ':=' Rvalue_Expr
              | Mul_Assign_Expr
Update_Expr ::= Simple_Expr1 Argument_Exprs ':=' Rvalue_Expr
Rvalue_Expr ::= Expr | TT_Expr
\end{lstlisting}

The interpretation of an assignment to a simple variable ~\lstinline!$x$ := $e$!~ depends on the definitions of $x$. If $x$ denotes a mutable variable, then the assignment changes the current value of $x$ to the result of evaluating the expression $e$. The type of $e$ is expected to conform to the type of $x$. 

If $x$ is defined as a property of some template, or the template contains a setter function ~\lstinline!$x$_=!~ as a member, then the assignment is interpreted as the invocation ~\lstinline!$x$_=($e$)!~ of that setter function. 

Analogously, an assignment ~\lstinline!$f$.$x$ := $e$!~ is interpreted as the invocation ~\lstinline!$f$.$x$_=($e$)!. If $f$ is evaluated to \code{nil}, then the invocation is forwarded to \code{nil}.\footnote{This likely results in a runtime error being raised, unless \code{nil} would actually implement method \code{x_=}.} 

An assignment ~\lstinline!$f$.?$x$ := $e$!~ is interpreted as the invocation ~\lstinline!$f$.?$x$_=($e$)!. If $f$ is evaluated to \code{nil}, then the invocation is evaluated to \code{nil}. See (\sref{sec:designators}) for more on behavior of the ``\lstinline!.?!'' navigation. 

An assignment ~\lstinline!$f$($\args$) := $e$!~ with a function application to the left of the ``\lstinline!:=!'' operator is interpreted as ~\lstinline!$f$.update($\args$)($e$)!, i.e. the invocation of an \code{update} function defined by $f$. If $f$ is evaluated to \code{nil}, then the invocation is forwarded to \code{nil}. The ``\lstinline!.?!'' navigation is not available with this expression. 

The interpretation of an assignment ~\lstinline!$x$ := .$e$!, where $x$ may be any of the left-hand sides described so far in assignments, depends on the type of $x$: if $e$ is a selection or a name, then the member of $x$ with the name selected by $e$ is used as the assigned value, and if arguments are also applied to $e$, then they are applied to the selected member as well. It is an error if the type of $x$ does not contain the selected member. 

\example Here are some assignment expressions and their equivalent interpretations. 
\begin{lstlisting}
f := e                       f_=(e)
f() := e                     f.update()(e)
f(i) := e                    f.update(i)(e)
f(i, j) := e                 f.update(i, j)(e)
x.f := e                     x.f_=(e)
x.f() := e                   x.f.update()(e)
x.f(i) := e                  x.f.update(i)(e)
x.f(i, j) := e               x.f.update(i, j)(e)
f()() := e                   f().update()(e)
f(i)() := e                  f(i).update()(e)
f()(i) := e                  f().update(i)(e)
f(i)(j) := e                 f(i).update(j)(e)
f(i, j)(k) := e              f(i, j).update(k)(e)
f(i, j)(k, l) := e           f(i, j).update(k, l)(e)
f(i, j) := (e_1, e_2)        f.update(i, j)((e_1, e_2))
\end{lstlisting}






\subsubsection{Multiple Assignments}
\label{sec:multiple-assignments}

\syntax\begin{lstlisting}
Mul_Assign_Expr ::= Mul_Vars ':=' Mul_Exprs
Mul_Vars        ::= [[val_ids ','] '*' id ','] val_ids
                  | [val_ids ','] '*' id
Mul_Exprs       ::= Mul_Expr {',' Mul_Expr}
Mul_Expr        ::= ['*'] Expr | TT_Expr
\end{lstlisting}

Multiple assignment is a way to assign multiple variables at once. On the left-hand side of the assignment are variables separated by commas, where at most one of which may be prefixed with an asterisk ``\lstinline!*!''. On the right-hand side of the assignment are expressions separated by commas, where one or more expressions may be prefixed with an asterisk ``\lstinline!*!'' as a sequence-splat operator. 

The left-hand side of the multiple assignment must contain only variable names that can be assigned to -- so either mutable variables, or declared and not defined variables. 

The right-hand side is expanded into a single sequence of expressions in the following way:
\begin{enumerate}
\item Say that $e_1 \commadots e_n$ are the original right-hand side expressions. 

\item For each $e_i$, where $1 \leq i \leq n$, if $e_i$ is prefixed with a sequence-splat operator, replace $e_i$ with a comma-separated expressions $e_{i,j}$, where $j$ is the index of the sub-expression contained in the original $e_i$, and move to the next expression $e_{i+1}$. 
\end{enumerate}

To match the left-hand side variable names with the expanded right-hand side expressions, match first the variables until the one prefixed with an asterisk, if any, and remove the matched expressions. Count variables that are following the one prefixed with an asterisk as $m$ and match them with the remaining expressions, starting from expression $n - m$ where $n$ is the count of the remaining expressions, or from the first expression, if $m \geq n$. If $m \leq n$, then collect the remaining expressions into a sequence and assign it to the variable prefixed with an asterisk. In any case, if there are less expressions available than variables to assign to, assign the extra variables with \code{nil}. If there are more expressions than variables to assign to and no variable is prefixed with an asterisk, then the extra expressions are discarded and released. 

The multiple assignment evaluates all expressions on the right-hand side of the assignment prior to the actual assignment. The expected type of each assigned expression is the expected type of the corresponding variable it assigns to, or if the corresponding variable is prefixed with an asterisk, then the expected type is the expected type of the elements of the sequence declared by that variable. 

If the name of the assigned variable is ``\lstinline!_!'', the assignment for that variable is not evaluated and is discarded. 

\example The following examples show how multiple assignment works. 
\begin{lstlisting}
(* swap two variables *)
a, b := b, a

(* swap with a pattern and a tuple, 
   rebinding the names a and b *)
let (a, b) := (b, a)

(* `a` will be `e`
   `b` will be the first element of `f` (if `f` contains anything)
   `d` will be the last element of `f` (if `f` contains anything)
   `c` will be the remaining elements of `f` (if `f` contains anything)
   if `f` is an empty sequence, then `b` and `d` are assigned nil
     and `c` is an empty sequence
   if `f` has one element, then `d` is assigned nil 
     and `c` is assigned an empty sequence
   if `f` has two elements, then `c` is assigned an empty sequence *)
a, b, *c, d := e, *f
\end{lstlisting}




\section{Definition Expressions}
\label{sec:def-expressions}

\syntax\begin{lstlisting}
Expr ::= Val_Def In_Sep Expr ['end']
       | Var_Def In_Sep Expr ['end']
\end{lstlisting}




\section{Type-Related Expressions}





\subsection{Typed Expressions}
\label{sec:typed-expressions}

\syntax\begin{lstlisting}
Cast_Expr  ::= Infix_Expr ('as' | 'as!' | 'as?') (Type | Simple_Expr1)
Infix_Expr ::= Infix_Expr ('is' ['not'] | 'is!' | 'is' 'not!') 
               (Type | Simple_Expr1)
\end{lstlisting}

The typed expression ~\lstinline!$e$ as $T$!~ has type $T$. The type of expression $e$ is expected to conform to $T$. The result of the expression is the value of $e$ converted to type $T$. The conversion can take these forms, preferred in the following order:
\begin{enumerate}
  \item No conversion, if $e$ conforms to $T$ directly. 
  \item If an implicit conversion $c$ from expression type $E$ of method type ~\lstinline!($E$) $\mapsto\ T$!~ exists in the scope, then the conversion is of the form ~\lstinline!$c$($e$)!. 
  \item Otherwise, the conversion is of the form ~\lstinline!$e$.as_instance_of[$T$]()!.\footnote{Note that this conversion method is not included in implicit conversions, and has to be used either directly, or via a typed expression.}
\end{enumerate}

If a type implements the ~\lstinline!as_instance_of[$T$]()!~ method, it must meet one of the following conditions:
\begin{itemize}
  \item Have at most one empty parameter list.
  \item Have exactly one implicit parameter list.\footnote{And no other parameter list.}
\end{itemize}

The conformance check expression ~\lstinline!$e$ is $T$!~ has type \code{Boolean} and tests whether $e$ conforms to $T$, basically by asking a question ``Can $e$ be of type $T$?'', answering either ``It can be'' or ``It can't be''. The expression $e$ conforms to type $T$ if at least one of the following conditions hold:
\begin{enumerate}
  \item Type of $e$ is a subtype of $T$. 
  \item An implicit conversion $c$ from expression type $E$ of method type ~\lstinline!($E$) $\mapsto\ T$!~ exists in the scope. 
  \item As a last resort, type of $e$ overrides the method ~\lstinline!is_instance_of[$T$]()!~ and evaluating it results in \code{yes} value.\footnote{This method basically tells whether the instance implements ~\lstinline!as_instance_of[$T$]()!, thus being able to convert itself into another type without other implicit conversions.}
\end{enumerate}

\paragraph{Flow Based Typing} 
If the conformance check expression is performed on a variable, as defined here, it shadows the type of the variable, if used as a condition in a conditional expression (\sref{sec:conditional-expressions}), in the related branch. Therefore, it is also used in resolution of function applications (\sref{sec:function-applications}). Furthermore, if the type of the variable was already known in the outer code, then it can both restrict and extend the expected type $T$ with $U$ into $T$: 
\begin{itemize}
  \item If the type $T$ did not contain $U$, then $T'$ is ~\lstinline!$T$ with $U$!.
  \item If the type $T$ did contain $U$ and was a union type, then $T'$ is only $U$, dropping the other member types. 
  \item In the other branches of a conditional expression, it means that $T$ does not conform to $U$, whatever that implies. Also, the same happens to the same branch, if the conformance check is negated (e.g., ~\lstinline!$e$ is not $U$!). 
\end{itemize}

The conformance check expression ~\lstinline!$e$ is not $T$!~ has type \code{Boolean} and tests whether $e$ does not conform to $T$, basically by asking a question ``Can $e$ not be of type $T$?'', answering either ``It can't be'' or ``It can be''.

The typed expression ~\lstinline@$e$ as! $T$@~ works like ~\lstinline!$e$ as $T$!, but only uses the first form. Similarly, the conformance check expression ~\lstinline@$e$ is! $T$@~ works like ~\lstinline!$e$ is $T$!, but it uses only the first condition, and the conformance check expression ~\lstinline@$e$ is not! $T$@~ works like ~\lstinline!$e$ is not $T$!, but also uses only the first condition. The bang character ``\lstinline@!@'' signalizes that the operation is more dangerous, in means of that its easier for the expression $e$ to not successfully convert to the target type or conform to it. 

The typed expression ~\lstinline!$e$ as? $T$!~ has a result of type ~\lstinline!$T$?!, resulting in a \code{nil} value instead of an error if no conversion is available to treat $e$ as $T$. 

If an expression is typed to a dynamic path of a (syntactic) type, then the value referenced by such path is expected to be a type, and it is an error if it is not. 

Typed expressions do not allow checks against target type expressions (\sref{sec:target-type-expressions}) and conversions to them, as such checks and conversions would make no sense at all. 






\subsection{Annotated Expressions}
\label{sec:annotated-exprs}

\syntax\begin{lstlisting}
Annot_Expr ::= Annotation {Annotation} Infix_Expr
\end{lstlisting}

An annotated expression $a_1\ \ldots\ a_n\ e$ attaches annotations $a_1\ \ldots\ a_n$ to the expression $e$ (\sref{sec:annotations}). 





\section{Control Flow Expressions}





\subsection{Conditional Expressions}
\label{sec:conditional-expressions}

\syntax\begin{lstlisting}
Cond_Expr        ::= Cond_Block_Expr | Cond_Mod_Expr
Cond_Block_Expr  ::= Cond_Block_Expr1 | Cond_Block_Expr2
Cond_Block_Expr1 ::= 'if' Condition ('then' | semi) Cond_Block 
                     {[semi] 'elsif' Condition 
                      ('then' | semi) Cond_Block}
                     [[semi] Else Cond_Block] 'end' ['if']
Cond_Block_Expr2 ::= 'unless' Condition ('then' | semi) Cond_Block 
                     {[semi] 'elsif' Condition 
                      ('then' | semi) Cond_Block}
                     [[semi] Else Cond_Block] 'end' ['unless']
Cond_Mod_Expr    ::= Expr Cond_Modifier
Cond_Modifier    ::= Cond_Modifier1
                     [Else Infix_Expr]
Cond_Modifier1   ::= ('if' | 'unless') Condition 
Cond_Block       ::= Expr | Block
Else             ::= 'else' | 'otherwise'
Condition        ::= Simple_Expr1 | Val_Def | Var_Def
\end{lstlisting}

The conditional expression ~\lstinline!if $e_1$ then $e_2$ else $e_3$!~ chooses one of the values of $e_2$ and $e_3$, depending on the value of $e_1$. The condition $e_1$ is expected to conform to type \code{Boolean}, but can be virtually any type -- if it is not a \code{Boolean}, then it is equal to \code{yes} if it implements the method ~\lstinline!to_boolean(): Boolean! and that implementation returns \code{yes}, or can be converted to \code{yes} (\sref{sec:typed-expressions}), and \code{no} otherwise. The \code{nil} and \code{undefined} objects convert always to \code{no}. If the $e_1$ is the single instance ``\lstinline!()!'' of type \code{Unit}, it is an error. The \code{then}-part $e_2$ and the \code{else}-part $e_3$ are both expected to conform to the expected type of the conditional expression, but are not required to. The type of the conditional expression is the weak least upper bound (\sref{sec:weak-conformance}) of the types of $e_2$ and $e_3$. A semicolon preceding the \code{else} symbol of a conditional expression is ignored. 

The conditional expression is evaluated by evaluating first $e_1$. If this evaluates to \code{true}, the result of evaluating $e_2$ is returned, otherwise the result of evaluating $e_3$ is returned. 

The evaluation of $e_1$ utilizes the so-called {\em short-circuit evaluation}. The expression $e_1$ is split by binary boolean operators. Then every first argument is evaluated, but the second argument is evaluated only if the evaluation of the first argument does not suffice to determine the value of the expression. When the first argument of ``\lstinline!&&!'' evaluates to \code{no}, the overall value must be \code{no} and the result of evaluating the second argument does not change that. When the first argument of ``\lstinline!||!'' evaluates to \code{yes}, the overall value must be \code{yes}. These boolean operators are in fact short-circuited source-code-wide, not only as part of conditional expressions. Word equivalents of these operators are also short-circuited (``\code{and}'' and ``\code{or}'' respectively). To prevent short-circuited behavior, one has to use the operator identifier in a function application (\sref{sec:function-applications}).

\example The following examples show how short-circuit evaluation behaves. Let's mark the short-circuited ``\lstinline!&&!'' as ``\lstinline!sand!'' and the short-circuited ``\lstinline!||!'' as ``\lstinline!sor!''. On the right side are the equivalent conditional expressions. 
\begin{lstlisting}
$x$ sand $y$          if $x$ then $y$ else no
$x$ sor $y$           if $x$ then yes else $y$
\end{lstlisting}

A short form of the conditional expression eliminates the \code{else}-part. The conditional expression ~\lstinline!if $e_1$ then $e_2$!~ is evaluated as if it was ~\lstinline!if $e_1$ then $e_2$ else ()!, and is therefore expected to be the weak least upper bound of the type \code{Unit} and the type of $e_2$. 

The conditional expression 
\begin{lstlisting}
if $e_1$ then $e_2$ elsif $e_3$ then $e_4$ $\ldots$ elsif $e_n$ then $e_{n+1}$ else $e_{n+2}$
\end{lstlisting} 
is evaluated as if it was 
\begin{lstlisting}
if $e_1$ then $e_2$ else if $e_3$ then $e_4$ $\ldots$ else if $e_n$ then $e_{n+1}$ else $e_{n+2}$
\end{lstlisting}
Basically, \code{elsif} is a simple syntax sugar for the little longer \code{else if} keyword tokens sequence. 

The alternative conditional expression ~\lstinline!unless $e_1$ then $e_2$ else $e_3$!~ is evaluated as if it was ~\lstinline@if not $e_1$ then $e_2$ else $e_3$@. Unlike in Ruby, the \code{elsif}-part is allowed to appear with this conditional expression. However, there is no syntax sugar for the \code{else unless} keyword tokens sequence. 

The modifier-fashion conditional expression ~\lstinline!$e_1$ if $e_2$ else $e_3$!~ is interpreted as if it was ~\lstinline!if $e_2$ then $e_1$ else $e_3$!. Similarly with the \code{unless} version and the short form of the modifier conditional expression (without the explicit \code{else}-part). 

Unlike in some languages, conditional expressions do not require to place parentheses around the conditions -- but it is possible to do so, the result is equivalent. That might be useful when the condition is inevitably long and needs to span multiple lines -- so that boolean operators may be situated at the beginning of each new line, instead of being at the end of the previous line. 

\paragraph{Note}
Gear provides two equivalent alternatives of the usual ``\code{else}'' keyword: ``\code{else}'' (obviously) and ``\code{otherwise}''. This is only provided so that certain conditions may be read better.

\paragraph{Conditional Variable Definition}
The conditional variable definition ~\lstinline!if $p$ := $e_1$ then $e_2$ else $e_3$!, where ~\lstinline!$p$ := $e_1$!~ is a variable definition (see syntactic categories \code{Var_Def} \& \code{Val_Def}), works the same way as other conditional expressions, with the following difference: if $e_1$ evaluates to \code{nil} or even \code{()} (\code{Unit} value), then the condition is regarded as \code{no}. Beware that if $e_1$ evaluates to \code{no}, the condition is still met and $e_2$ is evaluated. Note that if type required by $p$ does not allow \code{nil} or \code{()} value, then no error happens and $e_3$ is evaluated instead. The condition in this case says ``if the variable definition ~\lstinline!$p$ := $e_1$!~ can be realized, then proceed with $e_2$, otherwise proceed with $e_3$''. 






\subsection{Loop Expressions}

Gear has an elaborate support for loop expressions. Not all structures known from other languages are supported though, e.g. the ~\lstinline[language=Java]!do $\ldots$ while!~ expression, which is expressed differently in Gear. 






\subsubsection{Loop Control Expressions}
\label{sec:loop-control-expressions}

\syntax\begin{lstlisting}
Loop_Ctrl_Expr ::= Break_Expr
                 | Skip_Expr
                 | Next_Expr
                 | Redo_Expr
                 | Exhausted_Expr
                 | Broken_Expr
Break_Expr     ::= 'break' [label_name] [Cond_Modifier1]
Skip_Expr      ::= 'skip' [integer_literal] [Cond_Modifier1]
Next_Expr      ::= 'next' [label_name] [Cond_Modifier1]
Redo_Expr      ::= 'redo' [label_name] [Cond_Modifier1]
Exhausted_Expr ::= 'exhausted' Block_Expr
Broken_Expr    ::= 'broken' Block_Expr
\end{lstlisting}

Loop control expressions are made available inside of loop expressions to allow control of the enclosing loops.

In the following paragraphs, a {\em loop identified by the label $l$} is a loop expression preceded in its syntax with the syntax element \code{Label_Dcl} (\sref{sec:local-jump-expressions}). All annotations (\sref{sec:annotated-exprs}) that precede the label declaration are applied to the following loop expression, never to the label. 

The ~\lstinline!break $l$!~ expression stops the loop labeled with $l$, and omitting the $l$ label stops the directly enclosing loop. 

The ~\lstinline!skip $i$!~ expression skips $i$ loop iterations, or with the $i$ omitted, skips $1$ loop iteration (the current iteration). 

The ~\lstinline!next $l$!~ expression skips the current loop iteration and every other enclosing iteration until the loop identified by the given label $l$ is found, and continues with its next iteration. If the label $l$ is omitted, then its behavior is equal to ~\lstinline!skip 1!. 

The ~\lstinline!redo $l$!~ restarts the loop identified by the label $l$ (and stops all loops in between), or if $l$ is omitted, restarts the directly enclosing loop. 

The ~\lstinline!exhausted $e$!~ expression evaluates the expression $e$ only if the directly enclosing loop {\em was not broken} with the \code{break} keyword. 

The ~\lstinline!broken $e$!~ expression evaluates the expression $e$ only if the directly enclosing loop {\em was broken} with the \code{break} keyword. 

The standard library provides loop-like methods, where these loop control structures are not available as keywords, but as methods instead (either imported or available on some given loop-control object) -- they might be implemented e.g. using the \code{throw} expressions (\sref{sec:throw-catch-expressions}), that the enclosing loop-like method catches and resolves as appropriate. Only the \code{exhausted} and \code{broken} constructs need to be simulated, possibly by optional parameters or additional parameter sections.\footnote{In fact, all loop expressions may be interpreted as syntax sugar to such methods. How exactly -- that may get into this specification as soon as it is clearly defined.} 





\subsubsection{Iterable For Expressions}
\label{sec:iterable-expressions}

\syntax\begin{lstlisting}
Loop_Expr       ::= [Label_Dcl] 'for' Val_Dcls 'in' ['reverse'] Expr 
                    ['step' Expr] For_Loop
For_Loop        ::= 'loop' Loop_Block_Expr 'end' ['loop']
                  | 'do' Loop_Block_Expr 'done'
                  | '{' Loop_Block_Expr '}'
Loop_Block_Expr ::= {Block_Stat | Loop_Ctrl_Expr}
Val_Dcls        ::= Val_Dcl
                  | Pattern1
\end{lstlisting}

The {\em iterable expression} is typed as \code{Unit}, so there is no point in using its value. 

In an expression ~\lstinline!for $e_1$ in $e_2$ loop $e_3$ end!, the type of $e_2$ is expected to conform to ~\lstinline!Iterable_Like[$E$]!. The type of $e_1$ is expected to conform to the type $E$. The type of $e_3$ is evaluated to ``\lstinline!()!'' anyway. The scope of variables defined in $e_1$ extends to the $e_3$ expression. 

In expression ~\lstinline!for $e_1$ in reverse $e_2$ loop $e_3$ end!, the type of $e_2$ is expected to conform to \code{Reverse_Iterable_Like}. 

Iterable expressions make use only of the two mentioned traits and the methods defined by them, and therefore advanced iterating mechanisms, such as parallel computations, are not performed -- they are simply too complex to be generalized by a simple language construct. 

Iterable expression repeats evaluation of the expression $e_3$ for every value that comes from the \code{Iterable_Like}'s \code{Iterator}, unless the loop controls alter this flow (\sref{sec:loop-control-expressions}).

Iterable expressions can be seen as simple comprehensions over iterating a single iterable value. For more complex iterating expressions, see generators (\sref{sec:generator-expressions}).

An expression 
\begin{lstlisting}
for $e_1$ in $e_2$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}
$e_2$.each { when $e_1$ then $e_3$ }
\end{lstlisting} 

An expression 
\begin{lstlisting}
<<$l$>> for $e_1$ in $e_2$ loop $e_3$ end
\end{lstlisting} 
where $l$ is a label name, is translated to the invocation
\begin{lstlisting}[deletekeywords={label}]
$e_2$.each({ when $e_1$ then $e_3$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

An expression 
\begin{lstlisting}
for $e_1$ in reverse $e_2$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}[deletekeywords={reverse}]
$e_2$.reverse.each { when $e_1$ then $e_3$ }
\end{lstlisting} 

An expression 
\begin{lstlisting}
<<$l$>> for $e_1$ in reverse $e_2$ loop $e_3$ end
\end{lstlisting} 
where $l$ is a label name, is translated to the invocation
\begin{lstlisting}[deletekeywords={label,reverse}]
$e_2$.reverse.each({ when $e_1$ then $e_3$ }, label: $l'$)
\end{lstlisting}
where $l'$ is a symbol literal for the label $l$. 

An expression 
\begin{lstlisting}
for $e_1$ in $e_2$ step $i$ loop $e_3$ end
\end{lstlisting} 
is translated to the invocation
\begin{lstlisting}[deletekeywords={step}]
$e_2$.each({ when $e_1$ then $e_3$ }, step: $i$)
\end{lstlisting} 

Analogously, other combinations of \code{reverse}, \code{skip} and labeled loops are translated. If the $e_3$ expression contains a \code{exhausted} expression, then it's block is passed to the \code{each} method as an argument named \lstinline[deletekeywords={exhausted}]{exhausted}, and analogously, if the $e_3$ expression contains a \code{broken} expression, then it's block is passed to the \code{each} method as an argument named \lstinline[deletekeywords={broken}]{broken}.







\subsubsection{While \& Until Loop Expressions}

\syntax\begin{lstlisting}
Loop_Expr     ::= [Label_Dcl] ('while' | 'until') Condition For_Loop
                | Loop_Mod_Expr
Loop_Mod_Expr ::= Expr Loop_Modifier
Loop_Modifier ::= ('while' | 'until') Condition
\end{lstlisting}

The {\em while loop expression} ~\lstinline!while $e_1$ loop $e_2$ end!~ is typed as \code{Unit}, so there is no point in using its value. 

In an expression ~\lstinline!while $e_1$ loop $e_2$ end!, the expression $e_1$ is treated the same way as the condition part in conditional expressions (\sref{sec:conditional-expressions}). The type of $e_2$ is evaluated to ``\lstinline!()!'' anyway.

The while loop expression ~\lstinline!while $e_1$ loop $e_2$ end!~ is alone typed and evaluated as if it was an application of a hypothetical function ~\lstinline!while_loop ($e_1$) ($e_2$)!, where the function \code{while_loop} would be defined as follows, with the $e_1$ and $e_2$ would be passed by-name: 
\begin{lstlisting}
def while_loop (condition: => Boolean)(body: => Unit): Unit := {
<<repeat>>
  if condition { body; goto repeat } else {}
}
\end{lstlisting}
The real implementation has to handle loop control expressions (\sref{sec:loop-control-expressions}) around the evaluation of \code{body} and also handle a label, if one is given; so it is not this simple. 

A while loop expression repeats evaluation of the expression $e_2$ as long as $e_1$ evaluates to \code{yes}, unless the loop controls alter this flow (\sref{sec:loop-control-expressions}).

A while loop expression with variable definition works like a regular while loop expression, but the condition is treated as in conditional variable definition, and can be an immutable value definition, since it is local to each loop. 





\subsubsection{Pure Loops}
\label{sec:pure-loops}

\syntax\begin{lstlisting}
Loop_Expr  ::= [Label_Dcl] 'loop'
               (semi Loop_Block_Expr 'end' ['loop'] | 
               '{' Loop_Block_Expr '}')
\end{lstlisting}

The {\em pure loop expression} ~\lstinline!loop $e$ end!~ is typed as \code{Unit}, so there is no point in using its value. 

A pure loop expression repeats evaluation of the expression $e$ as long as the loop controls don't alter this flow (\sref{sec:loop-control-expressions}). It is basically equivalent to an iterable expression (\sref{sec:iterable-expressions}) that iterates over an endless iterator. 

This expression may also be used to replace the ~\lstinline[language=Java]!do { $e_1$ } while ($e_2$)!~ expression, known from other languages, using the following structure: 
\begin{lstlisting}
loop
  $e_1$
  break if $e_2$
end loop
\end{lstlisting}

A pure loop expression is the only expression that is not translated into a method call, but rather into another expression. The following constructs are practically the same: 
\begin{lstlisting}
(* construct with loop *)
loop
  $\ldots$
end loop

(* construct with goto *)
label loop_begin
  $\ldots$
  goto loop_begin
\end{lstlisting}
However, the loop construct has built-in support for loop control expressions. 





\subsection[Pattern Matching, Case Expressions \& Switch Expressions]{Pattern Matching, Case Expressions \\\& Switch Expressions}
\label{sec:case-exprs}

% TBD: add use of `parallel`

\syntax\begin{lstlisting}
Match_Expr     ::= Pat_Match_Expr | Case_Expr | Switch_Expr
Pat_Match_Expr ::= 'match' Simple_Expr1 Match_Body
Match_Body     ::= semi When_Clauses 'end' ['match']
                 | '{' When_Clauses '}'
When_Clauses   ::= When_Clause {semi When_Clause} 
                   [semi Else Cond_Block]
                   {semi ('rescue' | 'catch') When_Clause}
When_Clause    ::= 'when' Pattern [Guard] ('then' | semi) Cond_Block
Case_Expr      ::= 'case' Simple_Expr1 Case_Body
Switch_Expr    ::= 'switch' Simple_Expr1 Switch_Body
Case_Body      ::= semi Case_Clauses 'end' ['case']
                 | '{' Case_Clauses '}'
Switch_Body    ::= semi Switch_Clauses 'end' ['switch']
                 | '{' Switch_Clauses '}'
Case_Clauses   ::= Case_Clause {['next'] semi Case_Clause}
                   [['next'] semi Else Cond_Block]
                   {semi ('rescue' | 'catch') Case_Clause}
Switch_Clauses ::= Switch_Clause {['next'] semi Switch_Clause}
                   [['next'] semi Else Cond_Block]
Case_Clause    ::= 'when' Case_Patterns ('then' | semi) Cond_Block
Switch_Clause  ::= 'when' Switches ('then' | semi) Cond_Block
Case_Patterns  ::= Case_Pattern {',' Case_Pattern}
Switches       ::= Switch {',' Switch}
Case_Pattern   ::= Stable_Id
                 | id
                 | Infix_Expr
Switch_Scalar  ::= (Literal - Collection_Literal)
Switch         ::= Switch_Scalar [('..' | '...' | '..<') Switch_Scalar]
\end{lstlisting}

Pattern matching is described in (\sref{sec:pattern-matching}). Here, the syntax of expressions that make use of pattern matching is given. 

Case expressions 
\begin{lstlisting}
case $e$ { when $c_1$ then $b_1\ \ldots$ when $c_n$ then $b_n$ else $b_{n+1}$ }
\end{lstlisting}
are simplified pattern matching expressions, though they do not use patterns from pattern matching expressions, but {\em case equality} instead, defined with the method ``\lstinline!===!''. Thus, case expressions do not aim at matching the selector expression $e$, thus decomposing the selector $e$, but rather tests if it falls into a particular set of values, defined using the case equality method, by:
\begin{itemize}
  \item a type of values ~\lstinline!$c$.`===`($e$)!,
  \item a set of values defined by another value ~\lstinline!$e_1$.`===`($e$)!.
\end{itemize}

Let $T$ be the type of the selector expression $e$. The parameter $p_i$ of each invocation of the method ``\lstinline!===!'' is typed with $T$ as its expected type and \code{Boolean} as the result type. It is an error if $T$ does not conform to the actual type of the parameter, as the invocation would not be applicable (\sref{sec:function-applications}). The method ``\lstinline!===!'' may be overloaded for multiple parameter types, then overloading resolution (\sref{sec:overloading-resolution}) applies as usual. 

The method ``\lstinline!===!'' is defined basically as follows:
\begin{lstlisting}
operator === ($x$: $T$): Boolean
  $\ldots$
end
\end{lstlisting}
where $x$ is the parameter name and $T$ is the expected type of the parameter, and the type of the selector expression $e$. 

The expected type of every block $b_i$ is the expected type of the whole pattern matching expression. The type of the pattern matching expression is then the weak least upper bound (\sref{sec:conformance}) of the types of all blocks $b_i$.

Multiple values can define a case pattern, for convenience. Note that no variables are bound from the case pattern to the corresponding block.

A case clause or a switch clause that is not the first appearing may be prefixed with \code{next} on the preceding line, in which case control falls through to its code from the previous case clause or switch clause. 

Switch expressions 
\begin{lstlisting}
switch $e$ { when $c_1$ then $b_1\ \ldots$ when $c_n$ then $b_n$ else $b_{n+1}$ }
\end{lstlisting}
are extremely simplified pattern matching expressions, though they do not use patterns from pattern matching expressions, but {\em equality} and/or {\em range membership} instead. Therefore, switch expressions do not aim at matching the selector expression $e$, thus decomposing the selector $e$, but rather tests if it falls into a particular set of values, defined using the equality or range membership:
\begin{itemize}
  \item number types are matched based on their value,
  \item string types are matched based on their hash code,
  \item boolean types are considered \code{1} for \code{yes} and \code{0} for \code{no}.
\end{itemize}

Compiler adds extra code to determine the value to switch on if the switched expression is of an unknown type, or not of one of the mentioned types. Generally, there are two internal kinds of switch instructions:
\begin{enumerate}
  \item Single entry switch table, for switch expressions without ranges,
  \item Triplet entry switch table, for switch expressions with ranges, where the triplet consists of the two marginal values and an indicator whether the range is inclusive (\code{..}) or exclusive (\code{...} or \code{..<}) of the upper limit. 
\end{enumerate}

Switch expressions therefore do not involve any other implicit conversions or user code evaluation, other than that required to get the value to switch on. If a switch branch uses a guard, that guard becomes a part of the conditional expression that follows. 

\paragraph{Difference from Java etc}
Java (and countless other languages) does not allow switching on other values than integral numbers (and strings since Java 1.7), where Gear allows all scalar literals, including floating point numbers. It is quite unreliable to switch on floating point numbers, due to rounding errors, whereas switching on fixed point numbers is reliable. Both switching on floating point numbers and fixed point numbers should only be involved in switch expressions with ranges. 

\paragraph{NaN in a switch}
The {\em not a number} (\code{Number.NaN}) value is treated specially in switch expressions -- it simply never matches anything else but the \code{else} branch. The comparisons of values involved are safe from errors that could be raised from regular unsuspecting comparison with a \code{NaN} value. 






\subsection{Unconditional Expressions}

Unconditional expressions change the flow of programs without a condition. 






\subsubsection{Return Expressions}
\label{sec:return-expressions}

\paragraph{Implicit return expressions}
Implicit return expression is always the value of the last expression in a code execution path. 

\syntax\begin{lstlisting}
Result_Expr ::= ['memoize'] Expr
              | ['memoize'] 'tailcall' Argument_Exprs
\end{lstlisting}

\paragraph{Explicit return expressions}
Explicit return expressions unconditionally change the flow of programs by making the enclosing function definition return a value early (or return no value). 

\syntax\begin{lstlisting}
Return_Expr ::= ['memoize'] 'return' [Expr] [Cond_Modifier1]
\end{lstlisting}

A return expression ~\lstinline!return $e$!~ must occur inside the body of some enclosing method, or inside a block nested in the body of the innermost enclosing method. Unlike in Scala, the innermost enclosing method in a source program, $f$, does not need to have an explicitly declared result type, as the result type can be inferred as the weak least upper bound of all return paths, including the explicit return path. The return expression evaluates the expression $e$ and returns its value as the result of $f$. The evaluation of any statements or expressions following the return expression is omitted.The type of a return expression is \code{Nothing}.

The expression $e$ may be omitted, then the return expression \code{return} is type-checked and evaluated as if it was ~\lstinline!return ()!, typed as \code{Unit}. 

Returning from a nested block is implemented by throwing and catching a specialized exception, which may be seen by \code{throw}-\code{catch} expressions (\sref{sec:throw-catch-expressions}) between the point of return and the enclosing method. If such a block is captured and run later, at the point where the original call stack frame is long gone, the exception might propagate up the call stack that ran the captured block. Returning from anonymous functions does not affect the enclosing method. 

\paragraph{Memoized return expressions}
A returned expression may optionally be memoized, by using the keyword \code{memoize} right before the returned expression $e$ or ~\lstinline!return $e$!. In that case, arguments and reference to \code{self} are captured and stored along the returned value, so that further calls to the same method with the same arguments may be sped up significantly (\sref{sec:memoization}). Memoization is not available from within anonymous functions and blocks. 






\subsubsection{Structured Return Expressions}

\syntax\begin{lstlisting}
Return_Expr ::= ['memoize'] 'return' Var_Def 'do' 
                Block_Stat {semi Block_Stat} 
                'end' ['return']
\end{lstlisting}

A structured return expression is practically the same as explicit return expression. The variable defined in it has its scope extended to the following block statements, which are evaluated, and then the variable is returned. 






\subsubsection{Local Jump Expressions}
\label{sec:local-jump-expressions}

\syntax\begin{lstlisting}
Jump_Expr  ::= Goto_Expr | Label_Dcl
Goto_Expr  ::= 'goto' label_name [Cond_Modifier1]
Label_Dcl  ::= 'label' label_name 
             | '<<' label_name '>>'
label_name ::= plain_id
\end{lstlisting}

Local jumps transfer control from the points of \code{goto} statements to the statements following a \code{label}. Such a jump may only occur inside of the same function, i.e. it is not possible to jump from one method to another. Also, the jump can't happen to be from outside of a loop into a loop, but the other way around is possible. The only loop expressions that may be jumped out of are the pure loop (\sref{sec:pure-loops}) and a \code{while} loop, which are not transformed as comprehensions into method calls. 






\subsubsection{Continuations}
\label{sec:continuations}






\paragraph{Unlimited continuations}

Unlimited continuations are defined by the whole program, as the unlimited continuation allows almost arbitrary non-local jumps. The unlimited continuation is captured with \code{call/cc} function. 

\paragraph{Definitions}
The following code shows how a function that create unlimited continuations might be defined. 
\begin{lstlisting}
protocol Continuation [-A, +B] extends Function_1[A, B] {$\ldots$}
protocol Unlimited_Continuation [-A] extends Continuation[A, Unit] {$\ldots$}
def call/cc [A, B <: A] (&ctx: Unlimited_Continuation[A] -> B?): A end
\end{lstlisting}

A continuation, while internally holding a copy of the call stack that it was created in, is basically a function from the value that is passed into it to some other type. Unlimited continuations are restricted in the means that the input and output type has to be the same, as an unlimited continuation directly changes its result value based on that without any further modification -- the modification is to be actually performed by the code that invokes the unlimited continuation. Delimited continuations do not have this restriction, as the captured continuation is well defined and delimited to a particular scope. 

To vindicate the signature of \code{Unlimited_Continuation[A]}, it extends \code{Continuation[A, Unit]} because when invoked, it does not return any value and instead the given argument is what its \code{call/cc} application returns -- and therefore \code{call/cc} has to return a value of the same type that the unlimited continuation accepts as argument. This is unlike a delimited continuation, where invocation of the continuation does not continue from \code{reset}. 

\example The following shows how to invoke a continuation. 
\begin{lstlisting}
call/cc {|cont| cont () }
call/cc {|cont| cont 1 }
call/cc {|cont| cont 1, 2, 3 }
\end{lstlisting}
In this example, each line captures the current continuation, with unlimited scope -- the whole call stack is duplicated for that to be possible. Once a continuation is invoked, the code that follows the corresponding \code{call/cc} is resumed, with the passed arguments being the result value. On the first line, the continuation is immediately invoked with no arguments, therefore the \code{call/cc} returns the unit value ``\code{()}''. On the second line, the continuation is immediately invoked with argument \code{1}, therefore the \code{call/cc} returns the value \code{1}. On the third line, the continuation is immediately invoked with arguments \code{1, 2, 3}, therefore the \code{call/cc} returns the value \code{Sequence(1, 2, 3)}. 

Since invoking the continuation changes history and the return value of \code{call/cc}, the values passed as arguments to its invocation are limited to the expected type of the original application of \code{call/cc}. It is an error if a continuation is invoked with a value of an incompatible type. A similar restriction applies to delimited continuations as well. 

There is no requirement for functions that use unlimited continuations to define their result type with any special annotations regarding continuation passing style -- there would not be any result type available, since the whole remaining program is the result. 

The initial application of \code{call/cc} returns whatever the given block returns, and such value has to be compatible with the expected type of the \code{call/cc} application. If the block itself invokes the continuation, then its return value is discarded and replaced with the arguments of the continuation invocation. 







\paragraph{Delimited continuations}

Delimited continuations are defined with \code{reset} and \code{shift} functions. Reset and shift expressions are actually not language constructs, but rather regular functions that have a native implementation capable of unconditionally changing the standard control flow of a program. Moreover, the first \code{shift} expression (which captures the delimited continuation) controls the return value of the \code{reset} expression, which overrides the implicit return expression (\sref{sec:return-expressions}).

The difference between unlimited and delimited continuations is in the scope where the call stack is captured. With delimited continuations, that is defined by the scope of \code{reset} -- once \code{reset} is applied, there is no changing of its value, unlike with unlimited continuations, where the \code{call/cc} is similar to delimited continuation's \code{shift}. 

If the delimited continuation is stored to be used outside of \code{reset}'s bounds, then it can possibly return a value, but never modify the value of the original \code{reset} application.

A \code{reset} application is typed with its expected type and its result type is derived from the statically known contents of its passed block. If at any point there is a \code{Any} type occurring, it might propagate down into the result type. 

\paragraph{Definitions}
The following code shows how functions that create delimited continuations might be defined. 
\begin{lstlisting}
class Shift [+A, -B, +C] (val cont: Continuation[A, B] -> C) {
  def map [A1] (f: A -> A1): Shift[A1, B, C] := {
    Shift.new (k: Continuation[A1, B]) -> { cont((x: A) -> k(f(x))) }
  }
  def flat_map [A1, B1, C1 <: B] (f: A -> Shift[A1, B1, C1]): 
      Shift[A1, B1, C] := {
    Shift.new (k: Continuation[A1, B1]) -> { f(x).cont(k) }
  }
}
def reset [A, C] (ctx: => @[CPS_Param[A, C]] A): C end
def shift [A, B, C] (cont: Continuation[A, B] -> C): 
    @[CPS_Param[B, C] A end
annotation CPS_Param [-B, +C] {$\ldots$}
type CPS_Type [A] := CPS_Param[A, A]
type Suspendable := CPS_Param[Unit, Unit]
\end{lstlisting}

Here, the \code{ctx} parameter represents the block that is passed to \code{reset}. For typing, each \code{shift} block is virtually converted to a \code{for}-comprehension:
\begin{lstlisting}
val ctx := for {
  $x$ in Shift.new($y$)
} yield ($b$)
\end{lstlisting}
where $x$ is a name representing the value that is assigned with the value of the \code{shift} application, $y$ is the block passed to \code{shift}, and $b$ is the code continuation that follows the application of \code{shift} (and which may possibly include more \code{shift} applications). 

\paragraph{Note}
Here, the \code{ctx} parameter is causing the passed block to be used as a positional argument. But for the type system, the annotation \code{@[CPS_Param[A, C]]} makes the type of the argument convert to a \code{for}-comprehension as specified, similar to what workflows (\sref{sec:workflows}) do with their passed blocks. Both conversions may happen dynamically at runtime. Therefore, the passed block is eventually a regular positional argument anyway. 

\example An example of a delimited continuation in use. 
\begin{lstlisting}
reset do
  shift {|cont: Integer -> Integer|
    cont(5)
  } + 1
end
\end{lstlisting}
For the type system, it looks as if it was the following code:
\begin{lstlisting}
val ctx := for {
  x in Shift.new {|cont: Integer -> Integer|
    cont(5)
  }
} yield (x + 1)
reset(ctx)
\end{lstlisting}

\paragraph{Note}
Gear uses saguaro stack mechanisms instead of code conversions to actually implement both continuations. Due to this, the continuations are technically less limited, but the typing of its expressions may get complicated easily, as the control flow is manipulated on VM level.

% TBD: add the example from http://dcsobral.blogspot.cz/2009/07/delimited-continuations-explained-in.html and explain it step-by-step, incl. the double flat_map





\subsection{Throw, Catch \& Ensure Expressions}
\label{sec:throw-catch-expressions}

\syntax\begin{lstlisting}
Catch_Expr    ::= Catch_Expr1 | Catch_Expr2
Catch_Expr1   ::= 'begin' Block 
                  'catch' [nl] Catch_Clauses
                  ['ensure' [nl] Block_Stat {semi Block_Stat}] 'end'
Catch_Expr2   ::= '{' Block '}'
                  'catch' '{' Catch_Clauses '}'
                  ['ensure' '{' Block_Stat {semi Block_Stat} '}']
Throw_Expr    ::= 'throw' Expr
Catch_Clauses ::= Catch_Clause {semi Catch_Clause}
                  [semi Else Catch_Block]
Catch_Clause  ::= 'when' Pattern [Guard] ('then' | semi) Catch_Block
Catch_Block   ::= Expr | {Catch_Stat semi} [Result_Expr]
Catch_Stat    ::= Block_Stat | Rethrow_Expr
Rethrow_Expr  ::= 'rethrow' [Cond_Modifier1]
\end{lstlisting}

A throw expression ~\lstinline!throw $e$!~ evaluates the expression $e$. The type of this expression must conform to \code{Throwable}. It is an error if $e$ evaluates to \code{nil} or ~\lstinline!()!. If there is an active \code{begin}-\code{catch} expression that handles the thrown value, evaluation is resumed with the handler, otherwise a thread executing the \code{throw} is aborted. The type of a \code{throw} expression is \code{Nothing}. 

A \code{begin}-\code{catch} expression is of the form ~\lstinline!{ $b$ } catch $h$!, where $h$ is a handler pattern matching anonymous function (\sref{sec:pattern-matching-anon-fun})
\begin{lstlisting}
{ when $p_1$ then $b_1$ $\ldots$ when $p_k$ then $b_k$ else $b_{k+1}$ } .
\end{lstlisting}

This expression is evaluated by evaluating the block $b$ -- if evaluation of $b$ does not throw any value, the result of $b$ is returned, otherwise the handler $h$ is applied to the thrown value. If the handler $h$ contains a \code{when} clause matching the thrown value, the first such clause is invoked (and may throw another value, or the same value). If the handler contains no such clause, the value is re-thrown. 

Let $T$ be the expected type of the \code{begin}-\code{catch} expression. The block $b$ is expected to conform to $T$. The handler $h$ is expected to conform to type ~\lstinline!Partial_Function[Throwable, $T$]!. The type of the \code{begin}-\code{catch} expression is the weak least upper bound (\sref{sec:conformance}) of the type of $b$ and the result type of $h$. 

A \code{begin}-\code{ensure} expression ~\lstinline!{ $b$ } ensure { $e$ }!~ evaluates the block $b$. If evaluation of $b$ does not cause any value to be thrown, the block $e$ is evaluated. If any value is thrown during evaluation of $e$, the evaluation of the whole expression is aborted with the thrown value. If no value is thrown during evaluation of $e$, the result of $b$ is returned as the result of the whole expression, unless $e$ contains an explicit \code{return} (\sref{sec:return-expressions}) -- in that case, the value returned from $e$ replaces the value returned from $b$, even if $b$ returns a value explicitly. 

If a value is thrown during evaluation of $b$, the \code{ensure} block $e$ is also evaluated. If another value is thrown during evaluation of $e$, evaluation of the whole expression is aborted with the new thrown value and the previous is discarded. If no value is thrown during evaluation of $e$, the original value thrown from $b$ is re-thrown once evaluation of $e$ has completed, unless $e$ again contains an explicit \code{return} (\sref{sec:return-expressions}) -- in that case, the value thrown from $b$ is discarded, and the value returned from $e$ is returned. 


The block $b$ is expected to conform to the expected type of the whole expression and the \code{ensure} block $e$ is expected to conform to type \code{Unit}. 

An expression ~\lstinline!{ $b$ } catch $e_1$ ensure { $e_2$ }!~ is a shorthand for ~\lstinline!{{ $b$ } catch $e_1$ } ensure { $e_2$ }!. 





\subsubsection{Raise Expressions}

\syntax\begin{lstlisting}
Raise_Expr ::= 'raise' Raiseable
Raiseable  ::= string_literal
             | Stable_Id [',' string_literal]
             | Expr
\end{lstlisting}

A raise expression ~\lstinline!raise $e$!~ is similar to ~\lstinline!throw $e$! (\sref{sec:throw-catch-expressions}), it throws a value (raises an error) that is expected to be of type \code{Raiseable}. It has three variants: 
\begin{itemize}
\item[] \lstinline!raise $s$!, where $s$ is a string provided to constructor of the type \code{Runtime_Error}. 
\item[] \lstinline!raise $T$, $s$!, where $s$ is a string provided to constructor of the type $T$. 
\item[] \lstinline!raise $e$!, where $e$ is an expression, whose type is expected to conform to \code{Raiseable}, and whose result value will be raised after its evaluation. 
\item[] \lstinline!raise!, which raises a value of type \code{Runtime_Error} without any message. Such errors should not propagate outside of the method that raises them. 
\end{itemize}

\code{Raiseable} is a subtype of \code{Throwable}. 







\subsubsection{Rescue Expressions}

\syntax\begin{lstlisting}
Rescue_Expr  ::= [Label_Dcl] (Rescue_Expr1 | Rescue_Expr2)
Rescue_Expr1 ::= 'begin' Block 
                 'rescue' [Pattern [Guard]] semi Rescue_Block
                 {'rescue' [Pattern [Guard]] semi Rescue_Block }
                 ['ensure' semi Block_Stat {semi Block_Stat}] 'end'
Rescue_Expr2 ::= '{' Block '}' 
                 'rescue' [Pattern [Guard]] '{' Rescue_Block '}'
                 {'rescue' [Pattern [Guard]] '{' Rescue_Block '}'}
                 ['ensure' '{' Block_Stat {semi Block_Stat} '}']
Fun_Stats    ::= Block
                 {'rescue' [Pattern [Guard]] semi Rescue_Block }
                 ['ensure' semi Block_Stat {semi Block_Stat}]
Rescue_Block ::= {Rescue_Stat semi} [Result_Expr]
Rescue_Stat  ::= Block_Stat | Retry_Expr | Reraise_Expr
Retry_Expr   ::= 'retry' [label_name] [Cond_Modifier1]
Reraise_Expr ::= 'reraise' [Cond_Modifier1]
\end{lstlisting}

Rescue expression ~\lstinline!rescue $h$!~ is similar to catch expression (\sref{sec:throw-catch-expressions}), with two major differences: First, each \code{rescue} is followed by \code{when} clause; second, all \code{rescue} expressions in the same scope form together a handler $h$, where rules from catch expressions apply, only that $h$ is expected to conform to type ~\lstinline!Partial_Function[Raiseable, $T$]!, where $T$ is the expected type of the whole \code{begin}-\code{rescue} expression. 

The syntactic overlap with \code{ensure} expression signifies that the same expression with the exact same behavior may be used with \code{rescue} expressions as well. 

Optionally, the \code{rescue} may appear before any \code{begin} keyword, being connected to the function body instead as the expression protected agains raiseables (this does not apply to \code{catch}), where the \code{begin} is implied to be at the very start of the function's body. 

The ~\lstinline!retry $l$!~ expression is available inside of each raiseable handler block, and evaluating it restarts evaluation of the whole expression since \code{begin} of the labeled rescue expression, or if no label is given, then of the innermost (if nested) rescue expression. Again, it is not available in catch handler block. 

The keyword ~\lstinline[language=Java]!try!~ is not available in Gear -- in Gear, there is no trying, there is doing or not doing.  






\section{Quoted Expressions}
\label{sec:syntactic-forms}






\subsection{Quasi-quotation}
\label{sec:quasi-quotation}

\syntax\begin{lstlisting}
Quasiquote_Expr ::= '<@' Any_Expr '@>'
Any_Expr        ::= Expr
                  | Block_Stat {semi Block_Stat}
                  | Template_Stat {semi Template_Stat}
                  | Alias_Expr
                  | Compilation_Unit
                  | Top_Stat_Seq
Splice_Expr     ::= '#{' Expr '}'
\end{lstlisting}

Quasi-quote expression ``~\lstinline!<@ $e$ @>!~'' is basically a well-formed piece of Gear source code, wrapped in parentheses preceded by a backtick. The expression represents the compiled expression $e$ in means of an AST node. Alternative way to define a quasi-quoted expression is with the annotation \code{@[quasi-quote]}.

Quasi-quote expressions may optionally be interpolated, so that values or other nodes may be injected into the represented AST. There are the following ways to interpolate the AST:
\begin{itemize}
  \item Interpolating expression ``~\lstinline!#{ $e$ }!~'', where $e$'s value is expanded into the AST as is. If the expression would require parentheses around it in the source, then parentheses have to be around the interpolating expression.\footnote{Note that the same delimiters are used to interpolate string literals.}
  \item The \code{@[unquote]} annotation, which puts parentheses around the annotated expression.
  \item The \code{@[splice]} annotation, where the annotated expression is expanded into the AST as it is. Otherwise equivalent to ``~\lstinline!#{ $e$ }!~''.
\end{itemize}

A quasi-quote without any interpolation is equivalent to a quote (\sref{sec:quotation}). 

Quasi-quotes are useful in combination with macros (\sref{sec:macros}). 

An interpolating (splice or unquote) expression (like ``~\lstinline!#{ $e$ }!~'') appearing outside of a quasi-quote expression produces a compile-time warning and is replaced with $e$ directly. 





\subsection{Quotation}
\label{sec:quotation}

\syntax\begin{lstlisting}
Quote_Expr      ::= '<@@' Any_Expr '@@>'
\end{lstlisting}

A quote expression ``~\lstinline!<@@ $e$ @@>!~'' is similar to a quasi-quote, but without any interpolation, therefore, any apparent interpolation within a quote stays just that and is never expanded (unquoted or spliced). The annotation that marks an expression for quotation is \code{@[quote]}. 





\section{Statements}
\label{sec:statements}

\syntax\begin{lstlisting}
Block_Stat     ::= Use
                 | {Annotation} ['implicit'] Def 
                   [In_Sep Block_Stat ['end']]
                 | {Annotation} {Local_Modifier} Tmpl_Def
                 | Expr
                 | Alias_Expr
                 | Capture_Usage
                 | ()
                 | 'open' Stable_Id
                 | 'assert' Expr
Template_Stat  ::= Use
                 | {Annotation} {Modifier} Def
                   [In_Sep Block_Stat ['end']]
                 | Tmpl_Member [In_Sep Block_Stat ['end']]
                 | Tmpl_Ifc_Impl
                 | Tmpl_Ifc_Dcl
                 | {Annotation} [Opt_Req] {Modifier} Dcl
                 | {Annotation} {Modifier} Prop_Dcl
                 | {Annotation} {Modifier} Prop_Def
                 | 'inherit' Stable_Id [Cond_Modifier]
                 | 'include' Stable_Id [Cond_Modifier]
                 | ['inherit' 'as'] 'prepend' Stable_Id [Cond_Modifier]
                 | 'implements' Stable_Id [Cond_Modifier]
                 | Expr
                 | Alias_Expr
                 | ()
                 | Opt_Req [val_ids | symbol_ids]
                 | Access_Modifier [val_ids | symbol_ids]
                 | {Annotation} {Modifier} Constraint_Dcl
                 | {Annotation} {Modifier} Constraint_Def
                 | {Annotation} 'invariant' Invariant_Def
Fun_Stats      ::= [Fun_Stat {semi Fun_Stat}] Return_Expr
                 | Block
                   {'rescue' [Pattern [Guard]] semi Block }
                   ['ensure' semi Block_Stat {semi Block_Stat}]
Fun_Stat       ::= Block_Stat
Tmpl_Member    ::= {Annotation} {Modifier} ['member'] Def
Tmpl_Ifc_Impl  ::= 'interface' (Annot_Type - Nullable_Mod) 
                   'with' Record_Extension {'and' Record_Extension} 
                   'end' ['interface']
Tmpl_Ifc_Dcl   ::= 'interface' (Annot_Type - Nullable_Mod) 
                   'end' ['interface']
Fun_Dec_Expr   ::= {Annotation} Dcl
                 | {Annotation} ['implicit'] Def
                 | ('transparent'
                   | 'opaque')
                 | 'pure'
                 | 'native' [Expr]
                 | ('immutable'
                   | 'mutable')
                 | ()
Alias_Expr     ::= 'alias' symbol_literal 'is' symbol_literal
                 | 'alias' id 'is' id
Capture_Usage  ::= 'use' id {',' id} 
                   'as' R_Modifier
Constraint_Dcl ::= 'constraint' id ['as' Type] 'end' ['constraint']
Constraint_Def ::= 'constraint' 
                   (id ['as' Type] [':='] Constraint_Block 
                   | Alias_Expr)
Invariant_Def  ::= '{' Block '}' | 'do' Block 'end' ['invariant']
Opt_Req        ::= 'optional' | 'requires'
symbol_ids     ::= symbol_literal {',' symbol_literal}
\end{lstlisting}

Statements occur as parts of blocks and templates. Despite their name, they are actually generally expressions as well, except that for some statements, their value is not much of a use, i.e. use clauses, whose value is a \code{nil}, or the empty statement/expression, whose value is again \code{nil}. 

Function statements is an umbrella term for a series of statements and expressions, so their effective value is more complex. 

An expression that is used as a statement can have an arbitrary value type. An expression statement $e$ is evaluated by evaluating $e$ and discarding and releasing the result of the evaluation. 

Block statements may be definitions, which bind local names in the block. The only modifier allowed in all block-local definitions is \code{implicit}. When prefixing a class or object definition, modifiers \code{abstract}, \code{final} and \code{sealed} are also permitted (\sref{sec:modifiers}).

Evaluation of a statement sequence entails evaluation of the statements in the order they are written. This behavior can be overridden for statement sequences in workflows (\sref{sec:workflows}).

Statement can be an import via a use clause (\sref{sec:use-clauses}), a definition or an expression, or it can be empty. Statements used in the template of a class definition can also be declarations. 

A function that is declared with \code{transparent} in its \code{declare} block, is visible as referentially transparent, and therefore the compiler and possibly the runtime as well are given the possibility to replace function applications of this same function with its previously computed result with the same arguments on the same receiver instance. In that sense, it is similar to memoization (\sref{sec:memoization}), but skips one call stack frame and works better during compilation, unlike memoization, which is a runtime feature. Moreover, all function parameters are then marked as \code{constant}. 

On the other hand, a function that is declared with \code{opaque} in its \code{declare} block, is visible as referentially opaque and those optimizations are disabled for it, so the function is re-evaluated each time it is applied. 

A function that is declared with \code{pure} has no access to the \code{self} object, the \code{Function.self} object is marked \code{constant}, and moreover, it has disabled access to all expressions that were not passed to it via arguments. However, \code{constant} is not added to its parameters. A function that is declared with \code{pure} can't be declared with \code{opaque}, as that would be contradictory. A function that is declared with \code{transparent} combines restrictions from both keywords. 

A function that is declared with \code{native} in its \code{declare} block, has its body defined outside of Gear source files. Compilation of a source code that contains such functions result in generation of necessary header files, so that the native implementation may interface with a particular Gear VM implementation. Every Gear VM that has the ability to run native functions defines its own extra annotations that may be attached to the function, to influence the header file somehow (implementation-defined). 

A function that is declared with \code{immutable} in its \code{declare} block, has the \code{self} value treated as immutable, therefore it presents a guarantee that applying it will never modify the target value. On the other hand, a function that is declared with \code{mutable} in its \code{declare} block, is no different from a function that is declared without \code{immutable} or \code{mutable}, but it presents a requirement that the target object will be mutable, and thus it is an error if it is not, and also it is an error if a function with such modifier is a member of a template that is declared \code{immutable}, because all of its member values are inherently immutable. 

An alias to a function name creates a duplicate record in method table of a class or a duplicate variable pointing to the aliased function name. From that scope on, the functions are bound by name, and aliased function names are also inherited. If a subtype attempts to override an aliased method, then all methods with that alias are overridden as well. 

The \code{Capture_Usage} syntax construct (of the forms ~\lstinline{use $\id_1 \commadots \id_n$ as weak}, ~\lstinline{use $\id_1 \commadots \id_n$ as unowned} and ~\lstinline{use $\id_1 \commadots \id_n$ as soft}) provide a way to define ownership of captured variables in blocks and anonymous functions. Every captured variable is stored as a property within the function object, and therefore it takes an ownership of the pointed object. By using this construct, the default strong reference can be replaced with a \code{Weak_Reference[T]}, an \code{Unowned_Reference[T]} or a \code{Soft_Reference[T]}, with automatic unwrapping and wrapping of read and written values. It is an error if $\id_i$ is not a variable name in an enclosing scope. 

When \code{optional} or \code{requires} appear in a template, the following message declarations are either optional or required. When a message declaration is optional, then its result type is always nullable. No restriction is put on required messages. When those keywords appear alone on a line, then all following message members are affected. When the keywords directly precede a message member declaration, then only that member is affected. If the keyword precedes a list of identifiers or symbols, message members of those names are affected. 

When \code{public}, \code{protected} or \code{private} appear in a template, the following member declarations have their accessibility affected. When those keywords appear alone on a line, then all following message members are affected. When the keywords directly precede a message member declaration, then only that member is affected. If the keyword precedes a list of identifiers or symbols, message members of those names are affected. 

Constraint definitions, of the form ~\lstinline!constraint $\id$ as $T$ := $b$!, define argument-less methods ($\id$), whose names are then available as local variables inside of constraint blocks ($b$). A type $T$ can be used to specify explicitly the result type of such methods. The instance variables of the owning object that are read by such methods are observed for changes, so that constrained types can be consistent. Constraints may be aliased. If at runtime the object changes in a way that breaks the constraint condition, then \code{Broken_Constraint} is raised upon next read of a variable typed with a constrained type. 

If a parameter-less method of the same name as a constraint already exists, it is sufficient to just declare the constraint and let the pre-existing method implement it. Otherwise, a constraint declaration behaves exactly like a method declaration. On the contrary, neither method declaration, nor method definition alone create a constraint. 

% TBD: describe invariant and assert





\section{Implicit Conversions}
\label{sec:implicit-conversions}

Implicit conversions can be applied to expressions whose type does not match their expected type, to qualifiers in selections, and to unapplied methods. The available implicit conversions are given in the next two sub-sections.

We say that a type $T$ is {\em compatible} to a type $U$ if $T$ weakly conforms to $T$ after applying eta-expansion (\sref{sec:eta-expansion}) and view applications (\sref{sec:views}), if necessary.






\subsection{Value Conversions}
\label{sec:value-conversions}

The following implicit conversions can be applied to an expression $e$, which is of some value type $T$ and which is type-checked with some expected type $\exptype$. Some of these implicit conversions may be disabled with pragmas.

\paragraph{Overloading resolution}
If an expression denotes several possible members of a class, overloading resolution (\sref{sec:overloading-resolution}) is applied to pick a unique member. 

\paragraph{Type instantiation}
An expression $e$ of a polymorphic type
\begin{lstlisting}
[$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$] $\mapsto\ T$
\end{lstlisting}
which does not appear as the function part or a type application is converted to a type instance of $T$ by determining with local type inference (\sref{sec:local-type-inference}) instance types $T_1 \commadots T_n$ for the type variables $a_1 \commadots a_n$ and implicitly embedding $e$ in the type application ~\lstinline!$e$[$T_1 \commadots T_n$]! (\sref{sec:type-applications}). 

\paragraph{Numeric widening}
If $e$ is of a number type which weakly conforms (\sref{sec:conformance}) to the expected type, it is widened to the expected type. 

\paragraph{Numeric narrowing}
If the expected type has smaller range than the number type of $e$, but the value of $e$ fits into the expected type, it is narrowed to the expected type. 

\paragraph{Value discarding}
If $e$ is of some value type and the expected type is \code{Unit}, $e$ is converted to the expected type by embedding it in the block ~\lstinline!{ $e$; () }!. 

\paragraph{View application}
If none of the previous conversions applies, view applications are not disallowed by pragmas (implicitly they are allowed), and $e$'s type does not conform to the expected type $\exptype$, an attempt is made to convert $e$ to the expected type with a view application (\sref{sec:views}). This can happen in compile time only if all necessary type information is available, otherwise, runtime handles it by using specialized instructions (and those instructions are disabled from compilation when view applications are disabled). 

\paragraph{Dynamic member selection}
If none of the previous conversions applies, and $e$ is a prefix of a selection ~\lstinline!$e$.$x$!, then if $e$'s type conforms to \code{Dynamic_Member_Selecting}, the selection is rewritten according to rules for dynamic member selection (\sref{sec:dynamic-member-selection}). Otherwise, \code{member_not_found} is invoked on the receiver, whose implementation in \code{Object} is to raise an error. 

% TBD: explain in a GFR how dynamic member selecting actually works on the Gear VM level - registering a method fallback chain if a member is not found, here it is like %[:apply_dynamic; :member_not_found], and determine what happens when this is not done (no-op maybe? error maybe? language config error maybe?)





\subsection{Method Conversions}
\label{sec:method-conversions}

The following implicit conversions can be applied to methods which are not applied to some argument list. 

\paragraph{Evaluation}
A parameterless method $m$ of type ~\lstinline!() -> $T$!~ is always converted to type $T$ by evaluating the expression to which $m$ is bound. 

\paragraph{Implicit application}
If the method takes only implicit parameters, implicit arguments are passed following the rules of (\sref{sec:implicit-parameters}).

\paragraph{Eta expansion}
Otherwise, if the expected type $\exptype$ is a function type ~\lstinline!($\Ts'$) -> $T'$!, eta-expansion (\sref{sec:eta-expansion}) is performed on the expression $e$. 

\paragraph{Empty application}
Otherwise, if $e$ is of a method type ~\lstinline!() $\mapsto\ T$!, it is implicitly applied to the empty argument list, yielding ~\lstinline!$e$()!. 






\subsection{Overloading Resolution}
\label{sec:overloading-resolution}

If an identifier or selection $e$ references several members of a class, the context of the reference is used to identify a unique member, if possible. The way this is done depends on whether or not $e$ is used as a function. Note that even if overloaded resolution picks up a unique member, that member still may not be applied in regard of the actual expected types of the function application. Let $\mathcal{A}$ be the set of members referenced by $e$. Overloading resolution of $e$ is applied after local type inference, although local type inference may play part in overloading resolution of nested argument expressions, which are applied separately. 

\subsubsection{Function in an application}

Assume first that $e$ appears as a function in an application, as in ~\lstinline!$e$($e_1 \commadots e_m$)!.

\paragraph{Shape-based overloading resolution}
One first determines the set of functions that are potentially applicable based on the {\em shape} of the arguments. 

The shape of an argument expression $e$, written ~\lstinline!$\shape$($e$)!, is a type that is defined as follows:
\begin{itemize}
\item For a function expression ~\lstinline!($p_1$: $T_1 \commadots p_n$: $T_n$) -> $b$!, the shape is ~\lstinline!(Any$\commadots\,$Any) -> $\shape$($b$)!, where \code{Any} occurs $n$ times in the argument type. 
\item For a named argument ~\lstinline!$n$: $e$!, the shape is ~\lstinline!@[named_arg :$n$] $\shape$($e$)!, which is an annotated type.\footnote{This is different from e.g. Scala, since Gear supports capturing named arguments, which make the definition of applicable functions different.} % TBD: fix the name of the annotation as it will be chosen over time. 
\item For all other expressions, the shape is \code{Nothing}. 
\end{itemize}

Let $\mathcal{B}$ be the set of alternatives in $\mathcal{A}$ that are {\em applicable} (\sref{sec:function-applications}) to expressions ~\lstinline!($e_1 \commadots e_n$)!~ of types ~\lstinline!($\shape$($e_1$)$\commadots \shape$($e_n$))!. If there is precisely one alternative in $\mathcal{B}$, that alternative is chosen. It is an error if that alternative is not applicable to the expected types of the argument expressions -- the method is unapplied (\sref{sec:value-conversions}). 

\paragraph{Argument counts based overloading resolution}
Otherwise, let $S_1 \commadots S_m$ be the vector of types obtained by typing each argument with an undefined expected type (kind of equivalent to typing it with \code{Any}), keeping the annotations of named arguments attached (from the previous step with the shape of arguments). For every member $m$ in $\mathcal{B}$, one determines whether it is applicable to expressions ~\lstinline!($e_1 \commadots e_m$)!~ of types $S_1 \commadots S_m$, which drops requirements set up by ~\lstinline!$\shape$($e$)!, namely those for function expressions, and therefore members in $\mathcal{B}$ are more likely to be selected. It is an error if none of the members in $\mathcal{B}$ are applicable -- the method is unapplied. If there is one single applicable alternative, that alternative is chosen. 

\paragraph{Applicability based overloading resolution}
Otherwise, let $\mathcal{C}$ be the set of applicable alternatives in the application to $e_1 \commadots e_m$. It is again an error if $\mathcal{C}$ is empty. Otherwise, one chooses the {\em most specific} alternative among the alternatives in $\mathcal{C}$, according to the following definition of being  ``more specific than''.

\paragraph{Triggered early evaluation}
If any of the corresponding parameter types of any alternative in $\mathcal{C}$ is a constrained type (\sref{sec:constrained-types}) or non-trivial pattern\footnote{Non-trivial patterns are all patterns that are not variable patterns or typed patterns -- but a typed pattern with a constrained type is considered non-trivial as well.}, an early argument evaluation is triggered, exactly once per each corresponding argument, to detect whether the alternative is applicable to the constrained type or if the pattern matches. 

\begin{definition}
The {\em relative weight} of an alternative $A$ over an alternative $B$ is defined as the sum of relative weights of each argument $e_i$ in the application to $e_1 \commadots e_m$. In the following equation, $A_i$ is the type of the parameter corresponding to $e_i$ in the alternative $A$, and $B_i$ is the type of the parameter corresponding to $e_i$ in the alternative $B$. 

\[\begin{array}{l l}
\weight(A, B) &= \sum_{i=1}^{m} \pweight(A_i, B_i) \\
\pweight(t, u) &= \cweight(t, u) + \rweight(t)
\end{array}
\]

\[\begin{array}{l l}
\cweight(t, u) &= \left\{ 
  \begin{array}{l l}
    1 & \textrm{if $t \conforms u$}\\
    0 & \textrm{otherwise}
  \end{array} \right. \\
\rweight(t) &= \left\{ 
  \begin{array}{l l}
    1 & \textrm{unless $t$ is a variadic or a capturing named parameter}\\
    0 & \textrm{otherwise}
  \end{array} \right.
\end{array}\]
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the relative weight of $A$ over $B$ is greater than the relative weight of $B$ over $A$. 

If $A$ and $B$ share the same relative weight and $A$ requires argument expressions to tuple conversion and $B$ does not, then $B$'s relative weight is taken to be higher than that of $A$, and vice versa. 

\paragraph{Generics based overloading resolution}
If there are more alternatives in $\mathcal{C}$ that are equally most specific, then let $\mathcal{D}$ be those equally most specific alternatives. One chooses the most specific alternative from $\mathcal{D}$ based on the following redefinition of being ``more specific than''. 

\begin{definition}
The {\em generic relative weight} of an alternative $A$ over an alternative $B$ is a number between $0$ and $1$, defined as follows:
\begin{itemize}
  \item $1$, if $A$ is not polymorphic and $B$ is polymorphic. 
  \item $0$, in any other case. 
\end{itemize}
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the generic relative weight of $A$ over $B$ is greater than the generic relative weight of $B$ over $A$. 

If there are more alternatives in $\mathcal{D}$ that are equally most specific, continue with overloading resolution on $\mathcal{D}$ using preference declarations. If that fails, one chooses one alternative from $\mathcal{D}$ as in overloading resolution without any application (\sref{sec:overloading-resolution-no-app}), where $\mathcal{A}$ is the same as $\mathcal{D}$ here, and the expected type is the expected type of the function application, unless there are consecutive function applications. 

\paragraph{Consecutive applications based overloading resolution}
If there are any consecutive function applications (\sref{sec:curried-functions}) involved, then let $\mathcal{E}$ be those alternatives from $\mathcal{D}$ that have no following parameter lists, and let $\mathcal{F}$ be those alternatives from $\mathcal{D}$, for which one of the following conditions is true:
\begin{itemize}
  \item There are $a$ following consecutive function applications and the alternative has $a$ more parameter lists. The last parameter list may or may not be marked \code{implicit}, it does not matter. 
  \item There are $a$ following consecutive function applications and the alternative has $a + 1$ more parameter lists, and the last one is marked \code{implicit}. Note that $a$ might be 0, so that methods with an extra implicit parameter list are preferred. 
  \item There are $a$ following consecutive function applications and the alternative has more than $a$ more parameter lists, and the whole expression containing the consecutive function applications is enclosed in a method value, for partial application. 
\end{itemize}
Then, if $\mathcal{F}$ is not empty, apply overloading resolution on $\mathcal{F}$ recursively, omitting the already processed parameter list and argument list in each turn. If overloading resolution on $\mathcal{F}$ selects a unique member, that one is chosen. If no unique alternative from $\mathcal{F}$ could be selected (either because none was applicable, or there were multiple applicable alternatives at the end of recursion), continue with overloading resolution on alternatives from $\mathcal{E}$ using preference declarations. If $\mathcal{E}$ is empty, it is an error. 

\paragraph{Declared preference based overloading resolution, using arguments preference}
Let $\mathcal{G}$ be those alternatives that are supposed to be resolved based on declared preference (there are two points from which this can happen). One finds all preference declarations using arguments filter (not limited to) for each alternative over other alternatives in $\mathcal{G}$. If there is one alternative in $\mathcal{G}$ that is preferred strictly more times than any other alternative, then that one is chosen. Otherwise, one continues with overloading resolution without any application (\sref{sec:overloading-resolution-no-app}), where $\mathcal{A}$ is the same as $\mathcal{G}$ (i.e. no elements from $\mathcal{G}$ are left out). 

\paragraph{Note}
Nested overloading resolutions happen in depth-first order. If an alternative is polymorphic, it needs to be type-reified with local type inference to first determine what the types are. If an argument expression is itself overloaded, overloading resolution needs to be applied on it first and alone, and the expected type of the argument expression defined by the local type inference algorithm. Notice that this is safe in regard to local type inference of the enclosing alternative, since the type of the argument expression is just a part of type bounds for the enclosing alternative. Indeed, ambiguities may need to be resolved explicitly. 

\example Assume the following overloaded function definitions:
\begin{lstlisting}
def f (*x: Integer) end             (* 1. *)
def f (x: Integer) end              (* 2. *)
def f (x: Integer, y: Integer) end  (* 3. *)
\end{lstlisting}

In the application \code{f(1)}, there are two applicable alternatives in regard to both shape and argument counts -- the first two. Applicability test gives relative weight to $(1)$ over $(2)$ of $1$, since it has a repeated parameter, and relative weight to $(2)$ over $(1)$ of 2, therefore the second is chosen. 

In the application \code{f(1, 2)}, there are again two applicable alternatives -- the first and the last. Applicability test gives relative weight to $(1)$ over $(3)$ of $2$, since it has a repeated parameter matching both arguments, and relative weight to $(3)$ over $(1)$ of $4$, therefore the second is chosen. 

In the application \code{f(1, 2, 3)}, there is only one applicable alternative (the first), which can be detected (as soon as) based on the shape of its argument expressions. 






\subsubsection{Function in a type application}

Assume next that $e$ appears as a function in an explicit type application (not inferred), as in ~\lstinline!$e$[$\targs$]!. Then let $\mathcal{B}$ be the set of all alternatives in $\mathcal{A}$ which take the same number of type parameters as there are type arguments in $\targs$ are chosen. It is an error if no such alternative exists -- the type application is unapplied. If there is one such alternative, that one is chosen. 

Otherwise, let $\mathcal{C}$ be the set of those alternatives in $\mathcal{B}$ that are applicable to the type arguments, so that the bounds defined by the alternative's type parameters are satisfied. It is an error if no such alternative exists. If there are several such alternatives, overloading resolution (different than this case: so either in a function application or not in a function application) is applied to the whole expression ~\lstinline!$e$[$\targs$]!. 






\subsubsection{Expression not in any application}
\label{sec:overloading-resolution-no-app}

Assume finally that $e$ does not appear as a function in either an application or a type application, (or that overloading resolution on a function in an application was left with several most specific alternatives). If an expected type is given, let $\mathcal{B}$ be the set of those alternatives in $\mathcal{A}$ which are compatible (\sref{sec:implicit-conversions}) to it. Otherwise, let $\mathcal{B}$ be the same as $\mathcal{A}$. It is an error if there is no such alternative. If there is one such alternative, that one is chosen. 

Otherwise, one chooses the {\em most specific} alternative among the alternatives in $\mathcal{B}$, according to the following definition of being ``more specific than'':

\begin{definition}
The {\em relative weight} of an alternative $A$ over an alternative $B$ is defined as a number from $0$ to $2$, defined as the sum of:
\begin{itemize}
  \item $1$ if $A \conforms B$, $0$ otherwise, and
  \item $1$ if $A$ is not polymorphic and $B$ is polymorphic, $0$ otherwise.
\end{itemize}
\end{definition}

An alternative $A$ is {\em more specific than} an alternative $B$, if the relative weight of $A$ over $B$ is greater than the relative weight of $B$ over $A$. 

If there are multiple most specific alternatives in $\mathcal{B}$, one chooses an alternative from $\mathcal{B}$, which is strictly more times preferred to the other alternatives in $\mathcal{B}$, based on preference declarations that include a result type filter for that alternative.\footnote{This is needed to resolve ambiguities in cases such as when the expected type is the least upper bound of the result types of two or more overloaded alternatives.}

It is an error if there is no alternative in $\mathcal{B}$ which is more specific than all other alternatives in $\mathcal{B}$ -- the method is unapplied.\footnote{This can be fixed e.g. by using typed expressions (\sref{sec:typed-expressions}).}

\paragraph{Note}
An important note is that when an identifier $e$ references several members of a class, it also references only those members that are visible (\sref{sec:modifiers}) from the scope where $e$ appears. 

% TBD: maybe add more examples? including named arguments, optional arguments...







\subsection{Local Type Inference}
\label{sec:local-type-inference}

Local type inference infers type arguments to be passed to expressions of polymorphic type. Say $e$ is of a type ~\lstinline![$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$] $\mapsto\ T$!~ and no explicit type arguments are given. 

Local type inference converts this expression to a type application ~\lstinline!$e$[$T_1 \commadots T_n$]!. The choice of the type arguments $T_1 \commadots T_n$ depends on the context in which the expression appears and on the expected type $\exptype$. 

Local type inference is not always able to infer all type arguments, and sometimes may even infer useless ones -- in that cases, explicit type arguments are to be used to solve the problems, if even possible. 

\paragraph{Case 1: Selections}
If the expression appears as a prefix of a selection (or is a function application with empty arguments list; or is any of that as a prefix of multiple such selection) with a name $x$, then type inference is {\em deferred} to the whole expression \code{$e$.$x$}. That is, if \code{$e$.$x$} has type $S$, it is now treated as having type ~\lstinline![$a_1$ >: $L_1$ <: $U_1 \commadots a_n$ >: $L_n$ <: $U_n$] $\mapsto\ S$!, and local type inference is applied in turn to infer type arguments for $a_1 \commadots a_n$, using the context in which \code{$e$.$x$} appears. If $x$ is itself polymorphic, the type parameters $a_1 \commadots a_n$ are virtually added to type parameters of $x$ as fresh names, just for the purpose of deferred type inference. 

\paragraph{Case 2: Values}
If the expression $e$ appears as a value without being applied to some value arguments in a function application, the type arguments are inferred by solving a constraint system which relates the expression's type $T$ with the expected type $\exptype$. Without loss of generality we can assume that $T$ is a value type; if it is a method type, we apply eta-expansion (\sref{sec:eta-expansion}) to convert it to a function type (which is a value type and we're home again). Solving means finding a substitution $\sigma$ of types $T_i$ for the type parameters $a_i$, such that all of the following conditions hold:
\begin{itemize}
  \item None of inferred types $T_i$ is a singleton type (\sref{sec:singleton-types}). % TBD: decide whether this restriction can be removed
  \item All type parameter bounds are satisfied, i.e. $\sigma L_i \conforms \sigma a_i$ and also $\sigma a_i \conforms \sigma U_i$ for $i = 1 \commadots n$. 
  \item The expression's type conforms to the expected type, i.e. $\sigma T \conforms \sigma \exptype$. 
\end{itemize}

It is an error if no such substitution exists. If several substitutions exist, local type inference will choose for each type variable $a_i$ a minimal or a maximal type $T_i$ of the solution space (where a maximal type is closer to \code{Any} and minimal is closer to \code{Undefined}). A {\em maximal} type $T_i$ will be chosen if the type parameter $a_i$ appears contravariantly (\sref{sec:variance-of-type-parameters}) in the type $T$ of the expression. A {\em minimal} type $T_i$ will be chosen in all other situations, i.e. if the type variable appears covariantly, non-variantly or not at all in the type $T$. We call such a substitution $\sigma$ an {\em optimal solution} of the given constraint system for the type $T$. 

\paragraph{Case 3: Methods}
This case applies if the expression $e$ appears in an application \code{$e$($d_1 \commadots d_m$)}. In that case $T$ is a method type ~\lstinline!($p_1$: $R_1 \commadots p_n$: $R_n$) $\mapsto\ T'$!. Without loss of generality, we can assume that the result type $T'$ is a value type; if it is a method type, we apply eta-expansion (\sref{sec:eta-expansion}) to convert it to a function type (which is a value type and we're home, yet again). One computes first the types $S_j$ of the argument expressions $d_j$, using two alternative schemes. Each argument expression $d_j$ is typed first with the expected type $R_j$, in which the type parameters $a_1 \commadots a_n$ are taken as unknown type constants. If this fails for the particular argument expression\footnote{E.g., because the conformance can't be determined, or maybe $d_j$ is overloaded and could not select a unique member with expected type $R_j$.}, the argument $d_j$ is typed instead with an expected type $R'_j$, which results from $R_j$ by replacing every type parameter in $a_1 \commadots a_n$ with $\udef$. If $d_j$ is overloaded, a unique member is selected based on $R_j$, and if that fails, it is selected based on $R'_j$; it is an error if a unique member for $d_j$ can not be selected. \footnote{Selecting a unique overloaded member here is likely to fail, if $R_j$ is polymorphic and the member is overloaded on result type. Using a typed expression is a way to prevent that.}

If $e$ is a member with multiple parameter lists, then every following passed argument list is considered to be virtually a part of $d_1 \commadots d_m$. Some argument lists may be missing, e.g. in case of partial application, and \code{Undefined} is then inferred for every type parameter that appears only in the missing parameter lists, so that it gets inferred again upon future application\footnote{But the type arguments that are inferred in this step are permanent and not inferred again upon future applications.}. Multiple argument lists may be written in multiple forms, e.g. \code{$e$($d_1 \commadots d_a$)$\ldots$($d_l \commadots d_m$)}, and \code{$e$($d_1 \commadots d_a$).apply($\ldots$).apply($d_l \commadots d_m$)} is accepted as well, as is the shorter form \code{$e$($d_1 \commadots d_a$).($\ldots$).($d_l \commadots d_m$)}.\footnote{This way, methods with multiple parameter lists are first-class citizens, unlike in Scala.}

In a second step, type arguments are inferred by solving a constraint system, which relates the method's type with the expected type $\exptype$ and the argument types $S_1 \commadots S_m$. Solving the constraint system means finding a substitution $\sigma$ of types $T_i$ for the type parameters $a_i$, such that all of the following conditions hold:
\begin{itemize}
  \item None of inferred types $T_i$ is a singleton type (\sref{sec:singleton-types}). % TBD: decide whether this restriction can be removed
  \item All type parameter bounds are satisfied, i.e. $\sigma L_i \conforms \sigma a_i$ and also $\sigma a_i \conforms \sigma U_i$ for $i = 1 \commadots n$. 
  \item The method's result type $T'$ conforms to the expected type, i.e. $\sigma T' \conforms \sigma \exptype$. 
  \item Each argument type weakly conforms (\sref{sec:conformance}) to the corresponding formal parameter type (\sref{sec:corresponding-parameters}), i.e. $\sigma S_j \conforms _w \sigma R_j$ for $j = 1 \commadots m$. 
  \item If there is no constraint involving $T_i$, \code{Undefined} is inferred. 
\end{itemize}

It is an error if no such substitution exists. If several solutions exists, an optimal one for the type $T'$ is chosen. 

All or parts of an expected type $\exptype$ may be undefined. The rules for conformance (\sref{sec:conformance}) are extended to this case by adding the rule that for any type $T$, the following two statements are always true:
\begin{itemize}
  \item $\udef \conforms T$
  \item $T \conforms \udef$
\end{itemize}

It is possible that no minimal or maximal solution for a type variable exists, which is an error. Because ``$\conforms$'' is a partial order, it is also possible that a solution set has several optimal solutions for a type. In that case, Gear is free to pick any one of them. 

\example Consider the two methods, where \code{List} is covariant in its type parameter:
\begin{lstlisting}
def cons [A] (x: A, xs: List[A]): List[A] := x ~> xs
def list_nil [B]: List[B] := List.Nil
\end{lstlisting}
and the definition
\begin{lstlisting}
val xs := cons(1, list_nil)  .
\end{lstlisting}

The application of \code{cons} is typed with an undefined expected type. This application is completed by local type inference to \code{cons[Integer](1, list_nil)}. Here, one uses the following reasoning to infer the type argument \code{Integer} for the type parameter \code{A}:

First, the argument expressions are typed. The first argument \code{1} has type \code{Integer}, whereas the second argument \code{list_nil} is not overloaded, and is itself polymorphic. One tries to type \code{list_nil} with an expected type \code{List[A]}. This leads to the constraint system
\begin{lstlisting}
List[?B] <: List[A]  ,
\end{lstlisting}
where we have labeled \code{?B} with a question mark to indicate that it is a variable in the constraint system. Because class \code{List} is covariant, the optimal solution of this constraint is a minimal type, 
\begin{lstlisting}
B := Nothing  .
\end{lstlisting}

This finishes one separate local type inferencing instance. 

In the second step, one solves the following constraint system for the type parameter \code{A} of \code{cons}:
\begin{lstlisting}
Integer <: ?A              (* for the parameter x *)
List[Nothing] <: List[?A]  (* for the parameter xs *)
List[?A] <: $\udef$        (* for the result type *)
\end{lstlisting}

The optimal solution of this constraint system is 
\begin{lstlisting}
A := Integer  ,
\end{lstlisting}
so \code{Integer} is the type inferred for \code{A}. 

The optimal solution is found based on the following reasoning: 
\begin{enumerate}
  \item Solutions for the first constraint are types \code{Integer} and its supertypes.
  \item Solutions for the second constraint are \code{Nothing} and all supertypes of \code{Nothing}, basically any type. Together with the first constraint, only those types from the solution of the first constraint are possible. 
  \item Solutions for the third constraint are all types. Together with the first two constraint, only those types from the solution of the first constraint are possible. 
  \item Therefore, the minimal type is chosen from the solution space, as \code{A} appears covariantly (\sref{sec:variance-of-type-parameters}) in the type $T$ of the expression (which is \code{List[A]}), which is in turn \code{Integer}. 
\end{enumerate}

\example Consider now the definition
\begin{lstlisting}
val ys := cons("abc", xs)  ,
\end{lstlisting}
where \code{xs} is defined as type \code{List[Integer]} as before. In this case local type inference proceeds as follows.

First, the argument expressions are typed. The first argument \code{"abc"} is of type \code{String}. The second argument \code{xs} is first tried to be typed with expected type \code{List[A]}. This fails, because we can't tell whether \code{List[Integer]} is a subtype or supertype of \code{List[A]}, as we don't yet know what \code{A} is. Therefore, the second strategy is attempted and \code{xs} is typed with expected type \code{List[$\udef$]}. This succeeds and yields the argument type \code{List[Integer]}.

In a second step, one solves the following constraint system for the type parameter \code{A} of \code{cons}:
\begin{lstlisting}
String <: ?A
List[Integer] <: List[?A]
List[?A] <: $\udef$
\end{lstlisting}

The optimal solution of this constraint system is
\begin{lstlisting}
A := Object  ,
\end{lstlisting}
so \code{Object} is the type inferred for \code{A}, as it is the least upper bound of \code{String} and \code{Integer}. Notice that if any of those were types not descending from \code{Object}, \code{Any} would be inferred instead, as the least upper bound of any type. 

% TBD: throw in some advanced examples, possibly include:
% - multiple parameter lists
% - more variances than just covariant List[T]
% - nested overloaded argument expressions, also overloaded on result type




\subsection{Eta-Expansion}
\label{sec:eta-expansion}

{\em Eta-expansion} converts an expression of a method type (not a function application) to an equivalent expression of a function type. It is especially useful to prevent re-evaluation of the expression's subexpressions, if the expression is passed using a by-name strategy. It proceeds in two steps. 

First, one identifies the maximal subexpressions of $e$, let's say these are $e_1 \commadots e_m$. For each of these, one creates a fresh name $x_i$. Let $e'$ be the expression resulting from replacing every maximal subexpression $e_i$ in $e$ by the corresponding fresh name $x_i$. Second, one creates a fresh name $y_i$ for every argument type $T_i$ of the method, for $i = 1 \commadots n$, using named arguments and parameters as defined by the method. The result of eta-expansion is then: 
\begin{lstlisting}
{
  val $x_1$ := $e_1$
  $\ldots$
  val $x_m$ := $e_m$
  ($y_1$: $T_1 \commadots y_n$: $T_n$) -> $e'$($y_1 \commadots y_n$)
}
\end{lstlisting}

\example A few examples of eta-expansion, the original expression and eta-expanded below it:
\begin{lstlisting}
(* expression: *)
&((1 .. 9).fold(z))
(* expands to: *)
{ val eta1 := z
  val eta2 := (1 .. 9)
  x -> eta2.fold(eta1)(x) }
\end{lstlisting}







\subsection{Dynamic Member Selection}
\label{sec:dynamic-member-selection}

Gear defines a marker trait \code{Dynamic_Member_Selecting} that enables dynamic invocations rewriting without resorting to use error handling mechanisms to implement dynamic dispatch. 

Instances $x$ of this trait allow method invocations ~\lstinline[deletekeywords={method}]!$x$.method(args)! for arbitrary method ~\lstinline[deletekeywords={method}]!method!~ and argument lists \code{args}, as well as property accesses ~\lstinline[deletekeywords={property}]!$x$.property! for arbitrary property names ~\lstinline[deletekeywords={property}]!property!. 

If an invocation is not implemented by $x$ (i.e. if type checking fails and no other implicit conversion provides a way to proceed with the invocation), it is virtually rewritten according to the following rules:

\begin{lstlisting}[deletekeywords={property,method}]
foo.method("blah")      foo.apply_dynamic(:method)("blah")
foo.method(x: "blah")   foo.apply_dynamic_named(:method)((:x, "blah"))
foo.method(1, x: 2)     foo.apply_dynamic_named(:method)(
                            (nil, 1), (:x, "blah"))
foo.property            foo.select_dynamic(:property)
foo.property := 10      foo.update_dynamic(:property)(10)
foo.array(10)           foo.apply_dynamic(:array)(10)
foo.array(10) := 11     foo.select_dynamic(:array).update(10)(11)
\end{lstlisting}











